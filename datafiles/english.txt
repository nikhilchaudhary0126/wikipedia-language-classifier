The Space Shuttle was a partially reusable low Earth orbital spacecraft system operated from April 12, 1981, to July 21, 2011, by the National Aeronautics and Space Administration in the United States. Launched from the Kennedy Space Center in Florida, five Space Shuttle orbiter vehicles flew on a total of 135 missions during 30 years. They conducted science experiments in orbit, helped build the International Space Station, and launched numerous satellites, interplanetary probes, and the Hubble Space Telescope. Four fully operational orbiters were initially built: Columbia, Challenger, Discovery (pictured), and Atlantis. Lost in mission accidents were Challenger in 1986 and Columbia in 2003, with a total of fourteen astronauts killed. A fifth operational orbiter, Endeavour, was built in 1991 to replace Challenger. The Space Shuttle was retired from service upon the conclusion of Atlantis's final flight.
The tiger (Panthera tigris) is the largest living cat species and a member of the genus Panthera. It is most recognisable for its dark vertical stripes on orange-brown fur with a lighter underside. It is an apex predator, primarily preying on ungulates such as deer and wild boar. It is territorial and generally a solitary but social predator, requiring large contiguous areas of habitat, which support its requirements for prey and rearing of its offspring. Tiger cubs stay with their mother for about two years, before they become independent and leave their mother's home range to establish their own.
The tiger once ranged widely from the Eastern Anatolia Region in the west to the Amur River basin in the east, and in the south from the foothills of the Himalayas to Bali in the Sunda Islands. Since the early 20th century, tiger populations have lost at least 93% of their historic range and have been extirpated from Western and Central Asia, the islands of Java and Bali, and in large areas of Southeast and South Asia and China. Today, the tiger's range is fragmented, stretching from Siberian temperate forests to subtropical and tropical forests on the Indian subcontinent and Sumatra.
The tiger is listed as Endangered on the IUCN Red List. As of 2015, the global wild tiger population was estimated to number between 3,062 and 3,948 mature individuals, with most of the populations living in small pockets isolated from each other. India currently hosts the largest tiger population. Major reasons for population decline are habitat destruction, habitat fragmentation and poaching. Tigers are also victims of human–wildlife conflict, particularly in range countries with a high human population density.
The tiger is among the most recognisable and popular of the world's charismatic megafauna. It featured prominently in ancient mythology and folklore and continues to be depicted in modern films and literature, appearing on many flags, coats of arms and as mascots for sporting teams. The tiger is the national animal of India, Bangladesh, Malaysia and South Korea.
Following Linnaeus's first descriptions of the species, several tiger specimens were described and proposed as subspecies.[11] The validity of several tiger subspecies was questioned in 1999. Most putative subspecies described in the 19th and 20th centuries were distinguished on basis of fur length and colouration, striping patterns and body size, hence characteristics that vary widely within populations. Morphologically, tigers from different regions vary little, and gene flow between populations in those regions is considered to have been possible during the Pleistocene. Therefore, it was proposed to recognize only two tiger subspecies as valid, namely P. t. tigris in mainland Asia, and P. t. sondaica in the Greater Sunda Islands.[12]
Results of craniological analysis of 111 tiger skulls from Southeast Asian range countries indicate that Sumatran tiger skulls differ from Indochinese and Javan tiger skulls, whereas Bali tiger skulls are similar in size to Javan tiger skulls. The authors proposed to classify the Sumatran and Javan tigers as distinct species, P. sumatrae and P. sondaica, with the Bali tiger as subspecies P. sondaica balica.[13]
In 2015, morphological, ecological, and molecular traits of all putative tiger subspecies were analysed in a combined approach. Results support distinction of the two evolutionary groups continental and Sunda tigers. The authors proposed recognition of only two subspecies, namely P. t. tigris comprising the Bengal, Malayan, Indochinese, South Chinese, Siberian and Caspian tiger populations, and P. t. sondaica comprising the Javan, Bali and Sumatran tiger populations. The authors also noted that this reclassification will affect tiger conservation management.
The tiger's closest living relatives were previously thought to be the Panthera species lion, leopard and jaguar. Results of genetic analysis indicate that about 2.88 million years ago, the tiger and the snow leopard lineages diverged from the other Panthera species, and that both may be more closely related to each other than to the lion, leopard and jaguar.[32][33] The geographic origin of the Panthera is most likely northern Central Asia or the Holarctic region. The tiger–snow leopard lineage dispersed in Southeast Asia during the Miocene.[34]
Panthera zdanskyi is considered to be a sister taxon of the modern tiger. It lived at the beginning of the Pleistocene about two million years ago, its fossil remains were excavated in Gansu province of northwestern China. It was smaller and more "primitive", but functionally and ecologically similar to the modern tiger. It is disputed as to whether it had the striping pattern. Northwestern China is thought to be the origin of the tiger lineage. Tigers grew in size, possibly in response to adaptive radiations of prey species like deer and bovids, which may have occurred in Southeast Asia during the Early Pleistocene.[35]
Panthera tigris trinilensis lived about 1.2 million years ago and is known from fossils excavated near Trinil in Java.[36] The Wanhsien, Ngandong, Trinil, and Japanese tigers became extinct in prehistoric times.[37] Tigers reached India and northern Asia in the late Pleistocene, reaching eastern Beringia, Japan, and Sakhalin. Some fossil skulls are morphologically distinct from lion skulls, which could indicate tiger presence in Alaska during the last glacial period, about 100,000 years ago.[38]
In the Philippine island of Palawan, two articulated phalanx bones were found amidst an assemblage of other animal bones and stone tools in Ille Cave near the village of New Ibajay. They were smaller than mainland tiger fossils, possibly due to insular dwarfism. Otherwise, it would appear that early humans had accumulated the bones,[39] so it may be that the tiger parts were imported from elsewhere, or that the tiger colonised Palawan from Borneo before the Holocene, considering the proximity of the two islands.[40][41] Fossil remains of tigers were also excavated in Sri Lanka, China, Japan and Sarawak (Malaysia) dating to the late Pliocene, Pleistocene and Early Holocene.[38][42] The Bornean tiger was apparently present in Borneo between the Late Pleistocene and the Holocene, but whether it went extinct in prehistoric or recent times has not been resolved.[42][43]
Results of a phylogeographic study indicate that all living tigers had a common ancestor 72,000–108,000 years ago.[24] The potential tiger range during the late Pleistocene and Holocene was predicted applying ecological niche modelling based on more than 500 tiger locality records combined with bioclimatic data. The resulting model shows a contiguous tiger range at the Last Glacial Maximum, indicating gene flow between tiger populations in mainland Asia. The Caspian tiger population was likely connected to the Bengal tiger population through corridors below elevations of 4,000 m (13,000 ft) in the Hindu Kush. The tiger populations on the Sunda Islands and mainland Asia were possibly separated during interglacial periods.[44]
The tiger's full genome sequence was published in 2013. It was found to have similar repeat composition to other cat genomes and an appreciably conserved synteny.[45]
The Pacific Ocean is the largest and deepest of Earth's oceanic divisions. It extends from the Arctic Ocean in the north to the Southern Ocean (or, depending on definition, to Antarctica) in the south and is bounded by the continents of Asia and Australia in the west and the Americas in the east.
At 165,250,000 square kilometers (63,800,000 square miles) in the area (as defined with a southern Antarctic border), this largest division of the World Ocean—and, in turn, the hydrosphere—covers about 46% of Earth's water surface and about 32% of its total surface area, making it larger than all of Earth's land area combined (148,000,000 square kilometers).[1] The centers of both the Water Hemisphere and the Western Hemisphere are in the Pacific Ocean. Ocean circulation (caused by the Coriolis effect) subdivides it[citation needed] into two largely independent volumes of water, which meet at the equator: the North(ern) Pacific Ocean and South(ern) Pacific Ocean. The Galápagos and Gilbert Islands, while straddling the equator, are deemed wholly within the South Pacific.[2]
Its mean depth is 4,000 meters (13,000 feet).[3] Challenger Deep in the Mariana Trench, located in the western north Pacific, is the deepest point in the world, reaching a depth of 10,928 meters (35,853 feet).[4] The Pacific also contains the deepest point in the Southern Hemisphere, the Horizon Deep in the Tonga Trench, at 10,823 meters (35,509 feet).[5] The third deepest point on Earth, the Sirena Deep, is also located in the Mariana Trench.
The western Pacific has many major marginal seas, including the South China Sea, the East China Sea, the Sea of Japan, the Sea of Okhotsk, the Philippine Sea, the Coral Sea, and the Tasman Sea.
The first contact of European navigators with the western edge of the Pacific Ocean was made by the Portuguese expeditions of António de Abreu and Francisco Serrão, via the Lesser Sunda Islands, to the Maluku Islands, in 1512,[12][13] and with Jorge Álvares's expedition to southern China in 1513,[14] both ordered by Afonso de Albuquerque from Malacca.
The eastern side of the ocean was discovered by Spanish explorer Vasco Núñez de Balboa in 1513 after his expedition crossed the Isthmus of Panama and reached a new ocean.[15] He named it Mar del Sur (literally, "Sea of the South" or "South Sea") because the ocean was to the south of the coast of the isthmus where he first observed the Pacific.
Map showing a large number of Spanish expeditions across the Pacific Ocean from the 16th to 18th centuries including the Manila galleon route between Acapulco and Manila, the first transpacific trade route in history.
In 1520, navigator Ferdinand Magellan and his crew were the first to cross the Pacific in recorded history. They were part of a Spanish expedition to the Spice Islands that would eventually result in the first world circumnavigation. Magellan called the ocean Pacífico (or "Pacific" meaning, "peaceful") because, after sailing through the stormy seas off Cape Horn, the expedition found calm waters. The ocean was often called the Sea of Magellan in his honor until the eighteenth century.[16] Magellan stopped at one uninhabited Pacific island before stopping at Guam in March 1521.[17] Although Magellan himself died in the Philippines in 1521, Spanish navigator Juan Sebastián Elcano led the remains of the expedition back to Spain across the Indian Ocean and round the Cape of Good Hope, completing the first world circumnavigation in 1522.[18] Sailing around and east of the Moluccas, between 1525 and 1527, Portuguese expeditions discovered the Caroline Islands,[19] the Aru Islands,[20] and Papua New Guinea.[21] In 1542–43 the Portuguese also reached Japan.[22]
In 1564, five Spanish ships carrying 379 explorers crossed the ocean from Mexico led by Miguel López de Legazpi, and sailed to the Philippines and Mariana Islands.[23] For the remainder of the 16th century, Spanish influence was paramount, with ships sailing from Mexico and Peru across the Pacific Ocean to the Philippines via Guam, and establishing the Spanish East Indies. The Manila galleons operated for two and a half centuries, linking Manila and Acapulco, in one of the longest trade routes in history. Spanish expeditions also discovered Tuvalu, the Marquesas, the Cook Islands, the Solomon Islands, and the Admiralty Islands in the South Pacific.[24]
Later, in the quest for Terra Australis ("the [great] Southern Land"), Spanish explorations in the 17th century, such as the expedition led by the Portuguese navigator Pedro Fernandes de Queirós, discovered the Pitcairn and Vanuatu archipelagos, and sailed the Torres Strait between Australia and New Guinea, named after navigator Luís Vaz de Torres. Dutch explorers, sailing around southern Africa, also engaged in discovery and trade; Willem Janszoon, made the first completely documented European landing in Australia (1606), in Cape York Peninsula,[25] and Abel Janszoon Tasman circumnavigated and landed on parts of the Australian continental coast and discovered Tasmania and New Zealand in 1642.[26]
In the 16th and 17th centuries, Spain considered the Pacific Ocean a mare clausum—a sea closed to other naval powers. As the only known entrance from the Atlantic, the Strait of Magellan was at times patrolled by fleets sent to prevent entrance of non-Spanish ships. On the western side of the Pacific Ocean the Dutch threatened the Spanish Philippines.[27]
The 18th century marked the beginning of major exploration by the Russians in Alaska and the Aleutian Islands, such as the First Kamchatka expedition and the Great Northern Expedition, led by the Danish Russian navy officer Vitus Bering. Spain also sent expeditions to the Pacific Northwest, reaching Vancouver Island in southern Canada, and Alaska. The French explored and settled Polynesia, and the British made three voyages with James Cook to the South Pacific and Australia, Hawaii, and the North American Pacific Northwest. In 1768, Pierre-Antoine Véron, a young astronomer accompanying Louis Antoine de Bougainville on his voyage of exploration, established the width of the Pacific with precision for the first time in history.[28] One of the earliest voyages of scientific exploration was organized by Spain in the Malaspina Expedition of 1789–1794. It sailed vast areas of the Pacific, from Cape Horn to Alaska, Guam and the Philippines, New Zealand, Australia, and the South Pacific.[24]
Growing imperialism during the 19th century resulted in the occupation of much of Oceania by European powers, and later Japan and the United States. Significant contributions to oceanographic knowledge were made by the voyages of HMS Beagle in the 1830s, with Charles Darwin aboard;[29] HMS Challenger during the 1870s;[30] the USS Tuscarora (1873–76);[31] and the German Gazelle (1874–76).[32]
Abel Aubert du Petit-Thouars taking over Tahiti on 9 September 1842
In Oceania, France obtained a leading position as imperial power after making Tahiti and New Caledonia protectorates in 1842 and 1853, respectively.[33] After navy visits to Easter Island in 1875 and 1887, Chilean navy officer Policarpo Toro negotiated the incorporation of the island into Chile with native Rapanui in 1888. By occupying Easter Island, Chile joined the imperial nations.[34](p53) By 1900 nearly all Pacific islands were in control of Britain, France, United States, Germany, Japan, and Chile.[33]
Although the United States gained control of Guam and the Philippines from Spain in 1898,[35] Japan controlled most of the western Pacific by 1914 and occupied many other islands during the Pacific War; however, by the end of that war, Japan was defeated and the U.S. Pacific Fleet was the virtual master of the ocean. The Japanese-ruled Northern Mariana Islands came under the control of the United States.[36] Since the end of World War II, many former colonies in the Pacific have become independent states.
The volume of the Pacific Ocean, representing about 50.1 percent of the world's oceanic water, has been estimated at some 714 million cubic kilometers (171 million cubic miles).[58] Surface water temperatures in the Pacific can vary from −1.4 °C (29.5 °F), the freezing point of sea water, in the poleward areas to about 30 °C (86 °F) near the equator.[59] Salinity also varies latitudinally, reaching a maximum of 37 parts per thousand in the southeastern area. The water near the equator, which can have a salinity as low as 34 parts per thousand, is less salty than that found in the mid-latitudes because of abundant equatorial precipitation throughout the year. The lowest counts of less than 32 parts per thousand are found in the far north as less evaporation of seawater takes place in these frigid areas.[60] The motion of Pacific waters is generally clockwise in the Northern Hemisphere (the North Pacific gyre) and counter-clockwise in the Southern Hemisphere. The North Equatorial Current, driven westward along latitude 15°N by the trade winds, turns north near the Philippines to become the warm Japan or Kuroshio Current.[61]
Turning eastward at about 45°N, the Kuroshio forks and some water moves northward as the Aleutian Current, while the rest turns southward to rejoin the North Equatorial Current.[62] The Aleutian Current branches as it approaches North America and forms the base of a counter-clockwise circulation in the Bering Sea. Its southern arm becomes the chilled slow, south-flowing California Current.[63] The South Equatorial Current, flowing west along the equator, swings southward east of New Guinea, turns east at about 50°S, and joins the main westerly circulation of the South Pacific, which includes the Earth-circling Antarctic Circumpolar Current. As it approaches the Chilean coast, the South Equatorial Current divides; one branch flows around Cape Horn and the other turns north to form the Peru or Humboldt Current.[64]
Marine pollution occurs when harmful effects result from the entry into the ocean of chemicals, particles, industrial, agricultural and residential waste, noise, or the spread of invasive organisms. Eighty percent of marine pollution comes from land. Air pollution is also a contributing factor by carrying off iron, carbonic acid, nitrogen, silicon, sulfur, pesticides or dust particles into the ocean.[1] Land and air pollution have proven to be harmful to marine life and its habitats.[2]
The pollution often comes from nonpoint sources such as agricultural runoff, wind-blown debris, and dust. Pollution in large bodies of water can be aggravated by physical phenomena like the biological effects of Langmuir circulation. Nutrient pollution, a form of water pollution, refers to contamination by excessive inputs of nutrients. It is a primary cause of eutrophication of surface waters, in which excess nutrients, usually nitrates or phosphates, stimulate algae growth. Many potentially toxic chemicals adhere to tiny particles which are then taken up by plankton and benthic animals, most of which are either deposit feeders or filter feeders. In this way, the toxins are concentrated upward within ocean food chains. Many particles combine chemically in a manner highly depletive of oxygen, causing estuaries to become anoxic.
When pesticides are incorporated into the marine ecosystem, they quickly become absorbed into marine food webs. Once in the food webs, these pesticides can cause mutations, as well as diseases, which can be harmful to humans as well as the entire food web. Toxic metals can also be introduced into marine food webs. These can cause a change to tissue matter, biochemistry, behaviour, reproduction, and suppress growth in marine life. Also, many animal feeds have a high fish meal or fish hydrolysate content. In this way, marine toxins can be transferred to land animals, and appear later in meat and dairy products.
In order to protect the ocean from marine pollution, policies have been developed internationally. The international community has agreed that reducing pollution in the oceans is a priority, which is tracked as part of Sustainable Development Goal 14 which actively seeks to undo these human impacts on the oceans. There are different ways for the ocean to get polluted, therefore there have been multiple laws, policies, and treaties put into place throughout history.
Although marine pollution has a long history, significant international laws to counter it were not enacted until the twentieth century. Marine pollution was a concern during several United Nations Conventions on the Law of the Sea beginning in the 1950s. Most scientists believed that the oceans were so vast that they had unlimited ability to dilute, and thus render pollution harmless.
In the late 1950s and early 1960s, there were several controversies about dumping radioactive waste off the coasts of the United States by companies licensed by the Atomic Energy Commission, into the Irish Sea from the British reprocessing facility at Windscale, and into the Mediterranean Sea by the French Commissariat à l'Energie Atomique. After the Mediterranean Sea controversy, for example, Jacques Cousteau became a worldwide figure in the campaign to stop marine pollution. Marine pollution made further international headlines after the 1967 crash of the oil tanker Torrey Canyon, and after the 1969 Santa Barbara oil spill off the coast of California.
Marine pollution was a major area of discussion during the 1972 United Nations Conference on the Human Environment, held in Stockholm. That year also saw the signing of the Convention on the Prevention of Marine Pollution by Dumping of Wastes and Other Matter, sometimes called the London Convention. The London Convention did not ban marine pollution, but it established black and gray lists for substances to be banned (black) or regulated by national authorities (gray). Cyanide and high-level radioactive waste, for example, were put on the black list. The London Convention applied only to waste dumped from ships, and thus did nothing to regulate waste discharged as liquids from pipelines.[3]
Surface runoff from farming, as well as urban runoff and runoff from the construction of roads, buildings, ports, channels, and harbours, can carry soil and particles laden with carbon, nitrogen, phosphorus, and minerals. This nutrient-rich water can cause fleshy algae and phytoplankton to thrive in coastal areas; known as algal blooms, which have the potential to create hypoxic conditions by using all available oxygen. In the coast of southwest Florida, harmful algal blooms have existed for over 100 years.[14] These algal blooms have been a cause of species of fish, turtles, dolphins, and shrimp to die and cause harmful effects on humans who swim in the water.[14]
Polluted runoff from roads and highways can be a significant source of water pollution in coastal areas. About 75% of the toxic chemicals that flow into Puget Sound are carried by stormwater that runs off paved roads and driveways, rooftops, yards and other developed land.[15] In California, there are many rainstorms that runoff into the ocean. These rainstorms occur from October to March, and these runoff waters contain petroleum, heavy metals, pollutants from emissions, etc.[16]
In China, there is a large coastal population that pollutes the ocean through land runoff. This includes sewage discharge and pollution from urbanization and land use. In 2001, more than 66,795 mi² of the Chinese coastal ocean waters were rated less than Class I of the Sea Water Quality Standard of China.[17] Much of this pollution came from Ag, Cu, Cd, Pb, As, DDT, PCBs, etc., which occurred from contamination through land runoff.[17]
Deep sea mining is a relatively new mineral retrieval process undergoing research which takes place on the ocean floor. Ocean mining sites are usually around large areas of polymetallic nodules or active and extinct hydrothermal vents at about 3,000 – 6,500 meters below the ocean's surface.[34][35] The vents create sulfide deposits, which contain precious metals such as silver, gold, copper, manganese, cobalt, and zinc.[36][37] The deposits are mined using either hydraulic pumps or bucket systems that take ore to the surface to be processed. As with all mining operations, deep sea mining raises questions about potential environmental damages to the surrounding areas.
Because deep sea mining is a relatively new field, the complete consequences of full-scale mining operations are unknown. However, experts are certain that removal of parts of the sea floor will result in disturbances to the benthic layer, increased toxicity of the water column, and sediment plumes from tailings.[36] Removing parts of the sea floor disturbs the habitat of benthic organisms, possibly, depending on the type of mining and location, causing permanent disturbances.[35] Aside from direct impact of mining the area, leakage, spills, and corrosion could alter the mining area's chemical makeup.
Among the impacts of deep sea mining, it is theorized that sediment plumes could have the greatest impact. Plumes are caused when the tailings from mining (usually fine particles) are dumped back into the ocean, creating a cloud of particles floating in the water. Two types of plumes occur: near-bottom plumes and surface plumes.[35] Near-bottom plumes occur when the tailings are pumped back down to the mining site. The floating particles increase the turbidity, or cloudiness, of the water, clogging filter-feeding apparatuses used by benthic organisms.[38] Surface plumes cause a more serious problem. Depending on the size of the particles and water currents the plumes could spread over vast areas.[35][39] The plumes could impact zooplankton and light penetration, in turn affecting the food web of the area.[35][39] Further research has been conducted by the Massachusetts Institute of Technology to investigate how these plumes travel through water in an attempt to create mathematical models which would allow for prediction of how plumes may travel and potentially this mitigate damage.[40] This research is used to contribute to the work of the International Seabed Authority, the body which is mandated to develop, implement and enforce rules for deep-sea mining activities within its area of responsibility, [41] in gaining a full understanding of the environmental impacts.
Deep sea mining is a growing subfield of experimental seabed mining that involves the retrieval of minerals and deposits from the ocean floor found at depths of 200 meters or greater.[1] Presently, the majority of marine mining efforts are limited to shallow coastal waters, where sand, tin and diamonds are more readily accessible.[1] To date, deep sea mining has been limited to There are three types of deep sea mining that have generated great interest: polymetallic nodule mining, polymetallic sulphide mining, and the mining of Cobalt-Rich ferromanganese crusts.[2] The majority of proposed deep sea mining sites are near of polymetallic nodules or active and extinct hydrothermal vents at 1,400 to 3,700 metres (4,600 to 12,100 ft) below the ocean’s surface.[3] The vents create globular or massive sulfide deposits, which contain valuable metals such as silver, gold, copper, manganese, cobalt, and zinc.[4][5] The deposits are mined using either hydraulic pumps or bucket systems that take ore to the surface to be processed.
As with all mining operations, deep sea mining raises questions about its potential environmental impact. Environmental advocacy groups such as Greenpeace and the Deep Sea Mining Campaign[6] have argued that seabed mining should not be permitted in most of the world's oceans because of the potential for damage to deep sea ecosystems and pollution by heavy metal laden plumes.[4] Prominent environmental activists and state leaders have also called for moratoriums or total bans due to the potential of devastating environmental impacts.[7]
Over the past decade, a new phase of deep-sea mining has begun. Rising demand for precious metals in Japan, China, Korea and India has pushed these countries in search of new sources. Interest has recently shifted toward hydrothermal vents as the source of metals instead of scattered nodules. The trend of transition towards an electricity-based information and transportation infrastructure currently seen in western societies further pushes demands for precious metals. The current revived interest in phosphorus nodule mining at the seafloor stems from phosphor-based artificial fertilizers being of significant importance for world food production. Growing world population pushes the need for artificial fertilizers or greater incorporation of organic systems within agricultural infrastructure.
The world's first "large-scale" mining of hydrothermal vent mineral deposits was carried out by Japan in August - September, 2017.[8] Japan Oil, Gas and Metals National Corporation (JOGMEC) carried out this operation using the Research Vessel Hakurei.[9] This mining was carried out at the 'Izena hole/cauldron' vent field within the hydrothermally active back-arc basin known as the Okinawa Trough which contains 15 confirmed vent fields according to the InterRidge Vents Database.
A deep sea mining venture in Papua New Guinea, the Solwara 1 Project, was granted a mining permit to begin mining a high grade copper-gold resource from a weakly active hydrothermal vent.[10] This controversial project generated an enormous backlash from the community and environmental activists[11] The Solwara 1 Project was located at 1600 metres water depth in the Bismarck Sea, New Ireland Province.[10] Using ROV (remotely operated underwater vehicles) technology developed by UK-based Soil Machine Dynamics, Nautilus Minerals Inc. is first company of its kind to announce plans to begin full-scale undersea excavation of mineral deposits.[12] However a dispute with the government of Papua-New Guinea delayed production and operations until early 2018.[10] In September 2019, it was announced that the project had collapsed as Nautilus Minerals Inc. went into administration and its major creditors sought to recoup the millions of dollars they had sunk into the project. The Prime Minister of Papua New Guinea called the project a "total failure", sparking calls for a deep sea mining moratorium from his Pacific counterparts.[13]
An additional site that is being explored and looked at as a potential deep sea mining site is the Clarion-Clipperton Fracture Zone (CCZ). The CCZ stretches over 4.5 million square kilometers of the Northern Pacific Ocean between Hawaii and Mexico.[14] Scattered across the abyssal plain are trillions of polymetallic nodules, potato-sized rocklike deposits containing minerals such as magnesium, nickel, copper, zinc, cobalt, and others.[14] Polymetallic nodules are also abundant in the Central Indian Ocean Basin and the Peru Basin.[15] Mining claims registered with the International Seabed Authority (ISA) are mostly located in the CCZ, most commonly in the manganese nodule province.[16] The ISA has entered into 18 different contracts with private companies and national governments to explore the suitability of polymetallic nodule mining in the CCZ.[15]
In 2019, the government of the Cook Islands passed two legislative bills pertaining to deep sea mining in the country's EEZ. The Sea Bed Minerals (SBM) Act of 2019 was passed to "enable the effective and responsible management of the seabed minerals of the Cook Islands in a way that also...seeks to maximize the benefits of seabed minerals for present and future generations of Cook Islanders."[17] Sea Bed Minerals (Exploration) Regulations Act and the Sea Bed Minerals Amendment Act were passed by Parliament in 2020 and 2021 respectively.[18] As much as 12 billion tons of polymetallic nodules are spread across the ocean floor in the Cook Island's EEZ. The nodules found in the EEZ contain cobalt, nickel, manganese, titanium, and Rare Earth Elements.[19]
On November 10, 2020, the Chinese submersible Fendouzhe reached the bottom of the Mariana Trench 10,909 meters (35,790 feet). It didn't surpass the record of American undersea explorer Victor Vescovo who claimed 10,927 meters (35,853 feet) in May 2019. Chief designer of the submersible, Ye Cong said the seabed was abundant with resources and a "treasure map" can be made of the deep sea.[20]
Diamonds are also mined from the seabed by De Beers and others. Nautilus Minerals Inc. planned to mine offshore waters in Papua New Guinea but the project never got off the ground due to company financial troubles.[23] Neptune Minerals holds tenements in Japan, Papua New Guinea, Solomon Islands, Vanuatu, Fiji, Tonga, and New Zealand and intends to explore and mine these areas at a later date.[24]
Cobalt-rich ferromanganese formations are found at various depths between 400 and 7000 meters below sea level (masl). These formations are a type of Manganese crust deposits. The substrates of rock consist of layered iron and Magnesium layers ( Fe-Mn oxyhydroxide deposits ) that will host mineralization.[25]
Cobalt-rich ferromanganese formations exist in two categories depending on the Depositional environment, (1) hydrogenetic cobalt-rich ferromanganese crusts and (2) hydrothermal crusts and encrustations. Temperature, depth and sources of seawater are dependent variables that shape how the formations grow. Hydrothermal crusts precipitate quickly, near 1600–1800 mm/Ma and grow in hydrothermal fluids at approximately 200 °C. Hydrogenetic crusts grow much slower at 1–5 mm/Ma but will have higher concentrations of critical metals.[26]
Submarine seamount provinces, linked to hotspots and seafloor spreading, vary in depth along the ocean floor. These seamount show characteristics distribution that connects them to Cobalt-rich ferromanganese formation. In Western Pacific, a study conducted at <1500 m to 3500 m (mbsl) proved that the cobalt crusts are concentrated in the seamount section that slops at less than 20°. The high-grade cobalt crust in the Western Pacific trended /correlated with latitude and longitude, a high region within 150°E‐140°W and 30°S‐30°N[27]
Polymetallic sulphides are resources available for extraction from Seafloor massive sulfide deposits, composed on and within the seafloor base when mineralized water discharges from Hydrothermal vent. The hot mineral-rich water precipitates and condenses when released from hydrothermal vents and meets the cold seawater.[28] The stock area of the chimney structures of hydrothermal vents can be highly mineralized.
Polymetallic nodules/manganese nodules are founded on Abyssal plain, in a range of sizes, some as large as 15 cm long. The Clipperton Fracture Zone (CCZ) is a well know area of occurrences. Nodules are recoded to have average growth rates near 10-20 mm/Ma.[29]
The Clipperton Fracture Zone is host to the largest untapped deposit nickel resource; Polymetallic nodules or Manganese nodule sit on the seafloor. These nodules require no need for drilling or typical Surface mining techniques.[30]The composition of nickel, cobalt, copper and manganese make up nearly 100% of the nodules, and generates no toxic tailings.[30] Polymetallic nodules in the Clipperton Fracture Zone are currently being studied to produce battery metals.[31]
Recent technological advancements have given rise to the use remotely operated vehicles (ROVs) to collect mineral samples from prospective mine sites. Using drills and other cutting tools, the ROVs obtain samples to be analyzed for precious materials. Once a site has been located, a mining ship or station is set up to mine the area.[12]
There are two predominant forms of mineral extraction being considered for full-scale operations: continuous-line bucket system (CLB) and the hydraulic suction system. The CLB system is the preferred method of nodule collection. It operates much like a conveyor-belt, running from the sea floor to the surface of the ocean where a ship or mining platform extracts the desired minerals, and returns the tailings to the ocean.[21] Hydraulic suction mining lowers a pipe to the seafloor which transfers nodules up to the mining ship. Another pipe from the ship to the seafloor returns the tailings to the area of the mining site.[21]
In recent years, the most promising mining areas have been the Central and Eastern Manus Basin around Papua New Guinea and the crater of Conical Seamount to the east. These locations have shown promising amounts of gold in the area's sulfide deposits (an average of 26 parts per million). The relatively shallow water depth of 1050 m, along with the close proximity of a gold processing plant makes for an excellent mining site.[5]
Deep sea mining project value chain can be differentiated using the criteria of the type of activities where the value is actually added. During prospecting, exploration and resource assessment phases the value is added to intangible assets, for the extraction, processing and distribution phases the value increases with relation to product processing. There is an intermediate phase – the pilot mining test which could be considered to be an inevitable step in the shift from “resources” to “reserves” classification, where the actual value starts.[32]
Exploration phase involves such operations as locating, sea bottom scanning and sampling using technologies such as echo-sounders, side scan sonars, deep-towed photography, ROVs, AUVs. The resource valuation incorporates the examination of data in the context of potential mining feasibility.
Value chain based on product processing involves such operations as actual mining (or extraction), vertical transport, storing, offloading, transport, metallurgical processing for final products. Unlike the exploration phase, the value increases after each operation on processed material eventually delivered to the metal market. Logistics involves technologies analogous to those applied in land mines. This is also the case for the metallurgical processing, although rich and polymetallic mineral composition which distinguishes marine minerals from its land analogs requires special treatment of the deposit. Environmental monitoring and impact assessment analysis relate to the temporal and spatial discharges of the mining system if they occur, sediment plumes, disturbance to the benthic environment and the analysis of the regions affected by seafloor machines. The step involves an examination of disturbances near the seafloor, as well as disturbances near the surface. Observations include baseline comparisons for the sake of quantitative impact assessments for ensuring the sustainability of the mining process.[32]
Small scale mining of the deep sea floor is being developed off the coast of Papua New Guinea using robotic techniques, but the obstacles are formidable.[33]
Research shows that polymetallic nodule fields are hotspots of abundance and diversity for a highly vulnerable abyssal fauna.[34] Because deep sea mining is a relatively new field, the complete consequences of full-scale mining operations on this ecosystem are unknown. However, some researchers have said they believe that removal of parts of the sea floor will result in disturbances to the benthic layer, increased toxicity of the water column and sediment plumes from tailings.[4][34] Removing parts of the sea floor could disturb the habitat of benthic organisms, with unknown long-term effects.[3] Preliminary studies on seabed disturbances from mining-related activities have indicated that it takes decades for the seabed to recover from minor disturbances. Minerals targeted by seabed mining activities take millions of years to regenerate, if they do so at all.[35] Aside from the direct impact of mining the area, some researchers and environmental activists have raised concerns about leakage, spills and corrosion that could alter the mining area’s chemical makeup.
Polymetallic Nodule fields form some of the few areas of hard substrate on the pelagic red clay bottom, attracting macrofauna. In 2013, Researchers from the University of Hawaii at Manoa conducted a baseline study of benthic communities in the CCZ, assessing a 350 square mile area with a remote-operated vehicle (ROV). They found that the area surveyed contained one of the most diverse megafaunal communities recorded on the abyssal plain.[36] The megafauna (species greater than 0.78 inches) surveyed included glass sponges, anemones, eyeless fish, sea stars, psychropotes, amphipods, and isopods.[36] Macrofauna (species greater than 0.5mm) were found to have very high local species diversity, with 80 -100 macrofaunal species per square meter. The highest species diversity was found living amongst the polymetallic nodules.[36] In a follow-up survey, researchers identified over 1000 species, 90% of them previously unknown, and over 50% of them dependent on the polymetallic nodules for survival; all were identified in areas demarcated for potential seabed mining. Many scientists believe that seabed mining is posed to irreparably harm fragile abyssal plain habitats.[36] Despite the potential environmental impacts, research shows that the loss of biomass involved in Deep Sea Mining is significantly smaller than the expected loss of biomass as a result of land ore mining.[37] It is estimated that with the continued process of land ore mining will lead to a loss of 568 megatons (approximately the same as that of the entire human population) of biomass[38] whereas projections of the potential environmental impact of Deep Sea Mining will lead to a loss of 42 megatons of biomass. In addition to the loss of biomass, land ore mining will lead to a loss of 47 trillion megafauna organisms, whereas deep-sea mining is expected to lead to a loss of 3 trillion megafauna organisms.
A rare species called 'Scaly-foot snail', also known as sea pangolin, has become first species to be threatened because of deep sea mining.[3][21]
Zooplankton are the animal component of the planktonic community ("zoo" comes from the Greek word for animal). They are heterotrophic (other-feeding), meaning they cannot produce their own food and must consume instead other plants or animals as food. In particular, this means they eat phytoplankton.
Zooplankton are generally larger than phytoplankton, mostly still microscopic but some can be seen with the naked eye. Many protozoans (single-celled protists that prey on other microscopic life) are zooplankton, including zooflagellates, foraminiferans, radiolarians, some dinoflagellates and marine microanimals. Macroscopic zooplankton include pelagic cnidarians, ctenophores, molluscs, arthropods and tunicates, as well as planktonic arrow worms and bristle worms.
Zooplankton is a categorization spanning a range of organism sizes including small protozoans and large metazoans. It includes holoplanktonic organisms whose complete life cycle lies within the plankton, as well as meroplanktonic organisms that spend part of their lives in the plankton before graduating to either the nekton or a sessile, benthic existence. Although zooplankton are primarily transported by ambient water currents, many have locomotion, used to avoid predators (as in diel vertical migration) or to increase prey encounter rate.
Ecologically important protozoan zooplankton groups include the foraminiferans, radiolarians and dinoflagellates (the last of these are often mixotrophic). Important metazoan zooplankton include cnidarians such as jellyfish and the Portuguese Man o' War; crustaceans such as copepods, ostracods, isopods, amphipods, mysids and krill; chaetognaths (arrow worms); molluscs such as pteropods; and chordates such as salps and juvenile fish. This wide phylogenetic range includes a similarly wide range in feeding behavior: filter feeding, predation and symbiosis with autotrophic phytoplankton as seen in corals. Zooplankton feed on bacterioplankton, phytoplankton, other zooplankton (sometimes cannibalistically), detritus (or marine snow) and even nektonic organisms. As a result, zooplankton are primarily found in surface waters where food resources (phytoplankton or other zooplankton) are abundant.
Just as any species can be limited within a geographical region, so are zooplankton. However, species of zooplankton are not dispersed uniformly or randomly within a region of the ocean. As with phytoplankton, ‘patches’ of zooplankton species exist throughout the ocean. Though few physical barriers exist above the mesopelagic, specific species of zooplankton are strictly restricted by salinity and temperature gradients; while other species can withstand wide temperature and salinity gradients.[5] Zooplankton patchiness can also be influenced by biological factors, as well as other physical factors. Biological factors include breeding, predation, concentration of phytoplankton, and vertical migration.[5] The physical factor that influences zooplankton distribution the most is mixing of the water column (upwelling and downwelling along the coast and in the open ocean) that affects nutrient availability and, in turn, phytoplankton production.[5]
Through their consumption and processing of phytoplankton and other food sources, zooplankton play a role in aquatic food webs, as a resource for consumers on higher trophic levels (including fish), and as a conduit for packaging the organic material in the biological pump. Since they are typically small, zooplankton can respond rapidly to increases in phytoplankton abundance,[clarification needed] for instance, during the spring bloom. Zooplankton are also a key link in the biomagnification of pollutants such as mercury.[6]
Zooplankton can also act as a disease reservoir. Crustacean zooplankton have been found to house the bacterium Vibrio cholerae, which causes cholera, by allowing the cholera vibrios to attach to their chitinous exoskeletons. This symbiotic relationship enhances the bacterium's ability to survive in an aquatic environment, as the exoskeleton provides the bacterium with carbon and nitrogen.[7]
Photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that, through cellular respiration, can later be released to fuel the organism's metabolic activities. This chemical energy is stored in carbohydrate molecules, such as sugars, which are synthesized from carbon dioxide and water – hence the name photosynthesis, from the Greek phōs (φῶς), "light", and sunthesis (σύνθεσις), "putting together".[1][2][3] In most cases, oxygen is also released as a waste product. Most plants, algae, and cyanobacteria perform photosynthesis; such organisms are called photoautotrophs. Photosynthesis is largely responsible for producing and maintaining the oxygen content of the Earth's atmosphere, and supplies most of the energy necessary for life on Earth.[4]
Although photosynthesis is performed differently by different species, the process always begins when energy from light is absorbed by proteins called reaction centers that contain green chlorophyll pigments. In plants, these proteins are held inside organelles called chloroplasts, which are most abundant in leaf cells, while in bacteria they are embedded in the plasma membrane. In these light-dependent reactions, some energy is used to strip electrons from suitable substances, such as water, producing oxygen gas. The hydrogen freed by the splitting of water is used in the creation of two further compounds that serve as short-term stores of energy, enabling its transfer to drive other reactions: these compounds are reduced nicotinamide adenine dinucleotide phosphate (NADPH) and adenosine triphosphate (ATP), the "energy currency" of cells.
In plants, algae and cyanobacteria, long-term energy storage in the form of sugars is produced by a subsequent sequence of light-independent reactions called the Calvin cycle. In the Calvin cycle, atmospheric carbon dioxide is incorporated into already existing organic carbon compounds, such as ribulose bisphosphate (RuBP).[5] Using the ATP and NADPH produced by the light-dependent reactions, the resulting compounds are then reduced and removed to form further carbohydrates, such as glucose. In other bacteria, different mechanisms such as the reverse Krebs cycle are used to achieve the same end.
The first photosynthetic organisms probably evolved early in the evolutionary history of life and most likely used reducing agents such as hydrogen or hydrogen sulfide, rather than water, as sources of electrons.[6] Cyanobacteria appeared later; the excess oxygen they produced contributed directly to the oxygenation of the Earth,[7] which rendered the evolution of complex life possible. Today, the average rate of energy capture by photosynthesis globally is approximately 130 terawatts,[8][9][10] which is about eight times the current power consumption of human civilization.[11] Photosynthetic organisms also convert around 100–115 billion tons (91–104 petagrams) of carbon into biomass per year.[12][13] The phenomenon that plants receive some energy from light – in addition to air, soil, and water – was first discovered in 1779 by Jan Ingenhousz.
In photosynthetic bacteria, the proteins that gather light for photosynthesis are embedded in cell membranes. In its simplest form, this involves the membrane surrounding the cell itself.[20] However, the membrane may be tightly folded into cylindrical sheets called thylakoids,[21] or bunched up into round vesicles called intracytoplasmic membranes.[22] These structures can fill most of the interior of a cell, giving the membrane a very large surface area and therefore increasing the amount of light that the bacteria can absorb.[21]
In plants and algae, photosynthesis takes place in organelles called chloroplasts. A typical plant cell contains about 10 to 100 chloroplasts. The chloroplast is enclosed by a membrane. This membrane is composed of a phospholipid inner membrane, a phospholipid outer membrane, and an intermembrane space. Enclosed by the membrane is an aqueous fluid called the stroma. Embedded within the stroma are stacks of thylakoids (grana), which are the site of photosynthesis. The thylakoids appear as flattened disks. The thylakoid itself is enclosed by the thylakoid membrane, and within the enclosed volume is a lumen or thylakoid space. Embedded in the thylakoid membrane are integral and peripheral membrane protein complexes of the photosynthetic system.
Plants absorb light primarily using the pigment chlorophyll. The green part of the light spectrum is not absorbed but is reflected which is the reason that most plants have a green color. Besides chlorophyll, plants also use pigments such as carotenes and xanthophylls.[23] Algae also use chlorophyll, but various other pigments are present, such as phycocyanin, carotenes, and xanthophylls in green algae, phycoerythrin in red algae (rhodophytes) and fucoxanthin in brown algae and diatoms resulting in a wide variety of colors.
These pigments are embedded in plants and algae in complexes called antenna proteins. In such proteins, the pigments are arranged to work together. Such a combination of proteins is also called a light-harvesting complex.[24]
Calcium oxalate accumulating plants, such as Amaranthus hybridus and Colobanthus quitensis, showed a variation of photosynthesis where calcium oxalate crystals function as dynamic carbon pools, supplying carbon dioxide (CO2) to photosynthetic cells when stomata are partially or totally closed. This process was named Alarm photosynthesis. Under stress conditions (e.g. water deficit) oxalate released from calcium oxalate crystals is converted to CO2 by an oxalate oxidase enzyme and the produced CO2 can support the Calvin cycle reactions. Reactive hydrogen peroxide (H2O2), the byproduct of oxalate oxidase reaction, can be neutralized by catalase. Alarm photosynthesis represents an unknown photosynthetic variation to be added to the already known C4 and CAM pathways. However, alarm photosynthesis, in contrast to these pathways, operates as a biochemical pump that collects carbon from the organ interior (or from the soil) and not from the atmosphere.[32][33]
Plants usually convert light into chemical energy with a photosynthetic efficiency of 3–6%.[36] Absorbed light that is unconverted is dissipated primarily as heat, with a small fraction (1–2%)[37] re-emitted as chlorophyll fluorescence at longer (redder) wavelengths. This fact allows measurement of the light reaction of photosynthesis by using chlorophyll fluorometers.[37]
Actual plants' photosynthetic efficiency varies with the frequency of the light being converted, light intensity, temperature and proportion of carbon dioxide in the atmosphere, and can vary from 0.1% to 8%.[38] By comparison, solar panels convert light into electric energy at an efficiency of approximately 6–20% for mass-produced panels, and above 40% in laboratory devices.
The efficiency of both light and dark reactions can be measured but the relationship between the two can be complex.[39] For example, the ATP and NADPH energy molecules, created by the light reaction, can be used for carbon fixation or for photorespiration in C3 plants.[39] Electrons may also flow to other electron sinks.[40][41][42] For this reason, it is not uncommon for authors to differentiate between work done under non-photorespiratory conditions and under photorespiratory conditions.[43][44][45]
Chlorophyll fluorescence of photosystem II can measure the light reaction, and Infrared gas analyzers can measure the dark reaction.[46] It is also possible to investigate both at the same time using an integrated chlorophyll fluorometer and gas exchange system, or by using two separate systems together.[47] Infrared gas analyzers and some moisture sensors are sensitive enough to measure the photosynthetic assimilation of CO2, and of ΔH2O using reliable methods[48] CO2 is commonly measured in μmols/(m2/s), parts per million or volume per million and H2O is commonly measured in mmol/(m2/s) or in mbars.[48] By measuring CO2 assimilation, ΔH2O, leaf temperature, barometric pressure, leaf area, and photosynthetically active radiation or PAR, it becomes possible to estimate, "A" or carbon assimilation, "E" or transpiration, "gs" or stomatal conductance, and Ci or intracellular CO2.[48] However, it is more common to used chlorophyll fluorescence for plant stress measurement, where appropriate, because the most commonly used measuring parameters FV/FM and Y(II) or F/FM' can be made in a few seconds, allowing the measurement of larger plant populations.[45]
Gas exchange systems that offer control of CO2 levels, above and below ambient, allow the common practice of measurement of A/Ci curves, at different CO2 levels, to characterize a plant's photosynthetic response.[48]
Integrated chlorophyll fluorometer – gas exchange systems allow a more precise measure of photosynthetic response and mechanisms.[46][47] While standard gas exchange photosynthesis systems can measure Ci, or substomatal CO2 levels, the addition of integrated chlorophyll fluorescence measurements allows a more precise measurement of CC to replace Ci.[47][49] The estimation of CO2 at the site of carboxylation in the chloroplast, or CC, becomes possible with the measurement of mesophyll conductance or gm using an integrated system.[46][47][50]
Photosynthesis measurement systems are not designed to directly measure the amount of light absorbed by the leaf. But analysis of chlorophyll-fluorescence, P700- and P515-absorbance and gas exchange measurements reveal detailed information about e.g. the photosystems, quantum efficiency and the CO2 assimilation rates. With some instruments, even wavelength-dependency of the photosynthetic efficiency can be analyzed.[51]
A phenomenon known as quantum walk increases the efficiency of the energy transport of light significantly. In the photosynthetic cell of an algae, bacterium, or plant, there are light-sensitive molecules called chromophores arranged in an antenna-shaped structure named a photocomplex. When a photon is absorbed by a chromophore, it is converted into a quasiparticle referred to as an exciton, which jumps from chromophore to chromophore towards the reaction center of the photocomplex, a collection of molecules that traps its energy in a chemical form that makes it accessible for the cell's metabolism. The exciton's wave properties enable it to cover a wider area and try out several possible paths simultaneously, allowing it to instantaneously "choose" the most efficient route, where it will have the highest probability of arriving at its destination in the minimum possible time.
Because that quantum walking takes place at temperatures far higher than quantum phenomena usually occur, it is only possible over very short distances, due to obstacles in the form of destructive interference that come into play. These obstacles cause the particle to lose its wave properties for an instant before it regains them once again after it is freed from its locked position through a classic "hop". The movement of the electron towards the photo center is therefore covered in a series of conventional hops and quantum walks.[52][53][54]
Jan van Helmont began the research of the process in the mid-17th century when he carefully measured the mass of the soil used by a plant and the mass of the plant as it grew. After noticing that the soil mass changed very little, he hypothesized that the mass of the growing plant must come from the water, the only substance he added to the potted plant. His hypothesis was partially accurate – much of the gained mass also comes from carbon dioxide as well as water. However, this was a signaling point to the idea that the bulk of a plant's biomass comes from the inputs of photosynthesis, not the soil itself.
Joseph Priestley, a chemist and minister, discovered that, when he isolated a volume of air under an inverted jar, and burned a candle in it (which gave off CO2), the candle would burn out very quickly, much before it ran out of wax. He further discovered that a mouse could similarly "injure" air. He then showed that the air that had been "injured" by the candle and the mouse could be restored by a plant.[72]
In 1779, Jan Ingenhousz repeated Priestley's experiments. He discovered that it was the influence of sunlight on the plant that could cause it to revive a mouse in a matter of hours.[72][73]
In 1796, Jean Senebier, a Swiss pastor, botanist, and naturalist, demonstrated that green plants consume carbon dioxide and release oxygen under the influence of light. Soon afterward, Nicolas-Théodore de Saussure showed that the increase in mass of the plant as it grows could not be due only to uptake of CO2 but also to the incorporation of water. Thus, the basic reaction by which photosynthesis is used to produce food (such as glucose) was outlined.[74]
Cornelis Van Niel made key discoveries explaining the chemistry of photosynthesis. By studying purple sulfur bacteria and green bacteria he was the first to demonstrate that photosynthesis is a light-dependent redox reaction, in which hydrogen reduces (donates its – electron to) carbon dioxide.
Robert Emerson discovered two light reactions by testing plant productivity using different wavelengths of light. With the red alone, the light reactions were suppressed. When blue and red were combined, the output was much more substantial. Thus, there were two photosystems, one absorbing up to 600 nm wavelengths, the other up to 700 nm. The former is known as PSII, the latter is PSI. PSI contains only chlorophyll "a", PSII contains primarily chlorophyll "a" with most of the available chlorophyll "b", among other pigments. These include phycobilins, which are the red and blue pigments of red and blue algae respectively, and fucoxanthol for brown algae and diatoms. The process is most productive when the absorption of quanta are equal in both the PSII and PSI, assuring that input energy from the antenna complex is divided between the PSI and PSII system, which in turn powers the photochemistry.[13]
Robert Hill thought that a complex of reactions consisting of an intermediate to cytochrome b6 (now a plastoquinone), another is from cytochrome f to a step in the carbohydrate-generating mechanisms. These are linked by plastoquinone, which does require energy to reduce cytochrome f for it is a sufficient reductant. Further experiments to prove that the oxygen developed during the photosynthesis of green plants came from water, were performed by Hill in 1937 and 1939. He showed that isolated chloroplasts give off oxygen in the presence of unnatural reducing agents like iron oxalate, ferricyanide or benzoquinone after exposure to light.
Animals (also called Metazoa) are multicellular eukaryotic organisms that form the biological kingdom Animalia. With few exceptions, animals consume organic material, breathe oxygen, are able to move, can reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. Over 1.5 million living animal species have been described—of which around 1 million are insects—but it has been estimated there are over 7 million animal species in total. Animals range in length from 8.5 micrometres (0.00033 in) to 33.6 metres (110 ft). They have complex interactions with each other and their environments, forming intricate food webs. The scientific study of animals is known as zoology.
Most living animal species are in Bilateria, a clade whose members have a bilaterally symmetric body plan. The Bilateria include the protostomes—in which many groups of invertebrates are found, such as nematodes, arthropods, and molluscs—and the deuterostomes, containing both the echinoderms as well as the chordates, the latter containing the vertebrates. Life forms interpreted as early animals were present in the Ediacaran biota of the late Precambrian. Many modern animal phyla became clearly established in the fossil record as marine species during the Cambrian explosion, which began around 542 million years ago. 6,331 groups of genes common to all living animals have been identified; these may have arisen from a single common ancestor that lived 650 million years ago.
Historically, Aristotle divided animals into those with blood and those without. Carl Linnaeus created the first hierarchical biological classification for animals in 1758 with his Systema Naturae, which Jean-Baptiste Lamarck expanded into 14 phyla by 1809. In 1874, Ernst Haeckel divided the animal kingdom into the multicellular Metazoa (now synonymous for Animalia) and the Protozoa, single-celled organisms no longer considered animals. In modern times, the biological classification of animals relies on advanced techniques, such as molecular phylogenetics, which are effective at demonstrating the evolutionary relationships between taxa.
Humans make use of many other animal species, such as for food (including meat, milk, and eggs), for materials (such as leather and wool), as pets, and as working animals including for transport. Dogs have been used in hunting, while many terrestrial and aquatic animals were hunted for sports. Nonhuman animals have appeared in art from the earliest times and are featured in mythology and religion.
The largest organisms now found on Earth can be determined according to various aspects of an organism's size, such as: mass, volume, area, length, height, or even genome size. Some organisms group together to form a superorganism (such as ants or bees), but such are not classed as single large organisms. The Great Barrier Reef is the world's largest structure composed of living entities, stretching 2,000 km (1,200 mi), but contains many organisms of many types of species.
This article lists the largest species for various types of organisms and mostly considers extant species. The organism sizes listed are frequently considered "outsized" and are not in the normal size range for the respective group.
If considered singular entities, the largest organisms are clonal colonies which can spread over large areas. Pando, a clonal colony of the quaking aspen tree, is widely considered to be the largest such organism by mass.[1] Even if such colonies are excluded, trees retain their dominance of this listing, with the giant sequoia being the most massive tree.[2] In 2006 a huge clonal colony of Posidonia oceanica was discovered south of the island of Ibiza. At 8 kilometres (5 mi) across, and estimated at around 100,000 years old,[3] it may be one of the largest and oldest clonal colonies on Earth.[4][5][6]
Among animals, the largest species are all marine mammals, specifically whales. The blue whale is believed to be the largest animal to have ever lived. The largest land animal classification is also dominated by mammals, with the African bush elephant being the largest of these.
The common ostrich (Struthio camelus) or simply ostrich, is a species of large flightless bird native to certain large areas of Africa. It is one of two extant species of ostriches, the only living members of the genus Struthio in the ratite order of birds. The other is the Somali ostrich (Struthio molybdophanes), which was recognized as a distinct species by BirdLife International in 2014 having been previously considered a very distinctive subspecies of ostrich.[2][3]
The common ostrich belongs to the order Struthioniformes. Struthioniformes previously contained all the ratites, such as the kiwis, emus, rheas, and cassowaries. However, recent genetic analysis has found that the group is not monophyletic, as it is paraphyletic with respect to the tinamous, so the ostriches are now classified as the only members of the order.[4][5] Phylogenetic studies have shown that it is the sister group to all other members of Palaeognathae and thus the flighted tinamous are the sister group to the extinct moa.[6][7] It is distinctive in its appearance, with a long neck and legs, and can run for a long time at a speed of 55 km/h (34 mph)[8] with short bursts up to about 70 km/h (43 mph),[9] the fastest land speed of any bird.[10] The common ostrich is the largest living species of bird and lays the largest eggs of any living bird (the extinct elephant birds of Madagascar and the giant moa of New Zealand laid larger eggs).
The common ostrich's diet consists mainly of plant matter, though it also eats invertebrates and small reptiles. It lives in nomadic groups of 5 to 50 birds. When threatened, the ostrich will either hide itself by lying flat against the ground, or run away. If cornered, it can attack with a kick of its powerful legs. Mating patterns differ by geographical region, but territorial males fight for a harem of two to seven females.
The common ostrich is farmed around the world, particularly for its feathers, which are decorative and are also used as feather dusters. Its skin is used for leather products and its meat is marketed commercially, with its leanness a common marketing point.[9]
The long neck and legs keep their head up to 2.8 m (9 ft) above the ground, and their eyes are said to be the largest of any land vertebrate: 50 mm (2.0 in) in diameter;[13] helping them to see predators at a great distance. The eyes are shaded from sunlight from above.[14][15] However, the head and bill are relatively small for the birds' huge size, with the bill measuring 12 to 14.3 cm (4.7 to 5.6 in).[9]
Their skin varies in color depending on the subspecies, with some having light or dark gray skin and others having pinkish or even reddish skin. The strong legs of the common ostrich are unfeathered and show bare skin, with the tarsus (the lowest upright part of the leg) being covered in scales: red in the male, black in the female. The tarsus of the common ostrich is the largest of any living bird, measuring 39 to 53 cm (15 to 21 in) in length.[9] The bird has just two toes on each foot (most birds have four), with the nail on the larger, inner toe resembling a hoof. The outer toe has no nail.[16] The reduced number of toes is an adaptation that appears to aid in running, useful for getting away from predators. Common ostriches can run at a speed over 70 km/h (43 mph) and can cover 3 to 5 m (9.8 to 16.4 ft) in a single stride.[17] The wings reach a span of about 2 metres (6 ft 7 in), and the wing chord measurement of 90 cm (35 in) is around the same size as for the largest flying birds.[9]
The feathers lack the tiny hooks that lock together the smooth external feathers of flying birds, and so are soft and fluffy and serve as insulation. Common ostriches can tolerate a wide range of temperatures. In much of their habitat, temperatures vary as much as 40 °C (72 °F) between night and day. Their temperature control relies in part on behavioral thermoregulation. For example, they use their wings to cover the naked skin of the upper legs and flanks to conserve heat, or leave these areas bare to release heat. The wings also function as stabilizers to give better maneuverability when running. Tests have shown that the wings are actively involved in rapid braking, turning and zigzag maneuvers.[18] They have 50–60 tail feathers, and their wings have 16 primary, four alular and 20–23 secondary feathers.[9]
The common ostrich's sternum is flat, lacking the keel to which wing muscles attach in flying birds.[19] The beak is flat and broad, with a rounded tip.[11] Like all ratites, the ostrich has no crop,[20] and it also lacks a gallbladder.[21] They have three stomachs, and the caecum is 71 cm (28 in) long. Unlike all other living birds, the common ostrich secretes urine separately from faeces.[22] All other birds store the urine and faeces combined in the coprodeum, but the ostrich stores the faeces in the terminal rectum.[22] They also have unique pubic bones that are fused to hold their gut. Unlike most birds, the males have a copulatory organ, which is retractable and 20 cm (8 in) long. Their palate differs from other ratites in that the sphenoid and palatal bones are unconnected.[9]
The majority of the common ostrich's internal solutes are made up of sodium ions (Na+), potassium ions (K+), chloride ions (Cl-), total short-chain fatty acids (SCFA), and acetate.[79] The caecum contains a high water concentration with reduced levels nearing the terminal colon, and exhibits a rapid fall in Na+ concentrations and small changes in K+ and Cl-.[79] The colon is divided into three sections and take part in solute absorption. The upper colon largely absorbs Na+ and SCFA, and partially absorbs KCl.[79] The middle colon absorbs Na+, SCFA, with little net transfer of K+ and Cl-.[79] The lower colon then slightly absorbs Na+ and water, and secretes K+. There is no net movements of Cl- and SCFA found in the lower colon.[79]
When the common ostrich is in a dehydrated state plasma osmolality, Na+, K+, and Cl- ions all increase, however, K+ ions returned to controlled concentration.[84] The common ostrich also experiences an increase in haematocrit, resulting in a hypovolemic state.[84] Two antidiuretic hormones, Arginine vasotocin (AVT) and angiotensin (AII) are increased in blood plasma as a response to hyperosmolality and hypovolemia.[84] AVT triggers antidiuretic hormone (ADH) which targets the nephrons of the kidney.[68] ADH causes a reabsorption of water from the lumen of the nephron to the extracellular fluid osmotically.[68] These extracellular fluids then drain into blood vessels, causing a rehydrating effect.[68] This drainage prevents loss of water by both lowering volume and increasing concentration of the urine.[68] Angiotensin, on the other hand, causes vasoconstriction on the systemic arterioles, and acts as a dipsogen for ostriches.[68] Both of these antidiuretic hormones work together to maintain water levels in the body that would normally be lost due to the osmotic stress of the arid environment.
The end-product of catabolism of protein metabolism in animals is nitrogen.[68] Animals must excrete this in the form of nitrogenous compounds.[68] Ostriches are uricotelic. They excrete nitrogen as the complex nitrogenous waste compound uric acid, and related derivatives.[68] Uric acid's low solubility in water gives a semi-solid paste consistency to the ostrich's nitrogenous waste.[68]
Reptiles are tetrapod animals in the class or clade Reptilia /rɛpˈtɪliə/.
As a class in Linnean taxonomy, Reptilia refers to a paraphyletic grouping comprising all amniotes (vertebrates which encase their embryos in a series of protective sacs) except synapsids (mammals and their extinct relatives) and Aves (birds). The class Reptilia comprises turtles, crocodilians, snakes, amphisbaenians, lizards, tuatara, and their extinct relatives. The study of the traditional reptile orders, historically combined with that of modern amphibians, is called herpetology.
Operating under the modern evolutionary principle of cladistics, many paleontologists and herpetologists have redefined Reptilia as a monophyletic clade containing all modern reptiles (in the traditional sense), and any other descendant of their last common ancestor. This includes birds, which are a subgroup of archosaurs and more closely related to crocodilians than to any other modern animal.[1] The clade Reptilia could alternatively be defined as referring to animals more closely related to modern reptiles than to mammals. This definition would make Reptilia synonymous with the clade Sauropsida.[2]
The earliest known proto-reptiles originated around 312 million years ago during the Carboniferous period, having evolved from advanced reptiliomorph tetrapods which became increasingly adapted to life on dry land. The earliest known eureptile ("true reptile") was Hylonomus, a small and superficially lizard-like animal. Genetic and fossil data argues that the two largest lineages of reptiles, Archosauromorpha (crocodilians, birds and kin) and Lepidosauromorpha (lizards and kin), diverged near the end of the Permian period.[3] In addition to the living reptiles, there are many diverse groups that are now extinct, in some cases due to mass extinction events. In particular, the Cretaceous–Paleogene extinction event wiped out the pterosaurs, plesiosaurs, ornithischians, and sauropods, alongside many species of theropods, crocodyliforms, and squamates (e.g., mosasaurs).
Modern non-bird reptiles inhabit all the continents except Antarctica. Several living subgroups are recognized: Testudines (turtles and tortoises), 361 species;[4][5] Rhynchocephalia (the tuatara from New Zealand), 1 species;[4][6] Squamata (lizards, snakes, and worm lizards), about 11,052 species;[4][7] and Crocodilia (crocodiles, gharials, caimans, and alligators), 27 species.[4][8]
Reptiles are tetrapod vertebrates, creatures that either have four limbs or, like snakes, are descended from four-limbed ancestors. Unlike amphibians, reptiles do not have an aquatic larval stage. Most reptiles are oviparous, although several species of squamates are viviparous, as were some extinct aquatic clades[9] – the fetus develops within the mother, using a (non-mammalian) placenta rather than contained in an eggshell. As amniotes, reptile eggs are surrounded by membranes for protection and transport, which adapt them to reproduction on dry land. Many of the viviparous species feed their fetuses through various forms of placenta analogous to those of mammals, with some providing initial care for their hatchlings. Extant reptiles range in size from a tiny gecko, Sphaerodactylus ariasae, which can grow up to 17 mm (0.7 in) to the saltwater crocodile, Crocodylus porosus, which can reach 6 m (19.7 ft) in length and weigh over 1,000 kg (2,200 lb).
The Taj Mahal (/ˌtɑːdʒ məˈhɑːl, ˌtɑːʒ-/;[4] lit. 'Crown of the Palace', [taːdʒ ˈmɛːɦ(ə)l])[5] is an ivory-white marble mausoleum on the southern bank of the river Yamuna in the Indian city of Agra. It was commissioned in 1632 by the Mughal emperor Shah Jahan (reigned from 1628 to 1658) to house the tomb of his favourite wife, Mumtaz Mahal; it also houses the tomb of Shah Jahan himself. The tomb is the centrepiece of a 17-hectare (42-acre) complex, which includes a mosque and a guest house, and is set in formal gardens bounded on three sides by a crenellated wall.
Construction of the mausoleum was essentially completed in 1643, but work continued on other phases of the project for another 10 years. The Taj Mahal complex is believed to have been completed in its entirety in 1653 at a cost estimated at the time to be around 32 million rupees, which in 2020 would be approximately 70 billion rupees (about U.S. $956 million). The construction project employed some 20,000 artisans under the guidance of a board of architects led by the court architect to the emperor, Ustad Ahmad Lahauri.
The Taj Mahal was designated as a UNESCO World Heritage Site in 1983 for being "the jewel of Muslim art in India and one of the universally admired masterpieces of the world's heritage". It is regarded by many as the best example of Mughal architecture and a symbol of India's rich history. The Taj Mahal attracts 7–8 million visitors a year and in 2007, it was declared a winner of the New 7 Wonders of the World (2000–2007) initiative.
The Taj Mahal was commissioned by Shah Jahan in 1631, to be built in the memory of his wife Mumtaz Mahal, who died on 17 June that year, while giving birth to their 14th child, Gauhara Begum.[9][10] Construction started in 1632,[11] and the mausoleum was completed in 1648, while the surrounding buildings and garden were finished five years later.[12] The imperial court documenting Shah Jahan's grief after the death of Mumtaz Mahal illustrates the love story held as the inspiration for the Taj Mahal.[13]
The most spectacular feature is the marble dome that surmounts the tomb. The dome is nearly 35 metres (115 ft) high which is close in measurement to the length of the base, and accentuated by the cylindrical "drum" it sits on, which is approximately 7 metres (23 ft) high. Because of its shape, the dome is often called an onion dome or amrud (guava dome).[18] The top is decorated with a lotus design which also serves to accentuate its height. The shape of the dome is emphasised by four smaller domed chattris (kiosks) placed at its corners, which replicate the onion shape of the main dome. The dome is slightly asymmetrical.[19] Their columned bases open through the roof of the tomb and provide light to the interior. Tall decorative spires (guldastas) extend from edges of base walls, and provide visual emphasis to the height of the dome. The lotus motif is repeated on both the chattris and guldastas. The dome and chattris are topped by a gilded finial which mixes traditional Persian and Hindustani decorative elements.[20]
The main finial was originally made of gold but was replaced by a copy made of gilded bronze in the early 19th century. This feature provides a clear example of integration of traditional Persian and Hindu decorative elements.[21] The finial is topped by a moon, a typical Islamic motif whose horns point heavenward.[22]
The minarets, which are each more than 40 metres (130 ft) tall, display the designer's penchant for symmetry. They were designed as working minarets— a traditional element of mosques, used by the muezzin to call the Islamic faithful to prayer. Each minaret is effectively divided into three equal parts by two working balconies that ring the tower. At the top of the tower is a final balcony surmounted by a chattri that mirrors the design of those on the tomb. The chattris all share the same decorative elements of a lotus design topped by a gilded finial. The minarets were constructed slightly outside of the plinth so that in the event of collapse, a typical occurrence with many tall constructions of the period, the material from the towers would tend to fall away from the tomb.[23]
The exterior decorations of the Taj Mahal are among the finest in Mughal architecture. As the surface area changes, the decorations are refined proportionally. The decorative elements were created by applying paint, stucco, stone inlays or carvings. In line with the Islamic prohibition against the use of anthropomorphic forms, the decorative elements can be grouped into either calligraphy, abstract forms or vegetative motifs. Throughout the complex are passages from the Qur'an that comprise some of the decorative elements. Recent scholarship suggests that Amanat Khan chose the passages.[24][25]
The calligraphy on the Great Gate reads "O Soul, thou art at rest. Return to the Lord at peace with Him, and He at peace with you."[25] The calligraphy was created in 1609 by a calligrapher named Abdul Haq. Shah Jahan conferred the title of "Amanat Khan" upon him as a reward for his "dazzling virtuosity."[26] Near the lines from the Qur'an at the base of the interior dome is the inscription, "Written by the insignificant being, Amanat Khan Shirazi."[27] Much of the calligraphy is composed of florid thuluth script made of jasper or black marble[26] inlaid in white marble panels. Higher panels are written in slightly larger script to reduce the skewing effect when viewed from below. The calligraphy found on the marble cenotaphs in the tomb is particularly detailed and delicate.[citation needed]
Abstract forms are used throughout, especially in the plinth, minarets, gateway, mosque, jawab and, to a lesser extent, on the surfaces of the tomb. The domes and vaults of the sandstone buildings are worked with tracery of incised painting to create elaborate geometric forms. Herringbone inlays define the space between many of the adjoining elements. White inlays are used in sandstone buildings, and dark or black inlays on the white marbles. Mortared areas of the marble buildings have been stained or painted in a contrasting colour which creates a complex array of geometric patterns. Floors and walkways use contrasting tiles or blocks in tessellation patterns.[28]
On the lower walls of the tomb are white marble dados sculpted with realistic bas relief depictions of flowers and vines. The marble has been polished to emphasise the exquisite detailing of the carvings. The dado frames and archway spandrels have been decorated with pietra dura inlays of highly stylised, almost geometric vines, flowers and fruits. The inlay stones are of yellow marble, jasper and jade, polished and levelled to the surface of the walls.[26]
The interior chamber of the Taj Mahal reaches far beyond traditional decorative elements. The inlay work is not pietra dura, but a lapidary of precious and semiprecious gemstones.[29] The inner chamber is an octagon with the design allowing for entry from each face, although only the door facing the garden to the south is used. The interior walls are about 25 metres (82 ft) high and are topped by a "false" interior dome decorated with a sun motif. Eight pishtaq arches define the space at ground level and, as with the exterior, each lower pishtaq is crowned by a second pishtaq about midway up the wall.[30] The four central upper arches form balconies or viewing areas, and each balcony's exterior window has an intricate screen or jali cut from marble. In addition to the light from the balcony screens, light enters through roof openings covered by chattris at the corners. The octagonal marble screen or jali bordering the cenotaphs is made from eight marble panels carved through with intricate pierce work. The remaining surfaces are inlaid in delicate detail with semi-precious stones forming twining vines, fruits and flowers. Each chamber wall is highly decorated with dado bas-relief, intricate lapidary inlay and refined calligraphy panels which reflect, in little detail, the design elements seen throughout the exterior of the complex.[31]
Muslim tradition forbids elaborate decoration of graves. Hence, the bodies of Mumtaz and Shah Jahan were put in a relatively plain crypt beneath the inner chamber with their faces turned right, towards Mecca. Mumtaz Mahal's cenotaph is placed at the precise centre of the inner chamber on a rectangular marble base of 1.5 by 2.5 metres (4 ft 11 in by 8 ft 2 in). Both the base and casket are elaborately inlaid with precious and semiprecious gems. Calligraphic inscriptions on the casket identify and praise Mumtaz. On the lid of the casket is a raised rectangular lozenge meant to suggest a writing tablet. Shah Jahan's cenotaph is beside Mumtaz's to the western side and is the only visible asymmetric element in the entire complex. His cenotaph is bigger than his wife's, but reflects the same elements: a larger casket on a slightly taller base precisely decorated with lapidary and calligraphy that identifies him. On the lid of the casket is a traditional sculpture of a small pen box.[30]
The pen box and writing tablet are traditional Mughal funerary icons decorating the caskets of men and women respectively. The Ninety Nine Names of God are calligraphic inscriptions on the sides of the actual tomb of Mumtaz Mahal. Other inscriptions inside the crypt include, "O Noble, O Magnificent, O Majestic, O Unique, O Eternal, O Glorious... ". The tomb of Shah Jahan bears a calligraphic inscription that reads; "He travelled from this world to the banquet-hall of Eternity on the night of the twenty-sixth of the month of Rajab, in the year 1076 Hijri."[32]
The complex is set around a large 300-metre (980 ft) square charbagh or Mughal garden. The garden uses raised pathways that divide each of the four-quarters of the garden into 16 sunken parterres or flowerbeds. Halfway between the tomb and gateway in the centre of the garden is a raised marble water tank with a reflecting pool positioned on a north-south axis to reflect the image of the mausoleum. The elevated marble water tank is called al Hawd al-Kawthar in reference to the "Tank of Abundance" promised to Muhammad.[33]
Elsewhere, the garden is laid out with avenues of trees labeled according to common and scientific names[34] and fountains. The charbagh garden, a design inspired by Persian gardens, was introduced to India by Babur, the first Mughal emperor. It symbolises the four flowing rivers of Jannah (Paradise) and reflects the Paradise garden derived from the Persian paridaeza, meaning 'walled garden.' In mystic Islamic texts of the Mughal period, Paradise is described as an ideal garden of abundance with four rivers flowing from a central spring or mountain, separating the garden into north, west, south and east.[citation needed]
Most Mughal charbaghs are rectangular with a tomb or pavilion in the centre. The Taj Mahal garden is unusual in that the main element, the tomb, is located at the end of the garden. With the discovery of Mahtab Bagh or "Moonlight Garden" on the other side of the Yamuna, the interpretation of the Archaeological Survey of India is that the Yamuna river itself was incorporated into the garden's design and was meant to be seen as one of the rivers of Paradise.[35] Similarities in layout and architectural features with the Shalimar Gardens suggests both gardens may have been designed by the same architect, Ali Mardan.[36] Early accounts of the garden describe its profusion of vegetation, including abundant roses, daffodils, and fruit trees.[37] As the Mughal Empire declined, the Taj Mahal and its gardens also declined. By the end of the 19th century, the British Empire controlled more than three-fifths of India,[38] and assumed management of the Taj Mahal. They changed the landscaping to their liking which more closely resembled the formal lawns of London.[39]
The Taj Mahal complex is bordered on three sides by crenellated red sandstone walls; the side facing the river is open. Outside the walls are several additional mausoleums, including those of Shah Jahan's other wives, and a larger tomb for Mumtaz's favourite servant.[citation needed] These structures, composed primarily of red sandstone, are typical of the smaller Mughal tombs of the era. The garden-facing inner sides of the wall are fronted by columned arcades, a feature typical of Hindu temples which was later incorporated into Mughal mosques. The wall is interspersed with domed chattris, and small buildings that may have been viewing areas or watch towers like the Music House, which is now used as a museum.[citation needed]
The main gateway (darwaza) is a monumental structure built primarily of marble, and reminiscent of the Mughal architecture of earlier emperors. Its archways mirror the shape of the tomb's archways, and its pishtaq arches incorporate the calligraphy that decorates the tomb. It utilises bas-relief and pietra dura inlaid decorations with floral motifs. The vaulted ceilings and walls have elaborate geometric designs like those found in the other sandstone buildings in the complex.[citation needed]
At the far end of the complex are two grand red sandstone buildings that mirror each other, and face the sides of the tomb. The backs of the buildings parallel the western and eastern walls. The western building is a mosque and the other is the jawab (answer), thought to have been constructed for architectural balance although it may have been used as a guesthouse. Distinctions between the two buildings include the jawab's lack of a mihrab (a niche in a mosque's wall facing Mecca), and its floors of geometric design whereas the floor of the mosque is laid with outlines of 569 prayer rugs in black marble. The mosque's basic design of a long hall surmounted by three domes is similar to others built by Shah Jahan, particularly the Masjid-i Jahān-Numā, or Jama Masjid, Delhi. The Mughal mosques of this period divide the sanctuary hall into three areas comprising a main sanctuary and slightly smaller sanctuaries on either side. At the Taj Mahal, each sanctuary opens onto an expansive vaulting dome. The outlying buildings were completed in 1643.[12]
The Taj Mahal is built on a parcel of land to the south of the walled city of Agra. Shah Jahan presented Maharajah Jai Singh with a large palace in the centre of Agra in exchange for the land.[40] An area of roughly 1.2 hectares (3 acres) was excavated, filled with dirt to reduce seepage, and levelled at 50 metres (160 ft) above riverbank. In the tomb area, wells were dug and filled with stone and rubble to form the footings of the tomb. Instead of lashed bamboo, workmen constructed a colossal brick scaffold that mirrored the tomb. The scaffold was so enormous that foremen estimated it would take years to dismantle.[41]
The Taj Mahal was constructed using materials from all over India and Asia. It is believed over 1,000 elephants were used to transport building materials. It took the efforts of 22,000 labourers, painters, embroidery artists and stonecutters to shape the Taj Mahal.[42] The translucent white marble was brought from Makrana, Rajasthan, the jasper from Punjab, jade and crystal from China. The turquoise was from Tibet and the Lapis lazuli from Afghanistan, while the sapphire came from Sri Lanka and the carnelian from Arabia. In all, twenty-eight types of precious and semi-precious stones were inlaid into the white marble.[citation needed]
According to the legend, Shah Jahan decreed that anyone could keep the bricks taken from the scaffold, and thus it was dismantled by peasants overnight.[43] A 15-kilometre (9.3 mi) tamped-earth ramp was built to transport marble and materials to the construction site and teams of twenty or thirty oxen pulled the blocks on specially constructed wagons.[44] An elaborate post-and-beam pulley system was used to raise the blocks into desired position. Water was drawn from the river by a series of purs, an animal-powered rope and bucket mechanism, into a large storage tank and raised to a large distribution tank. It was passed into three subsidiary tanks, from which it was piped to the complex.[citation needed]
The plinth and tomb took roughly 12 years to complete. The remaining parts of the complex took an additional 10 years and were completed in order of minarets, mosque and jawab, and gateway. Since the complex was built in stages, discrepancies exist in completion dates due to differing opinions on "completion". Construction of the mausoleum itself was essentially completed by 1643[11] while work on the outlying buildings continued for years. Estimates of the cost of construction vary due to difficulties in estimating costs across time. The total cost at the time has been estimated to be about 32 million Indian rupees,[11] which is around 52.8 billion Indian rupees ($827 million US) based on 2015 values.[45]
In 1942, the government erected scaffolding to disguise the building in anticipation of air attacks by the Japanese Air Force.[48][49] During the India-Pakistan wars of 1965 and 1971, scaffolding was again erected to mislead bomber pilots.[50]
More recent threats have come from environmental pollution on the banks of the Yamuna River including acid rain[51] due to the Mathura Oil Refinery,[52] which was opposed by Supreme Court of India directives.[53] The pollution has been turning the Taj Mahal yellow-brown.[54] To help control the pollution, the Indian government has set up the "Taj Trapezium Zone (TTZ)", a 10,400-square-kilometre (4,000 sq mi) area around the monument where strict emissions standards are in place.[55]
Concerns for the tomb's structural integrity have recently been raised because of a decline in the groundwater level in the Yamuna river basin which is falling at a rate of around 1.5 m (5 ft) per year. In 2010, cracks appeared in parts of the tomb, and the minarets which surround the monument were showing signs of tilting, as the wooden foundation of the tomb may be rotting due to lack of water. It has been pointed out by politicians, however, that the minarets are designed to tilt slightly outwards to prevent them from crashing on top of the tomb in the event of an earthquake. In 2011, it was reported that some predictions indicated that the tomb could collapse within five years.[56][56]
Small minarets located at two of the outlying buildings were reported as damaged by a storm on April 11, 2018.[57] On 31 May 2020 another fierce thunderstorm caused some damage to the complex.[58]
The Taj Mahal attracts a large number of tourists. UNESCO documented more than 2 million visitors in 2001,[59] which had increased to about 7–8 million in 2014.[3] A two-tier pricing system is in place, with a significantly lower entrance fee for Indian citizens and a more expensive one for foreigners. In 2018, the fee for Indian citizens was 50 INR, for foreign tourists 1,100 INR.[60] Most tourists visit in the cooler months of October, November and February. Polluting traffic is not allowed near the complex and tourists must either walk from parking areas or catch an electric bus. The Khawasspuras (northern courtyards) are currently being restored for use as a new visitor centre.[61][62] In 2019, in order to address overtourism, the site instituted fines for visitors who stayed longer than three hours.[63]
The small town to the south of the Taj, known as Taj Ganji or Mumtazabad, was initially constructed with caravanserais, bazaars and markets to serve the needs of visitors and workers.[64] Lists of recommended travel destinations often feature the Taj Mahal, which also appears in several listings of seven wonders of the modern world, including the recently announced New Seven Wonders of the World, a recent poll with 100 million votes.[65]
The grounds are open from 6 to 19 weekdays, except for Friday when the complex is open for prayers at the mosque between 12:00 and 14:00. The complex is open for night viewing on the day of the full moon and two days before and after,[66] excluding Fridays and the month of Ramadan.
Foreign dignitaries often visit the Taj Mahal on trips to India. Notable figures who have travelled to the site include Dwight Eisenhower, Jacqueline Kennedy, Jimmy Carter, George H.W. Bush, George Harrison, Mark Zuckerberg, Vladimir Putin, Princess Diana, Donald Trump, and Justin Trudeau.[67][68][69]
Ever since its construction, the building has been the source of an admiration transcending culture and geography, and so personal and emotional responses have consistently eclipsed scholastic appraisals of the monument.[70] A longstanding myth holds that Shah Jahan planned a mausoleum to be built in black marble as a Black Taj Mahal across the Yamuna river.[9] The idea originates from fanciful writings of Jean-Baptiste Tavernier, a European traveller who visited Agra in 1665. It was suggested that his son Aurangzeb overthrew Shah Jahan before it could be built. Ruins of blackened marble across the river in the Mehtab Bagh, seemed to support this legend. However, excavations carried out in the 1990s found that they were discoloured white stones that had turned black.[71] A more credible theory for the origins of the black mausoleum was demonstrated in 2006 by archaeologists who reconstructed part of the pool in the Mehtab Bagh. A dark reflection of the white mausoleum could clearly be seen, befitting Shah Jahan's obsession with symmetry and the positioning of the pool itself. Warrior Empire: The Mughals of India. A+E Television Network. 2006.
No concrete evidence exists for claims that describe, often in horrific detail, the deaths, dismemberments and mutilations which Shah Jahan supposedly inflicted on various architects and craftsmen associated with the tomb. Some stories claim that those involved in construction signed contracts committing themselves to have no part in any similar design. Similar claims are made for many famous buildings.[72] No evidence exists for claims that Lord William Bentinck, governor-general of India in the 1830s, supposedly planned to demolish the Taj Mahal and auction off the marble. Bentinck's biographer John Rosselli says that the story arose from Bentinck's fund-raising sale of discarded marble from Agra Fort.[73]
Another myth suggests that beating the silhouette of the finial will cause water to come forth. To this day, officials find broken bangles surrounding the silhouette.[74]
In 2000, India's Supreme Court dismissed P. N. Oak's petition[75] to declare that a Hindu king built the Taj Mahal.[72][76] In 2005 a similar petition was dismissed by the Allahabad High Court. This case was brought by Amar Nath Mishra, a social worker and preacher who says that the Taj Mahal was built by the Hindu King Parmal Dev in 1196. Other theories suggest that the Taj Mahal was previously a Hindu Temple and Shah Jahan demolished the Hindu symbols and put Muslim symbols in its place to make it a tomb. The idols of the temple were hidden in a deep vault and locked up.[77]
A theory that the Taj Mahal was designed by an Italian, Geronimo Vereneo, held sway for a brief period after it was first promoted by Henry George Keene in 1879 who went by a translation of a Spanish work Itinerario, (The Travels of Fray Sebastian Manrique, 1629–1643). Another theory that a Frenchman, Austin of Bordeaux designed the Taj was promoted by William Henry Sleeman based on the work of Jean-Baptiste Tavernier. These ideas were revived by Father Hosten and discussed again by E.B. Havell and served as the basis for subsequent theories and controversies.[78]
A controversial but less-known theory suggests that the Taj Mahal marked the site of a Hindu temple dedicated to Shiva in the form of a lingam. When Shah Jahan arrived at the site upon Mumtaz's death, he demolished the temple and built the Taj Mahal entirely with Muslim symbols. The actual tomb of Mumtaz never contained her body but instead it contained the lingam that was at the temple site and other idols and Hindu symbols of the temple were hidden and locked in a vault under the Taj Mahal.
Another theory suggests that Mumtaz Mahal's remains were not buried in Agra but in the Ahukhana in Burhanpur. Shah Jahan had shifted base from Delhi due to the recurrent attacks from his enemies. He settled down at the Shahi Quila close to the Tapti River in Burhanpur sometime in the late 1620s. In the 16th century, the Mughals built the Ahukhana as a sprawling garden deer park. It had a small palace where the body of Mumtaz was laid to rest for about six months. Historical records state that Mumtaz Mahal’s mortal remains were kept at the Ahukhana for six months after her demise. Although, in its heydays, the Akhukhana was a vibrant retreat for the royal Mughals, all that remains today is a neglected site overgrown with wild grass. The dead body of Mumtaz Mahal was kept in a garden on the shore of Yamuna River for about 22 years till the completion of Taj Mahal in 1653 A.D. According to the locals of Burhanpur, Shah Jahan chose to built Taj Mahal in Agra for mainly three reasons. First, Burhanpur’s soil was infested with termites, and hence, it would have been impossible for it to hold a magnanimous building for long. Second, the emperor wanted the reflection of Taj Mahal to reflect on the river. Since, the Tapti River of Burhanpur was narrower as compared to the width of the Yamuna River in Agra, Shah Jahan naturally zeroed in on Agra. The third reason was Agra’s proximity to Makrana in Rajasthan from where the white marble was sourced.
The Great Pyramid of Giza (also known as the Pyramid of Khufu or the Pyramid of Cheops) is the oldest and largest of the pyramids in the Giza pyramid complex bordering present-day Giza in Greater Cairo, Egypt. It is the oldest of the Seven Wonders of the Ancient World, and the only one to remain largely intact.
Egyptologists conclude that the pyramid was built as a tomb for the Fourth Dynasty Egyptian pharaoh Khufu and estimate that it took around 27 years to build,[3] being completed circa 2560 BC.
Initially standing at 146.5 metres (481 feet), the Great Pyramid was the tallest man-made structure in the world for more than 3,800 years. The base was measured to be about 230.3 metres (755.6 ft) square, giving a volume of roughly 2.6 million cubic metres (92 million cubic feet), which includes an internal hillock.[4]
It was originally covered by white limestone casing stones that formed a smooth outer surface; The pyramid was dismantled and used as a quarry, mostly in the middle ages, which lowered its height to the present 137 metres (449.5 ft). What is seen today is the underlying core structure, although a few casing stones are still In situ.
The Great Pyramid was built by quarrying an estimated 2.3 million large stones weighing 6 million tonnes total, which were dragged into position. Many varying scientific and alternative hypotheses attempt to explain the exact construction techniques. Primarily local limestone from the Giza Plateau was used. Other blocks were imported by boat down the Nile: White limestone from Tura for the casing, and granite blocks from Aswan, weighing up to 80 tonnes, for the King's Chamber structure.[5]
The dimensions of the pyramid, expressed in ancient Egyptian units of measurement, were 280 cubits high, a base length of 440 cubits, with a Seked of palms (a slope of 51°50'40").There are three known chambers inside the Great Pyramid. The lowest chamber was cut into the bedrock upon which the pyramid was built but remained unfinished. The so-called[6] Queen's Chamber and King's Chamber, that contains a granite sarcophagus, are higher up, within the pyramid structure. The funerary complex around the pyramid included two mortuary temples connected by a causeway (one close to the pyramid and one near the Nile), tombs for the immediate family and court of Khufu, including three smaller pyramids for Khufu's wives, an even smaller "satellite" pyramid and five buried solar barges.
Historically the Great Pyramid had been attributed to Khufu based on the words of authors of classical antiquity, first and foremost Herodotus and Diodorus Siculus. However during the middle ages a number of other people were credited with the construction of the pyramid as well, for example Josef, Nimrod or king Saurid.[8]
In 1837 four additional Relieving Chambers were found above the King's Chamber after tunneling to them. The chambers, that had been inaccessible until then, were covered in hieroglyphs of red paint. The workers who were building the pyramid had marked the blocks with the names of their gangs, which included the pharaoh's name (e.g.: “The gang, The white crown of Khnum-Khufu is powerful”). Over a dozen times are the names of Khufu spelled out on the walls. Another one of these graffiti was found by Goyon on an exterior block of the 4th layer of the pyramid.[9] The inscriptions are comparable to those found at other sites of Khufu such as the alabaster quarry at Hatnub[10] or the harbor at Wadi al-Jarf, and are present in pyramids of other Pharaohs as well.[11][12]
Throughout the 20th century the cemeteries next to the pyramid were excavated. Family members and high officials of Khufu were buried in the East Field south of the causeway, and the West Field. Most notably the wives, children and grandchildren of Khufu, Hemiunu, Ankhaf and (the funerary cache of) Hetepheres I, mother of Khufu. As Hassan puts it: "From the early dynastic times, it was always the custom for the relatives, friends and courtiers to be buried in the vicinity of the king they had served during life. This was quite in accordance with the Egyptian idea of the Hereafter."
The cemeteries were actively expanded until the 6th dynasty and used less frequently afterwards. The earliest pharaonic name of seal impressions is that of Khufu, the latest of Pepi II. Worker graffiti are written on some of the stones of the tombs as well, for instance "Mddw" (Horus name of Khufu) on the mastaba of Chufunacht, probably a grandson of Khufu.[13]
Some inscriptions in the chapels of the mastabas (like the pyramid, their burial chambers were usually bare of inscriptions) mention Khufu or his pyramid. For instance an inscription of Mersyankh III states that "Her mother [is the] daughter of the King of Upper and Lower Egypt Khufu." Most often these references are part of a title, for example Snnw-ka, "Chief of the Settlement and Overseer of the Pyramid City of Akhet-Khufu" or Merib, "Priest of Khufu".[14] Several tomb owners have a king's name as part of their own name (e.g. Chufudjedef, Chufuseneb, Merichufu). The earliest pharaoh alluded to in that manner at Giza is Snefru (Khufu's father).[15][16][17]
In 1936 Hassan uncovered a stela of Amenhopet II near the Great Sphinx of Giza which implies the two larger pyramids were still attributed to Khufu and Khafre in the New Kingdom. It reads: "He yoked the horses in Memphis, when he was still young, and stopped at the Sanctuary of Hor-em-akhet (the Sphinx). He spent a time there in going round it, looking at the beauty of the Sanctuary of Khufu and Khafra the revered."[18]
In 1954 the Khufu ship was discovered, buried south of the pyramid. The cartouche of Djedefre was found on many of the blocks that covered the boat pit. As the successor and eldest son he would have presumably been responsible for the burial of Khufu.[19]
During excavations in 2013 the Diary of Merer was found at Wadi al-Jarf. It documents the transportation of white limestone blocks from Tura to the Great Pyramid, which is mentioned by its original name Akhet Khufu (with a pyramid determinative) dozens of times. It details that the stones were accepted at She Akhet-Khufu ("the pool of the pyramid Horizon of Khufu") or Ro-She Khufu (“the entrance to the pool of Khufu”) which was under supervision of Ankhhaf, half brother and vizier of Khufu who is the owner of the largest mastaba of the Giza East Field.[20]
The ancient Greek historian Herodotus, writing in the 5th century BC, is one of the first major authors to mention the pyramid. In the second book of his work The Histories, he discusses the history of Egypt and the Great Pyramid. This report was created more than 2000 years after the structure was built, meaning that Herodotus obtained his knowledge mainly from a variety of indirect sources, including officials and priests of low rank, local Egyptians, Greek immigrants, and Herodotus's own interpreters. Accordingly, his explanations present themselves as a mixture of comprehensible descriptions, personal descriptions, erroneous reports, and fantastical legends; as such, many of the speculative errors and confusions about the monument can be traced back to Herodotus and his work.[21][22]
Herodotus writes that the pyramid was built by Khufu (Hellenized as Cheops), whom he mistakenly argues ruled sometime after Ramses III of the Twentieth Dynasty.[23] Khufu, Herodotus claims, was a tyrannical king, which probably shows the view of the Greeks that such buildings can only come about through cruel exploitation of the people.[21] Herodotus further writes that on the orders of Khufu, 100,000 workers worked on the building in three-month shifts, taking 20 years to build. In the first ten years, a wide causeway was erected, which, according to Herodotus, was almost as impressive as the construction of the pyramids themselves, since it was nearly 1 kilometre (0.62 mi) long and twenty yards wide, and elevated at its highest to a height of sixteen yards, and it is all of stone polished and carved with figures.[24] In addition, underground chambers were made on the hill whereon the pyramids stand, meant to be burial places for Khufu himself, which were encompassed with water which a channel brought in from the Nile.[24] Herodotus later states that at the Pyramid of Khafre (next to the Great Pyramid) the Nile flows through a built passage to an island in which Khufu is buried.[25] (Hawass interprets this to be a reference to the "Osiris Shaft" which is located at the causeway of Khafre south of the Great Pyramid.)[26][27]
Herodotus also described an inscription on the outside of the pyramid which, according to his translators, indicated the amount of radishes, garlic and onions that the workers would have eaten while working on the pyramid.[28] This could be a note of restoration work that Khaemweset, son of Rameses II, had carried out. Apparently, Herodotus companions and interpreters could not read the hieroglyphs or deliberately gave him false information.[29]
Between 60-56 BC, the ancient Greek historian Diodorus Siculus visited Egypt and later dedicated the first book of his Bibliotheca historica to the land, its history, and its monuments, including the Great Pyramid. Diodorus's work was inspired by historians of the past, but he also distanced himself from Herodotus, who Diodorus claimed described only "marvelous tales and the invention of myths".[30] Diodorus presumably drew his knowledge from the lost work of Hecataeus of Abdera,[31] and like Herodotus, he also places the builder of the pyramid, "Chemmis,"[32] after Ramses III.[23] According to his report, neither Chemmis (Khufu) nor Cephren (Khafre) were buried in their pyramids, but rather in secret places, for fear that the people ostensibly forced to build the structures would seek out the bodies for revenge;[33] with this assertion, Diodorus strengthened the connection between pyramid building and slavery.[34]
According to Diodorus, the cladding of the pyramid was still in excellent condition at the time, whereas the uppermost part of the pyramid was formed by a platform six cubits wide (approx. 3 m). About the construction of the pyramid he notes that it was built with the help of ramps since no lifting tools had yet been invented. Nothing was left of the ramps, as they were removed after the pyramids were completed. He estimated the number of workers who were necessary to erect the Great Pyramid at 360,000 and the construction time at 20 years.[32] Similar to Herodotus, Diodorus also claims that the side of the pyramid is inscribed with writing that "[set] forth [the price of] vegetables and purgatives for the workmen there were paid out over sixteen hundred talents."[33]
The Greek geographer, philosopher, and historian Strabo visited Egypt around 25 BC, shortly after Egypt was annexed by the Romans. In his work Geographica, the writer argued that the pyramids were the burial place of kings, but he does mention which king was buried in the structure. Strabo also mentions: "At a moderate height in one of the sides is a stone, which may be taken out; when that is removed, there is an oblique passage to the tomb."[35] This statement has generated much speculation, as it suggests that the pyramid could be entered at this time.[36] I. E. S. Edwards later suggested that the pyramid was entered by robbers after the end of the Old Kingdom and sealed and then reopened more than once until Strabo's door was added sometime before 25 BC, potentially by the Saite pharaohs (664–525 BC). Edwards adds: "If this highly speculative surmise be correct, it is also necessary to assume either that the existence of the door was forgotten or that the entrance was again blocked with facing stones", in order to explain why al-Ma'mun could not find the entrance in the ninth century AD.[37] Scholars such as Gaston Maspero and Flinders Petrie have noted that evidence for a similar door has been found at the Bent Pyramid of Dashur.[38][39]
The Roman writer Pliny the Elder, writing in the first century AD, argued that the Great Pyramid had been raised either "to prevent the lower classes from remaining unoccupied", or as a measure to prevent the pharaoh's riches from falling into the hands of his rivals or successors.[40] Pliny does not speculate as to the pharaoh in question, explicitly noting that "accident [has] consigned to oblivion the names of those who erected such stupendous memorials of their vanity".[41] Pliny echoes previous authors, such as Diodorus Siculus, stating it took 20 years and 360,000 men to build.[42] Pliny further contends that the structure was built by stone hauled from "Arabia". In pondering how the stones could be transported to such a vast height he gives two explanations: That either vast mounds of nitre and salt were heaped up against the pyramid which were then melted away with water redirected from the river. Or that "bridges" were constructed, their bricks afterwards distributed for erecting houses of private individuals, arguing that the level of the river is too low for canals to ever bring water up to the pyramid. Pliny also recounts how "in the interior of the largest Pyramid there is a well, eighty-six cubits deep, which communicates with the river, it is thought". Further, he describes a method discovered by Thales of Miletus for ascertaining the pyramid's height by measuring its shadow.[41]
During late antiquity, a misinterpretation of the pyramids as "Joseph's granary" began to gain in popularity. The first textual evidence of this connection is found in the travel narratives of the female Christian pilgrim Egeria, who records that on her visit between 381-84 CE, "in the twelve-mile stretch between Memphis and Babylonia [= Old Cairo] are many pyramids, which Joseph made in order to store corn."[43] Ten years later the usage is confirmed in the anonymous travelogue of seven monks that set out from Jerusalem to visit the famous ascetics in Egypt, wherein they report that they "saw Joseph's granaries, where he stored grain in biblical times."[44] This late 4th century usage is further confirmed in the geographical treatise Cosmographia , written by Julius Honorius around 376 AD,[45] which explains that the Pyramids were called the "granaries of Joseph" (horrea Ioseph).[46] This reference from Julius is important, for it indicates that the identification was starting to spread out from pilgrim's travelogues. In 530 AD, Stephanos of Byzantium added more to this idea when he wrote in his Ethnica that the word "pyramid" was connected to the Greek word πυρός (puros), meaning wheat.[47]
In the seventh century AD, the Rashidun Caliphate conquered Egypt, ending several centuries of Romano-Byzantine rule. A few centuries later, in 820 AD, the Abbasid Caliph Al-Ma'mun (AD 786–833) is said to have tunneled into the side of the structure and discovered the ascending passage and its connecting chambers.[48] It was around this time that a Coptic legend gained popularity that claimed the antediluvian king Surid Ibn Salhouk was the one who built the Pyramid. One legend in particular relates how, three hundred years prior to the Great Flood, Surid had a terrifying dream of the world's end, and so he ordered the construction of the pyramids so that they might house all the knowledge of Egypt and survive into the present.[49] The most notable account of this legend was given by Al-Masudi (AD 896-956) in his Akbar al-zaman alongside imaginative tales about the pyramid, such as the story of a man who fell three hours down the pyramid's well and the tale of an expedition that discovered bizarre finds in the structure's inner chambers. The Akbar al-zaman also contains a report of Al-Ma'mun's entry into the pyramid, although the author adds that Al-Ma'mun discovered a vessel containing a thousand coins, which just so happened to account for the cost of opening the pyramid.[50] (Some speculate that this story is true, but that the coins were planted by Al-Ma'mun to appease his workers, who were likely frustrated that they had found no treasure.)[51]
In 987 AD, the Arab bibliographer Ibn al-Nadim relates a fantastical tale in his Al-Fihrist about a man who journeyed into the main chamber of a pyramid, which Bayard Dodge argues is the Great Pyramid.[52] According to al-Nadim, the person in question saw a statue of a man holding a tablet and a woman holding a mirror. Between the statues was supposedly a "stone vessel [with] a gold cover." Inside the vessel was "something like pitch," and when the explorer reached into the vessel "a gold receptacle happened to be inside." The receptacle, when taken from the vessel, was filled with "fresh blood," which quickly dried up. Ibn al-Nadim's work also claims that the bodies of a man and woman were discovered inside the Pyramid in "best possible state of preservation."[53] The author al-Kaisi, in his work the Tohfat Alalbab, retells the story of Al-Ma'mun's entry but notes that Al-Ma'mun also discovered "an image of a man in green stone," which when opened revealed a body dressed in jewel-encrusted gold armor. al-Kaisi's claims to have seen the case from which the body was taken, and asserts that it was located at the king's palace in Cairo. al-Kaisi also writes that he himself entered into the Pyramid and discovered myriad preserved bodies.[54]
The Arab polymath Abd al-Latif al-Baghdadi (1163-1231) studied the pyramid with great care, and in his Account of Egypt, he praises them of works of engineering genius. In addition to measuring the structure (and the other pyramids at Giza), al-Baghdadi also writes that the structures were surely tombs, although he thought it was used for the burial of Agathodaimon or Hermes. al-Baghdadi also discussed whether the pyramid pre-dated the Great flood as described in Genesis, and he even briefly entertained the idea that it was a pre-Adamic construction.[55][56] A few centuries later, the Islamic historian Al-Maqrizi (1364-1442) compiled up lore about the Pyramid in his Al-Khitat. In addition to further assertions that Al-Ma'mun breached the pyramid in 820 AD, Al-Maqrizi's work also discusses the sarcophagus in the coffin chambers, explicitly noting that the structure was a grave.[57] By the close of the Middle Ages, the Great Pyramid had gained a reputation as a haunted structure. Others feared the structure because the Pyramid was home to animals like bats.[58]
The Well Shaft (also known as the Service-, Air- or Vertical Shaft) links the lower end of the Grand Gallery to the bottom of Descending Passage, about 50 metres (160 ft) further down.
It doesn't take a direct course but changes angle several times. The upper half goes through the nucleus masonry of the pyramid. Vertical at first for 8 metres (26 ft) it then runs slightly angled southwards for about the same distance until it hits bedrock that is circa 5.7 metres (19 ft) above the pyramid's base level at this point. Another vertical section descents further which is partially lined with masonry that has been broken through to a cavity known as the Grotto. The lower half of the Well Shaft goes through the bedrock at an angle of about 45° for 26.5 metres (87 ft) before a steeper section, 9.5 metres (31 ft) long, leads to its lowest point. The final section of 2.6 metres (8.5 ft) connects it to the Descending Passage, running almost horizontal. The builders evidently had trouble aligning the lower exit.[124][61]
The purpose of the shaft is commonly explained as a ventilation shaft for the Subterranean Chamber and as a flight shaft for the workers who slid the blocking stones of the Ascending Passage into place.
The Grotto is a natural limestone cave, likely filled with sand and gravel before pyramid construction, that was later on hollowed out by looters. A granite block rests in it that likely originated from the portcullis that once sealed the King's Chamber.
Also at the start of the Grand Gallery, there is the Horizontal Passage leading to the "Queen's Chamber". At start, five pairs of holes suggest the tunnel was once concealed with slabs that laid flush with the gallery floor. The passage is 1.06 metres (3.5 ft) (2 cubits) wide and 1.17 metres (3.8 ft) high for most of its length, but near the chamber there is a step in the floor, after which the passage is 1.68 metres (5.5 ft) high.[61] Half of the west-wall consists of two layers that have atypically continuous vertical joints. Dormion suggests the entrances to magazines laid here, that were filled in.[125]
The "Queen's Chamber"[6] is exactly halfway between the north and south faces of the pyramid. It measures 10 cubits (north-south) by 11 cubits (east-west) or 5.23 metres (17.2 ft) by 5.77 metres (18.9 ft),[126] and has a pointed roof with an apex 12 cubits or 6.26 metres (20.5 ft)[127] above the floor. At the eastern end of the chamber there is a niche 9 cubits or 4.67 metres (15.3 ft) high. The original depth of the niche was 2 cubits or 1.04 metres (3.4 ft), but has since been deepened by treasure hunters.[128]
In the north and south walls of the Queen's Chamber there are shafts which were found in 1872 by a British engineer, Waynman Dixon, who believed shafts similar to those in the King's Chamber must also exist. The shafts were not connected to the outer faces of the pyramid or the Queen's Chamber; their purpose is unknown. In one shaft Dixon discovered a ball of diorite (a type of rock), a bronze hook of unknown purpose and piece of cedar wood. The first two objects are currently in the British Museum.[129] The latter was lost until recently when it was found at the University of Aberdeen. It has since been radiocarbon dated to 3341-3094 BC.[130] The northern shaft's angle of ascent fluctuates and at one point turns 45 degrees to avoid the Great Gallery. The southern is perpendicular to the pyramid's slope[129]
The shafts in the Queen's Chamber were explored in 1993 by the German engineer Rudolf Gantenbrink using a crawler robot he designed, Upuaut 2. After a climb of 65 m (213 ft),[131] he discovered that one of the shafts was blocked by a limestone "door" with two eroded copper "handles". The National Geographic Society created a similar robot which, in September 2002, drilled a small hole in the southern door only to find another stone slab behind it.[132] The northern passage, which was difficult to navigate because of its twists and turns, was also found to be blocked by a slab.[133]
Research continued in 2011 with the Djedi Project which used a fibre-optic "micro snake camera" that could see around corners. With this, they were able to penetrate the first door of the southern shaft through the hole drilled in 2002, and view all the sides of the small chamber behind it. They discovered hieroglyphics written in red paint. Egyptian mathematics researcher Luca Miatello stated that the markings read "121"- the length of the shaft in cubits.[134] The Djedi team were also able to scrutinize the inside of the two copper "handles" embedded in the door which they now believe to be for decorative purposes. They also found the reverse side of the "door" to be finished and polished which suggests that it was not put there just to block the shaft from debris, but rather for a more specific reason.[135]
The Grand Gallery continues the slope of the Ascending Passage towards the King's Chamber, extending from the 23rd to the 48th course, a rise of 21 metres (69 ft). It has been praised as a "truly spectacular example of stonemasonry".[136] It is 8.6 metres (28 ft) high and 46.68 metres (153.1 ft) long. The base is 4 cubits or 2.06 metres (6.8 ft) wide, but after two courses (at a height of 2.29 metres (7.5 ft)) the blocks of stone in the walls are corbelled inwards by 6–10 centimetres (2.4–3.9 in) on each side.[61] There are seven of these steps, so, at the top, the Grand Gallery is only 2 cubits or 1.04 metres (3.4 ft) wide. It is roofed by slabs of stone laid at a slightly steeper angle than the floor of the gallery so that each stone fits into a slot cut in the top of the gallery like the teeth of a ratchet. The purpose was to have each block supported by the wall of the Gallery, rather than resting on the block beneath it, in order to prevent cumulative pressure.[137]
At the upper end of the Gallery on the eastern wall, there is a hole near the roof that opens into a short tunnel by which access can be gained to the lowest of the Relieving Chambers.
The floor of the Grand Gallery has a shelf or step on either side, 1 cubit or 51 centimetres (20 in) wide, leaving a lower ramp 2 cubits or 1.04 metres (3.4 ft) wide between them. In the shelves, there are 56 slots, 28 on each side. On each wall, 25 niches have been cut above the slots.[138] The purpose of these slots is not known, but the central gutter in the floor of the Gallery, which is the same width as the Ascending Passage, has led to speculation that the blocking stones were stored in the Grand Gallery and the slots held wooden beams to restrain them from sliding down the passage.[139] Jean-Pierre Houdin theorized that they held a timber frame that was used in combination with a trolley to pull the heavy granite blocks up the pyramid.
At the top of the gallery, there is a step onto a small horizontal platform where a tunnel leads through the Antechamber, which was once blocked by portcullis stones, into the King's Chamber.The Eiffel Tower (/ˈaɪfəl/ EYE-fəl; French: tour Eiffel [tuʁ‿ɛfɛl] (About this soundlisten)) is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.
Locally nicknamed "La dame de fer" (French for "Iron Lady"), it was constructed from 1887 to 1889 as the entrance to the 1889 World's Fair and was initially criticised by some of France's leading artists and intellectuals for its design, but it has become a global cultural icon of France and one of the most recognisable structures in the world.[3] The Eiffel Tower is the most-visited paid monument in the world; 6.91 million people ascended it in 2015.
The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure in the world to surpass both the 200 meter and 300 meter mark in height. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.
The tower has three levels for visitors, with restaurants on the first and second levels. The top level's upper platform is 276 m (906 ft) above the ground – the highest observation deck accessible to the public in the European Union. Tickets can be purchased to ascend by stairs or lift to the first and second levels. The climb from ground level to the first level is over 300 steps, as is the climb from the first level to the second. Although there is a staircase to the top level, it is usually accessible only by lift.
The design of the Eiffel Tower is attributed to Maurice Koechlin and Émile Nouguier, two senior engineers working for the Compagnie des Établissements Eiffel. It was envisioned after discussion about a suitable centrepiece for the proposed 1889 Exposition Universelle, a world's fair to celebrate the centennial of the French Revolution. Eiffel openly acknowledged that inspiration for a tower came from the Latting Observatory built in New York City in 1853.[4] In May 1884, working at home, Koechlin made a sketch of their idea, described by him as "a great pylon, consisting of four lattice girders standing apart at the base and coming together at the top, joined together by metal trusses at regular intervals".[5] Eiffel initially showed little enthusiasm, but he did approve further study, and the two engineers then asked Stephen Sauvestre, the head of company's architectural department, to contribute to the design. Sauvestre added decorative arches to the base of the tower, a glass pavilion to the first level, and other embellishments.
Little progress was made until 1886, when Jules Grévy was re-elected as president of France and Édouard Lockroy was appointed as minister for trade. A budget for the exposition was passed and, on 1 May, Lockroy announced an alteration to the terms of the open competition being held for a centrepiece to the exposition, which effectively made the selection of Eiffel's design a foregone conclusion, as entries had to include a study for a 300 m (980 ft) four-sided metal tower on the Champ de Mars.[6] (A 300-metre tower was then considered a herculean engineering effort). On 12 May, a commission was set up to examine Eiffel's scheme and its rivals, which, a month later, decided that all the proposals except Eiffel's were either impractical or lacking in details.
After some debate about the exact location of the tower, a contract was signed on 8 January 1887. This was signed by Eiffel acting in his own capacity rather than as the representative of his company, and granted him 1.5 million francs toward the construction costs: less than a quarter of the estimated 6.5 million francs. Eiffel was to receive all income from the commercial exploitation of the tower during the exhibition and for the next 20 years. He later established a separate company to manage the tower, putting up half the necessary capital himself.[7]
Work on the foundations started on 28 January 1887.[16] Those for the east and south legs were straightforward, with each leg resting on four 2 m (6.6 ft) concrete slabs, one for each of the principal girders of each leg. The west and north legs, being closer to the river Seine, were more complicated: each slab needed two piles installed by using compressed-air caissons 15 m (49 ft) long and 6 m (20 ft) in diameter driven to a depth of 22 m (72 ft)[17] to support the concrete slabs, which were 6 m (20 ft) thick. Each of these slabs supported a block of limestone with an inclined top to bear a supporting shoe for the ironwork.
Each shoe was anchored to the stonework by a pair of bolts 10 cm (4 in) in diameter and 7.5 m (25 ft) long. The foundations were completed on 30 June, and the erection of the ironwork began. The visible work on-site was complemented by the enormous amount of exacting preparatory work that took place behind the scenes: the drawing office produced 1,700 general drawings and 3,629 detailed drawings of the 18,038 different parts needed.[18] The task of drawing the components was complicated by the complex angles involved in the design and the degree of precision required: the position of rivet holes was specified to within 1 mm (0.04 in) and angles worked out to one second of arc.[19] The finished components, some already riveted together into sub-assemblies, arrived on horse-drawn carts from a factory in the nearby Parisian suburb of Levallois-Perret and were first bolted together, with the bolts being replaced with rivets as construction progressed. No drilling or shaping was done on site: if any part did not fit, it was sent back to the factory for alteration. In all, 18,038 pieces were joined together using 2.5 million rivets.[16]
At first, the legs were constructed as cantilevers, but about halfway to the first level construction was paused to create a substantial timber scaffold. This renewed concerns about the structural integrity of the tower, and sensational headlines such as "Eiffel Suicide!" and "Gustave Eiffel Has Gone Mad: He Has Been Confined in an Asylum" appeared in the tabloid press.[20] At this stage, a small "creeper" crane designed to move up the tower was installed in each leg. They made use of the guides for the lifts which were to be fitted in the four legs. The critical stage of joining the legs at the first level was completed by the end of March 1888.[16] Although the metalwork had been prepared with the utmost attention to detail, provision had been made to carry out small adjustments to precisely align the legs; hydraulic jacks were fitted to the shoes at the base of each leg, capable of exerting a force of 800 tonnes, and the legs were intentionally constructed at a slightly steeper angle than necessary, being supported by sandboxes on the scaffold. Although construction involved 300 on-site employees,[16] due to Eiffel's safety precautions and the use of movable gangways, guardrails and screens, only one person died.[21]
Equipping the tower with adequate and safe passenger lifts was a major concern of the government commission overseeing the Exposition. Although some visitors could be expected to climb to the first level, or even the second, lifts clearly had to be the main means of ascent.[22]
Constructing lifts to reach the first level was relatively straightforward: the legs were wide enough at the bottom and so nearly straight that they could contain a straight track, and a contract was given to the French company Roux, Combaluzier & Lepape for two lifts to be fitted in the east and west legs.[23] Roux, Combaluzier & Lepape used a pair of endless chains with rigid, articulated links to which the car was attached. Lead weights on some links of the upper or return sections of the chains counterbalanced most of the car's weight. The car was pushed up from below, not pulled up from above: to prevent the chain buckling, it was enclosed in a conduit. At the bottom of the run, the chains passed around 3.9 m (12 ft 10 in) diameter sprockets. Smaller sprockets at the top guided the chains.[23]
Installing lifts to the second level was more of a challenge because a straight track was impossible. No French company wanted to undertake the work. The European branch of Otis Brothers & Company submitted a proposal but this was rejected: the fair's charter ruled out the use of any foreign material in the construction of the tower. The deadline for bids was extended but still no French companies put themselves forward, and eventually the contract was given to Otis in July 1887.[24] Otis were confident they would eventually be given the contract and had already started creating designs.[citation needed]
The car was divided into two superimposed compartments, each holding 25 passengers, with the lift operator occupying an exterior platform on the first level. Motive power was provided by an inclined hydraulic ram 12.67 m (41 ft 7 in) long and 96.5 cm (38.0 in) in diameter in the tower leg with a stroke of 10.83 m (35 ft 6 in): this moved a carriage carrying six sheaves. Five fixed sheaves were mounted higher up the leg, producing an arrangement similar to a block and tackle but acting in reverse, multiplying the stroke of the piston rather than the force generated. The hydraulic pressure in the driving cylinder was produced by a large open reservoir on the second level. After being exhausted from the cylinder, the water was pumped back up to the reservoir by two pumps in the machinery room at the base of the south leg. This reservoir also provided power to the lifts to the first level.[citation needed]
The original lifts for the journey between the second and third levels were supplied by Léon Edoux. A pair of 81 m (266 ft) hydraulic rams were mounted on the second level, reaching nearly halfway up to the third level. One lift car was mounted on top of these rams: cables ran from the top of this car up to sheaves on the third level and back down to a second car. Each car only travelled half the distance between the second and third levels and passengers were required to change lifts halfway by means of a short gangway. The 10-ton cars each held 65 passengers.[25]
The main structural work was completed at the end of March 1889 and, on 31 March, Eiffel celebrated by leading a group of government officials, accompanied by representatives of the press, to the top of the tower.[13] Because the lifts were not yet in operation, the ascent was made by foot, and took over an hour, with Eiffel stopping frequently to explain various features. Most of the party chose to stop at the lower levels, but a few, including the structural engineer, Émile Nouguier, the head of construction, Jean Compagnon, the President of the City Council, and reporters from Le Figaro and Le Monde Illustré, completed the ascent. At 2:35 pm, Eiffel hoisted a large Tricolour to the accompaniment of a 25-gun salute fired at the first level.[26]
There was still work to be done, particularly on the lifts and facilities, and the tower was not opened to the public until nine days after the opening of the exposition on 6 May; even then, the lifts had not been completed. The tower was an instant success with the public, and nearly 30,000 visitors made the 1,710-step climb to the top before the lifts entered service on 26 May.[27] Tickets cost 2 francs for the first level, 3 for the second, and 5 for the top, with half-price admission on Sundays,[28] and by the end of the exhibition there had been 1,896,987 visitors.[3]
For the 1900 Exposition Universelle, the lifts in the east and west legs were replaced by lifts running as far as the second level constructed by the French firm Fives-Lille. These had a compensating mechanism to keep the floor level as the angle of ascent changed at the first level, and were driven by a similar hydraulic mechanism to the Otis lifts, although this was situated at the base of the tower. Hydraulic pressure was provided by pressurised accumulators located near this mechanism.[24] At the same time the lift in the north pillar was removed and replaced by a staircase to the first level. The layout of both first and second levels was modified, with the space available for visitors on the second level. The original lift in the south pillar was removed 13 years later.[citation needed]
On 19 October 1901, Alberto Santos-Dumont, flying his No.6 airship, won a 100,000-franc prize offered by Henri Deutsch de la Meurthe for the first person to make a flight from St. Cloud to the Eiffel Tower and back in less than half an hour.[32]
Many innovations took place at the Eiffel Tower in the early 20th century. In 1910, Father Theodor Wulf measured radiant energy at the top and bottom of the tower. He found more at the top than expected, incidentally discovering what are known today as cosmic rays.[33] Just two years later, on 4 February 1912, Austrian tailor Franz Reichelt died after jumping from the first level of the tower (a height of 57 m) to demonstrate his parachute design.[34] In 1914, at the outbreak of World War I, a radio transmitter located in the tower jammed German radio communications, seriously hindering their advance on Paris and contributing to the Allied victory at the First Battle of the Marne.[35] From 1925 to 1934, illuminated signs for Citroën adorned three of the tower's sides, making it the tallest advertising space in the world at the time.[36] In April 1935, the tower was used to make experimental low-resolution television transmissions, using a shortwave transmitter of 200 watts power. On 17 November, an improved 180-line transmitter was installed.[37]
On two separate but related occasions in 1925, the con artist Victor Lustig "sold" the tower for scrap metal.[38] A year later, in February 1926, pilot Leon Collet was killed trying to fly under the tower. His aircraft became entangled in an aerial belonging to a wireless station.[39] A bust of Gustave Eiffel by Antoine Bourdelle was unveiled at the base of the north leg on 2 May 1929.[40] In 1930, the tower lost the title of the world's tallest structure when the Chrysler Building in New York City was completed.[41] In 1938, the decorative arcade around the first level was removed.[42]
Upon the German occupation of Paris in 1940, the lift cables were cut by the French. The tower was closed to the public during the occupation and the lifts were not repaired until 1946.[43] In 1940, German soldiers had to climb the tower to hoist a swastika-centered Reichskriegsflagge,[44] but the flag was so large it blew away just a few hours later, and was replaced by a smaller one.[45] When visiting Paris, Hitler chose to stay on the ground. When the Allies were nearing Paris in August 1944, Hitler ordered General Dietrich von Choltitz, the military governor of Paris, to demolish the tower along with the rest of the city. Von Choltitz disobeyed the order.[46] On 25 June, before the Germans had been driven out of Paris, the German flag was replaced with a Tricolour by two men from the French Naval Museum, who narrowly beat three men led by Lucien Sarniguet, who had lowered the Tricolour on 13 June 1940 when Paris fell to the Germans.[43]
A fire started in the television transmitter on 3 January 1956, damaging the top of the tower. Repairs took a year, and in 1957, the present radio aerial was added to the top.[47] In 1964, the Eiffel Tower was officially declared to be a historical monument by the Minister of Cultural Affairs, André Malraux.[48] A year later, an additional lift system was installed in the north pillar.[49]
According to interviews, in 1967, Montreal Mayor Jean Drapeau negotiated a secret agreement with Charles de Gaulle for the tower to be dismantled and temporarily relocated to Montreal to serve as a landmark and tourist attraction during Expo 67. The plan was allegedly vetoed by the company operating the tower out of fear that the French government could refuse permission for the tower to be restored in its original location.[50]
In 1982, the original lifts between the second and third levels were replaced after 97 years in service. These had been closed to the public between November and March because the water in the hydraulic drive tended to freeze. The new cars operate in pairs, with one counterbalancing the other, and perform the journey in one stage, reducing the journey time from eight minutes to less than two minutes. At the same time, two new emergency staircases were installed, replacing the original spiral staircases. In 1983, the south pillar was fitted with an electrically driven Otis lift to serve the Jules Verne restaurant.[citation needed] The Fives-Lille lifts in the east and west legs, fitted in 1899, were extensively refurbished in 1986. The cars were replaced, and a computer system was installed to completely automate the lifts. The motive power was moved from the water hydraulic system to a new electrically driven oil-filled hydraulic system, and the original water hydraulics were retained solely as a counterbalance system.[49] A service lift was added to the south pillar for moving small loads and maintenance personnel three years later.[citation needed]
Robert Moriarty flew a Beechcraft Bonanza under the tower on 31 March 1984.[51] In 1987, A.J. Hackett made one of his first bungee jumps from the top of the Eiffel Tower, using a special cord he had helped develop. Hackett was arrested by the police.[52] On 27 October 1991, Thierry Devaux, along with mountain guide Hervé Calvayrac, performed a series of acrobatic figures while bungee jumping from the second floor of the tower. Facing the Champ de Mars, Devaux used an electric winch between figures to go back up to the second floor. When firemen arrived, he stopped after the sixth jump.[53]
For its "Countdown to the Year 2000" celebration on 31 December 1999, flashing lights and high-powered searchlights were installed on the tower. During the last three minutes of the year, the lights were turned on starting from the base of the tower and continuing to the top to welcome 2000 with a huge fireworks show. An exhibition above a cafeteria on the first floor commemorates this event. The searchlights on top of the tower made it a beacon in Paris's night sky, and 20,000 flashing bulbs gave the tower a sparkly appearance for five minutes every hour on the hour.[54]
The lights sparkled blue for several nights to herald the new millennium on 31 December 2000. The sparkly lighting continued for 18 months until July 2001. The sparkling lights were turned on again on 21 June 2003, and the display was planned to last for 10 years before they needed replacing.[55]
The tower received its 200,000,000th guest on 28 November 2002.[56] The tower has operated at its maximum capacity of about 7 million visitors per year since 2003.[57] In 2004, the Eiffel Tower began hosting a seasonal ice rink on the first level.[58] A glass floor was installed on the first level during the 2014 refurbishment.[59]
In 2016, during Valentine's Day, the performance UN BATTEMENT [60] by French artist Milène Guermont unfolds among the Eiffel Tower, the Montparnasse Tower and the contemporary artwork PHARES installed on the Place de la Concorde. This interactive pyramid-shaped sculpture allows the public to transmit the beating of their hearts thanks to a cardiac sensor. The Eiffel Tower and the Montparnasse Tower also light up to the rhythm of PHARES. This is the first time that the Eiffel Tower has interacted with a work of art.[citation needed]
The Red Fort is a historic fort in the city of Delhi (in Old Delhi) in India that served as the main residence of the Mughal Emperors. Emperor Shah Jahan commissioned construction of the Red Fort on 12 May 1638, when he decided to shift his capital from Agra to Delhi. Originally red and white, its painting is credited to architect Ustad Ahmad Lahori, who also constructed the Taj Mahal. It was renovated between May 1639 and April 1648 based on an earlier fort.
On 15 August 1947, the first prime minister of India, Jawaharlal Nehru, raised the Indian national flag above the Lahori Gate.[1] Every year on India's Independence Day (15 August), the prime minister hoists the Indian tricolour flag at the fort's main gate and delivers a nationally broadcast speech from its ramparts.[2]Constructed in 1639 by the fifth Mughal Emperor Shah Jahan as the palace of his fortified capital Shahjahanabad, the Red Fort is named for its massive enclosing walls of red sandstone. The imperial apartments consist of a row of pavilions, connected by a water channel known as the Stream of Paradise (Nahr-i-Bihisht). The fort complex is "considered to represent the zenith of Mughal creativity under Shah Jahan",[7] and although the palace was planned according to Islamic prototypes, each pavilion contains architectural elements typical of Mughal buildings that reflect a fusion of Persian, Timurid and Hindu traditions.[8] The Red Fort's innovative architectural style, including its garden design, influenced later buildings and gardens in Delhi, Rajasthan, Punjab, Kashmir, Braj, Rohilkhand and elsewhere.[9]
The fort was plundered of its artwork and jewels during Nadir Shah's invasion of the Mughal Empire in 1747. Most of the fort's precious marble structures were subsequently destroyed by the British following the Revolt of 1857.[10] The fort's defensive walls were largely spared, and the fortress was subsequently used as a garrison.[10] It was designated a UNESCO World Heritage Site in 2007 as part of the Red Fort Complex.[9][11]
Emperor Shah Jahan commissioned construction of the Red Fort on 12 May 1638, when he decided to shift his capital from Agra to Delhi. Originally red and white, Shah Jahan's favourite colours,[12] its design is credited to architect Ustad Ahmad Lahori, who also constructed the Taj Mahal.[13][14] The fort lies along the Yamuna River, which fed the moats surrounding most of the walls.[15] Construction began in the sacred month of Muharram, on 13 May 1638.[16]:01 Supervised by Shah Jahan, it was completed on 6 April 1648.[17][18][19] Unlike other Mughal forts, the Red Fort's boundary walls are asymmetrical to contain the older Salimgarh Fort.[16]:04 The fortress-palace was a focal point of the city of Shahjahanabad, which is present-day Old Delhi. Shah Jahan's successor, Aurangzeb, added the Pearl Mosque to the emperor's private quarters, constructing barbicans in front of the two main gates to make the entrance to the palace more circuitous.[16]:08
The administrative and fiscal structure of the Mughal dynasty declined after Aurangzeb, and the 18th century saw a degeneration of the palace. When Jahandar Shah took over the Red Fort in 1712, it had been without an emperor for 30 years. Within a year of beginning his rule, Shah was murdered and replaced by Farrukhsiyar. Muhammad Shah, known as 'Rangila' (the Colourful) for his interest in art. In 1739, Persian emperor Nadir Shah easily defeated the Mughal army, plundering the Red Fort, including the Peacock Throne. Nadir Shah returned to Persia after three months, leaving a destroyed city and a weakened Mughal empire to Muhammad Shah.[16]:09 The internal weakness of the Mughal Empire made the Mughals only titular rulers of Delhi, and a 1752 treaty made the Marathas protectors of the throne at Delhi.[20][21] The 1758 Maratha victory at Sirhind aided by the Sikhs and successive defeat at Panipat[22] placed them in further conflict with Ahmad Shah Durrani.[23][24]
In 1760, the Marathas removed and melted the silver ceiling of the Diwan-i-Khas to raise funds for the defence of Delhi from the armies of Ahmed Shah Durrani.[25][26] In 1761, after the Marathas lost the third battle of Panipat, Delhi was raided by Ahmed Shah Durrani. Ten years later, the Marathas captured Delhi from the Afghans under the leadership of Mahadji Scindia and Peshwa Madhavrao and placed their puppet emperor Shah Alam II on the throne.[16]:10
In 1783 the Sikh Misl Karor Singhia, led by Baghel Singh, conquered Delhi and the Red Fort.[27] Baghel Singh, Jassa Singh Ahluwalia and Jassa Singh Ramgarhia all allied with a 40,000 force and plundered the area from Awadh to Jodhpur. They destroyed Mughal supremacy and made them pay Rakhi Tax of 4 lacks each month.
In 1788, a Maratha garrison occupied the Red fort and Delhi alongside providing protection to the Mughal Emperor. Mahadji Scindia signed a treaty with the Sikhs where they were warned not to enter Delhi or ask for the Rakhi tribute. The Marathas lost the fort to the British East India Company following the Second Anglo-Maratha War in 1803.[27]
During the Second Anglo-Maratha War, forces of British East India Company defeated Maratha forces of Daulat Rao Scindia in the Battle of Delhi; this ended Maratha rule of the city and their control of the Red Fort.[28] After the battle, the British took over the administration of Mughal territories and installed a Resident at the Red Fort.[16]:11 The last Mughal emperor to occupy the fort, Bahadur Shah II, became a symbol of the 1857 rebellion against the British in which the residents of Shahjahanbad participated.[16]:15
Despite its position as the seat of Mughal power and its defensive capabilities, the Red Fort was not defended during the 1857 uprising against the British. After the rebellion failed, Bahadur Shah II left the fort on 17 September and was apprehended by British forces. Bahadur Shah Zafar II returned to Red Fort as a British prisoner, was tried in 1858 and exiled to Rangoon on 7 October of that year.[29] With the end of Mughal reign, the British sanctioned the systematic plunder of valuables from the fort's palaces. All furniture was removed or destroyed; the harem apartments, servants' quarters and gardens were destroyed, and a line of stone barracks built.[10] Only the marble buildings on the east side at the imperial enclosure escaped complete destruction, although they were looted and damaged. While the defensive walls and towers were relatively unharmed, more than two-thirds of the inner structures were destroyed by the British.{cn}}
Lord Curzon, Viceroy of India from 1899 to 1905, ordered repairs to the fort including reconstruction of the walls and the restoration of the gardens complete with a watering system.[30]
Most of the jewels and artwork of the Red Fort were looted and stolen during Nadir Shah's invasion of 1747 and again after the Indian Rebellion of 1857 against the British. They were eventually sold to private collectors or the British Museum, British Library and the Victoria and Albert Museum. For example, the jade wine cup of Shah Jahan and the crown of Bahadur Shah II are all currently located in London. Various requests for restitution have so far been rejected by the British government.[31]
Every year on India's Independence Day (15 August), the prime minister of India hoists the national flag at the Red Fort and delivers a nationally broadcast speech from its ramparts.[2] The Red Fort, the largest monument in Delhi,[37] is one of its most popular tourist destinations[38] and attracts thousands of visitors every year.[39] A sound and light show describing Mughal history is a tourist attraction in the evenings. The major architectural features are in mixed condition; the extensive water features are dry. Some buildings are in fairly good condition, with their decorative elements undisturbed; in others, the marble inlaid flowers have been removed by looters. The tea house, although not in its historical state, is a working restaurant. The mosque and hamam or public baths are closed to the public, although visitors can peer through their glass windows or marble latticework. Walkways are crumbling, and public toilets are available at the entrance and inside the park. The Lahori Gate entrance leads to a mall with jewellery and craft stores. There is also a museum of "blood paintings", depicting young 20th-century Indian martyrs and their stories, an archaeological museum and an Indian war-memorial museum.
The Red fort appears on the back of the ₹500 note of the Mahatma Gandhi New Series of the Indian rupee.[40]
In April 2018, Dalmia Bharat Group adopted the Red Fort for maintenance, development, and operations,[41] per a contract worth ₹25 crores for a period of five years, under the government's "Adopt A Heritage" scheme.[42] The memorandum of understanding was signed with the ministries of tourism and culture and the Archaeological Survey of India (A.S.I.).[42] Following the deal, Dalmia took over control of the fort's light and sound show.[43] Under the contract, Dalmia will have to engage in development by restoring, landscaping, providing basic amenities, and arranging for battery operated cars, amongst other things.[44] It can charge visitors an admission fee following clearances from the ministries. That revenue will go towards the fort's maintenance and development.[44] Dalmia is not to be held liable under the contract if the A.S.I. or the Delhi district collector pursues claims against its work on the monument.[44] Dalmia's brand is also to be visible under the contract; it can have its name on souvenirs that are sold and on banners displayed during events at the fort.[44]
The adoption of the fort by a private group left people divided and drew criticism from the public, opposition political parties, and historians.[41] It also led to the #IndiaOnSale hashtag on Twitter.[41] In May 2018, the Indian History Congress called for the deal to be suspended until there is an "impartial review" of the deal "by the Central Advisory Board of Archaeology or any other recognised body of experts".[45]
During the CAA protests in December 2019, the Delhi Police imposed Section 144 of the CrPC around the Red Fort and detained a number of agitators near the fort area ahead of planned march against the new citizenship act.[46]
In 2021, a Farmers' Republic day parade was organized as part of the protest involving farmers from all over India, with a majority from Punjab and Haryana, after talks broke down with the government.[47][48][49][50] In the morning, protestors were diverted to smaller streets after leaving the agreed rally routes. The protests collided with the police and made their way to the center of Delhi. Some protestors entered the Red Fort premises, where they hoisted National Flag, Nishan Sahib (Sikh religious flag) and farmer union flags.[51] By the end of the day there were many injuries on both sides during the violent clashes.[52][53][47][54] This action stirred patriotic reactions in the Indian population both offline and on social media platforms.[55]
The Maratha Empire or the Maratha Confederacy was a power that dominated a large portion of the Indian subcontinent in the 18th century. The empire formally existed from 1674 with the coronation of Shivaji as the Chhatrapati and ended in 1818 with the defeat of Peshwa Bajirao II at the hands of the British East India Company. The Marathas are credited to a large extent for ending Mughal Rule over most of the Indian subcontinent.[4][5][6][note 1]
The Marathas were a Marathi-speaking warrior group from the western Deccan Plateau (present-day Maharashtra) who rose to prominence by establishing a Hindavi Swarajya (meaning "self-rule of Native Hindu/Indian people").[8][9] The Marathas became prominent in the 17th century under the leadership of Shivaji Maharaj, who revolted against the Adil Shahi dynasty, and carved out a kingdom with Raigad as his capital. His father, Shahji had earlier conquered Thanjavur which Shivaji's half-brother, Venkoji Rao alias Ekoji inherited and that Kingdom was known as the Thanjavur Maratha kingdom. Known for their mobility, the Marathas were able to consolidate their territory during the Mughal–Maratha Wars and later controlled a large part of the Indian subcontinent.
After the death of Aurangzeb in 1707, Shahu, grandson of Shivaji, was released by the Mughals.[10] Following a brief struggle with his aunt Tarabai, Shahu became the ruler with the help of Balaji Vishwanath and Dhanaji Jadhav. Pleased by his help, Shahu appointed Balaji Vishwanath and later, his descendants, as the peshwas or prime ministers of the empire.[11] Balaji and his descendants played a key role in the expansion of Maratha rule. The empire at its peak stretched from Tamil Nadu[12] in the south, to Peshawar (modern-day Khyber Pakhtunkhwa, Pakistan[13][note 2]) in the north, and Orissa & western Bengal up to the Hooghly River,[15] in the east. The Marathas discussed abolishing the Mughal throne and placing Vishwasrao Peshwa on the Mughal imperial throne in Delhi but were not able to do so.[16] In 1761, the Maratha Army lost the Third Battle of Panipat against Ahmad Shah Abdali of the Afghan Durrani Empire, which halted their imperial expansion into Afghanistan. Ten years after Panipat, the young Peshwa Madhavrao I's Maratha Resurrection reinstated Maratha authority over North India.
In a bid to effectively manage the large empire, Madhavrao gave semi-autonomy to the strongest of the knights, and created a confederacy of Maratha states. These leaders became known as the Gaekwads of Baroda, the Holkars of Indore and Malwa, the Scindias of Gwalior and Ujjain, the Bhonsales of Nagpur, the Meheres of Vidharbha, the Puars of Dhar and Dewas and the Newalkars of Jhansi. In 1775, the East India Company intervened in a Peshwa family succession struggle in Pune, which led to the First Anglo-Maratha War in which the Marathas emerged victorious.[17] The Marathas remained the pre-eminent power in India until their defeat in the Second and Third Anglo-Maratha Wars (1805–1818), which resulted in the East India Company seizing control of most of the Indian subcontinent.
A large portion of the Maratha empire was coastline, which had been secured by the potent Maratha Navy under commanders such as Kanhoji Angre. He was very successful at keeping foreign naval ships at bay, particularly those of the Portuguese and British.[18] Securing the coastal areas and building land-based fortifications were crucial aspects of the Maratha's defensive strategy and regional military history.
Shivaji (1627–1680) was a Maratha aristocrat of the Bhosale clan who is the founder of the Maratha empire.[4] Shivaji led a resistance to free the people from the Sultanate of Bijapur in 1645 by winning the fort Torna, followed by many more forts, placing the area under his control and establishing Hindavi Swarajya (self-rule of Hindu people[9]). He created an independent Maratha kingdom with Raigad as its capital[24] and successfully fought against the Mughals to defend his kingdom. He was crowned as Chhatrapati (sovereign) of the new Maratha kingdom in 1674.
The Maratha kingdom comprised about 4.1% of the subcontinent, but it was spread over large tracts. At the time of his death,[4] it was reinforced with about 300 forts, and defended by about 40,000 cavalries, and 50,000 soldiers, as well as naval establishments along the west coast. Over time, the kingdom would increase in size and heterogeneity;[25] by the time of his grandson's rule, and later under the Peshwas in the early 18th century, it was a full-fledged empire.[26]
Upon Sambhaji's death, his half-brother Rajaram ascended the throne. The Mughal siege of Raigad continued, and he had to flee to Vishalgad and then to Gingee for safety. From there, the Marathas raided Mughal territory, and many forts were recaptured by Maratha commanders such as Santaji Ghorpade, Dhanaji Jadhav, Parshuram Pant Pratinidhi, Shankaraji Narayan Sacheev and Melgiri Pandit. In 1697, Rajaram offered a truce but this was rejected by Aurangzeb. Rajaram died in 1700 at Sinhagad. His widow, Tarabai, assumed control in the name of her son, Ramaraja (Shivaji II). She led the Marathas against the Mughals, and by 1705 they had crossed the Narmada River and entered Malwa, then in Mughal possession.[citation needed]
After Aurangzeb's death in 1707, Shahu, the son of Sambhaji (and grandson of Shivaji), was released by Bahadur Shah I, the new Mughal emperor. However, his mother was kept as a hostage of the Mughals, in order to ensure that Shahu adhered to the release conditions. Upon release, Shahu immediately claimed the Maratha throne and challenged his aunt Tarabai and her son. The spluttering Mughal-Maratha war became a three-cornered affair. The states of Satara and Kolhapur were organised in 1707 because of the succession dispute over the Maratha kingship. Shahu appointed Balaji Vishwanath as Peshwa.[30] The Peshwa was instrumental in securing Mughal recognition of Shahu as the rightful heir of Shivaji and the Chatrapati of the Marathas.[30] Balaji also gained the release of Shahu's mother, Yesubai, from Mughal captivity in 1719.[31]
During Shahu's reign, Raghoji Bhosale expanded the empire Eastwards, reaching present-day Bengal. Khanderao Dabhade and later his son, Triambakrao, expanded it Westwards into Gujarat.[32] Peshwa Bajirao and his three chiefs, Pawar (Dhar), Holkar (Indore), and Scindia (Gwalior), expanded it Northwards up to Attock.In 1759, the Marathas under Sadashivrao Bhau (referred to as the Bhau or Bhao in sources) responded to the news of the Afghans' return to North India by sending a large army north. Bhau's force was bolstered by some Maratha forces under Holkar, Scindia, Gaikwad and Govind Pant Bundele. The combined army of over 100,000 regular troops re-captured the former Mughal capital, Delhi, from an Afghan garrison in August 1760.[47] Delhi had been reduced to ashes many times due to previous invasions, and there was an acute shortage of supplies in the Maratha camp. Bhau ordered the sacking of the already depopulated city.[46][48] He is said to have planned to place his nephew and the Peshwa's son, Vishwasrao, on the Mughal throne. By 1760, with defeat of the Nizam in the Deccan, Maratha power had reached its zenith with a territory of over 2,500,000 square miles (6,500,000 km2).[3]
Ahmad Shah Durrani called on the Rohillas and the Nawab of Oudh to assist him in driving out the Marathas from Delhi.[citation needed] Huge armies of Muslim forces and Marathas collided with each other on 14 January 1761 in the Third Battle of Panipat. The Maratha Army lost the battle, which halted their imperial expansion. The Jats and Rajputs did not support the Marathas. Historians have criticised the Maratha treatment of fellow Hindu groups. Kaushik Roy says "The treatment of Marathas with their co-religionist fellows – Jats and Rajputs was definitely unfair and ultimately they had to pay its price in Panipat where Muslim forces had united in the name of religion."[45] The Marathas had antagonised the Jats and Rajputs by taxing them heavily, punishing them after defeating the Mughals and interfering in their internal affairs[citation needed]. The Marathas were abandoned by Raja Suraj Mal of Bharatpur and the Rajputs, who quit the Maratha alliance at Agra before the start of the great battle and withdrew their troops as Maratha general Sadashivrao Bhau did not heed the advice to leave soldier's families (women and children) and pilgrims at Agra and not take them to the battle field with the soldiers, rejected their co-operation. Their supply chains (earlier assured by Raja Suraj Mal and Rajputs) did not exist.[citation needed]
In 1775, the British East India Company, from its base in Bombay, intervened in a succession struggle in Pune, on behalf of Raghunathrao (also called Raghobadada), who wanted to become Peshwa of the empire. Marathas forces under Tukojirao Holkar and Mahadaji Shinde defeated a British expeditionary force at the Battle of Wadgaon, but the heavy surrender terms, which included the return of annexed territory and a share of revenues, were disavowed by the British authorities at Bengal and fighting continued. What became known as the First Anglo-Maratha War ended in 1782 with a restoration of the pre-war status quo and the East India Company's abandonment of Raghunathrao's cause.[73]
In 1799, Yashwantrao Holkar was crowned King of the Holkars and he captured Ujjain. He started campaigning towards the north to expand his empire in that region. Yashwant Rao rebelled against the policies of Peshwa Baji Rao II. In May 1802, he marched towards Pune the seat of the Peshwa. This gave rise to the Battle of Poona in which the Peshwa was defeated. After the Battle of Poona, the flight of the Peshwa left the government of the Maratha state in the hands of Yashwantrao Holkar.(Kincaid & Pārasanīsa 1925, p. 194) He appointed Amrutrao as the Peshwa and went to Indore on 13 March 1803. All except Gaikwad, chief of Baroda, who had already accepted British protection by a separate treaty on 26 July 1802, supported the new regime. He made a treaty with the British. Also, Yashwant Rao successfully resolved the disputes with Scindia and the Peshwa. He tried to unite the Maratha Confederacy but to no avail. In 1802, the British intervened in Baroda to support the heir to the throne against rival claimants and they signed a treaty with the new Maharaja recognising his independence from the Maratha Empire in return for his acknowledgment of British paramountcy. Before the Second Anglo-Maratha War (1803–1805), the Peshwa Baji Rao II signed a similar treaty. The defeat in Battle of Delhi, 1803 during the Second Anglo-Maratha War resulted in the loss of the city of Delhi for the Marathas.[74]
The Second Anglo-Maratha War represents the military high-water mark of the Marathas who posed the last serious opposition to the formation of the British Raj. The real contest for India was never a single decisive battle for the subcontinent. Rather, it turned on a complex social and political struggle for the control of the South Asian military economy. The victory in 1803 hinged as much on finance, diplomacy, politics and intelligence as it did on battlefield maneuver and war itself.[72]
Ultimately, the Third Anglo-Maratha War (1817–1818) resulted in the loss of Maratha independence. It left the British in control of most of the Indian subcontinent. The Peshwa was exiled to Bithoor (Marat, near Kanpur, Uttar Pradesh) as a pensioner of the British. The Maratha heartland of Desh, including Pune, came under direct British rule, with the exception of the states of Kolhapur and Satara, which retained local Maratha rulers (descendants of Shivaji and Sambhaji II ruled over Kolhapur). The Maratha-ruled states of Gwalior, Indore, and Nagpur all lost territory and came under subordinate alliances with the British Raj as princely states that retained internal sovereignty under British paramountcy. Other small princely states of Maratha knights were retained under the British Raj as well.[citation needed]
The Maratha Empire, at its peak, encompassed a large area of the Indian sub-continent. Apart from capturing various regions, the Marathas maintained a large number of tributaries who were bounded by agreements to pay a certain amount of regular tax, known as Chauth. The empire defeated the Sultanate of Mysore under Hyder Ali and Tipu Sultan, the Nawab of Oudh, the Nawab of Bengal, the Nizam of Hyderabad and the Nawab of Arcot as well as the Polygar kingdoms of South India. They extracted chauth from the rulers in Delhi, Oudh, Bengal, Bihar, Odisha, Punjab, Hyderabad, Mysore, Uttar Pradesh and Rajputana.[84][85]
The Marathas were requested by Safdarjung, the Nawab of Oudh, in 1752 to help him defeat the Afghani Rohillas. The Maratha force set out from Pune and defeated the Afghan Rohillas in 1752, capturing the whole of Rohilkhand (present-day northwestern Uttar Pradesh).[46] In 1752, the Marathas entered into an agreement with the Mughal emperor, through his wazir, Safdarjung, and the Mughals gave the Marathas the chauth of Punjab, Sindh and Doab in addition to the subedari of Ajmer and Agra.[86] In 1758, Marathas started their north-west conquest and expanded their boundary till Afghanistan. They defeated Afghan forces of Ahmed Shah Abdali, in what is now Pakistan, including Pakistani Punjab Province and Khyber Pakhtunkhwa. The Afghans were numbered around 25,000–30,000 and were led by Timur Shah, the son of Ahmad Shah Durrani. The Marathas massacred and looted thousands of Afghan soldiers and captured Lahore, Multan, Dera Ghazi Khan, Attock, Peshawar in the Punjab region and Kashmir.[87]
During the confederacy era, Mahadji Shinde resurrected the Maratha domination on much of North India, which was lost after the Third battle of Panipat including the cis-Sutlej states (south of Sutlej) like Kaithal, Patiala, Jind, Thanesar, Maler Kotla and Faridkot. Delhi and Uttar Pradesh were under the suzerainty of the Scindhias of the Maratha Empire and following the Second Anglo-Maratha War of 1803–1805, the Marathas lost these territories to the British East India Company.[58][88]
Similarly, the Duke of Wellington, after defeating the Marathas, noted that the Marathas, though poorly led by their Generals, had regular infantry and artillery that matched the level of that of the Europeans and warned other British officers from underestimating the Marathas on the battlefield. He cautioned one British general that: "You must never allow Maratha infantry to attack head on or in close hand to hand combat as in that your army will cover itself with utter disgrace".[104] Even when Arthur Wellesley, 1st Duke of Wellington, became the Prime Minister of Britain, he held the Maratha infantry in utmost respect, claiming it to be one of the best in the world. However, at the same time he noted the poor leadership of Maratha Generals, who were often responsible for their defeats.
The Mughal Empire, Mogul or Moghul Empire, was an early modern empire in South Asia.[9] For some two centuries, the empire stretched from the outer fringes of the Indus basin in the west, northern Afghanistan in the northwest, and Kashmir in the north, to the highlands of present-day Assam and Bangladesh in the east, and the uplands of the Deccan plateau in south India.[10]
The Mughal empire is conventionally said to have been founded in 1526 by Babur, a warrior chieftain from what today is Uzbekistan, who employed aid from the neighbouring Safavid and Ottoman empires,[11] to defeat the Sultan of Delhi, Ibrahim Lodhi, in the First Battle of Panipat, and to sweep down the plains of Upper India. The Mughal imperial structure, however, is sometimes dated to 1600, to the rule of Babur's grandson, Akbar, [12] This imperial structure lasted until 1720, until shortly after the death of the last major emperor, Aurengzeb,[13][14] during whose reign the empire also achieved its maximum geographical extent. Reduced subsequently, especially during the East India Company rule in India, to the region in and around Old Delhi, the empire was formally dissolved by the British Raj after the Indian Rebellion of 1857.
Although the Mughal empire was created and sustained by military warfare,[15][16][17] it did not vigorously suppress the cultures and peoples it came to rule, but balanced them by establishing new administrative practices,[18][19] and incorporating diverse ruling elites, leading to more efficient, centralised, and standarized rule.[20] The base of the empire's collective wealth was agricultural taxes, instituted by the third Mughal emperor, Akbar.[21][22] These taxes, which amounted to well over half the output of a peasant cultivator,[23] were paid in the well-regulated silver currency,[24] and caused peasants and artisans to enter larger markets.[25]
The relative peace maintained by the empire during much of the 17th century was a factor in India's economic expansion.[26] Burgeoning European presence in the Indian ocean, and its increasing demand for Indian raw and finished products, created still greater wealth in the Mughal courts.[27] There was more conspicuous consumption among the Mughal elite,[28] resulting in greater patronage of painting, literary forms, textiles, and architecture, especially during the reign of Shah Jahan.[29] Among the Mughal UNESCO World Heritage Sites in South Asia are: Agra Fort, Fatehpur Sikri, Red Fort, Humayun's Tomb, Lahore Fort and the Taj Mahal, which is described as the "jewel of Muslim art in India and one of the universally admired masterpieces of the world's heritage."[30]The Mughal Empire was founded by Babur (reigned 1526–1530), a Central Asian ruler who was descended from the Turco-Mongol conqueror Timur (the founder of the Timurid Empire) on his father's side, and from Genghis Khan on his mother's side.[41] Ousted from his ancestral domains in Central Asia, Babur turned to India to satisfy his ambitions.[42] He established himself in Kabul and then pushed steadily southward into India from Afghanistan through the Khyber Pass.[41] Babur's forces occupied much of northern India after his victory at Panipat in 1526.[41] The preoccupation with wars and military campaigns, however, did not allow the new emperor to consolidate the gains he had made in India.[43]
The instability of the empire became evident under his son, Humayun (reigned 1530–1556), who was forced into exile in Persia by rebels. The Sur Empire (1540–1555), founded by Sher Shah Suri (reigned 1540–1545), briefly interrupted Mughal rule.[41] Humayun's exile in Persia established diplomatic ties between the Safavid and Mughal Courts, and led to increasing Persian cultural influence in the Mughal Empire.[citation needed] Humayun's triumphant return from Persia in 1555 restored Mughal rule, but he died in an accident the next year.[41]
Akbar (reigned 1556–1605) was born Jalal-ud-din Muhammad[44] in the Rajput Umarkot Fort,[45] to Humayun and his wife Hamida Banu Begum, a Persian princess.[46] Akbar succeeded to the throne under a regent, Bairam Khan, who helped consolidate the Mughal Empire in India. Through warfare and diplomacy, Akbar was able to extend the empire in all directions and controlled almost the entire Indian subcontinent north of the Godavari River.[citation needed] He created a new ruling elite loyal to him, implemented a modern administration, and encouraged cultural developments. He increased trade with European trading companies.[41] India developed a strong and stable economy, leading to commercial expansion and economic development.[citation needed] Akbar allowed freedom of religion at his court, and attempted to resolve socio-political and cultural differences in his empire by establishing a new religion, Din-i-Ilahi, with strong characteristics of a ruler cult.[41] He left his son an internally stable state, which was in the midst of its golden age, but before long signs of political weakness would emerge.[41]
Jahangir (born Salim,[47] reigned 1605–1627) was born to Akbar and his wife Mariam-uz-Zamani, an Indian Rajput princess.[48] He "was addicted to opium, neglected the affairs of the state, and came under the influence of rival court cliques".[41] Jahangir delibrately distinguished himself from Akbar, and made substantial efforts to harness the support of the Islamic religious establishment, granting them great tracts of land as madad-i ma'ash holders.[49] In contrast to Akbar, Jahangir came into conflict with non-Muslim religious leaders, notably the Sikh guru Arjan, whose execution was the first of many conflicts between the Mughal empire and the Sikh community.[50][51][52]
Shah Jahan's eldest son, the liberal Dara Shikoh, became regent in 1658, as a result of his father's illness.[citation needed] Dara championed a syncretistic Hindu-Muslim culture. With the support of the Islamic orthodoxy, however, a younger son of Shah Jahan, Aurangzeb (reigned 1658–1707), seized the throne. Aurangzeb defeated Dara in 1659 and had him executed.[41] Although Shah Jahan fully recovered from his illness, Aurangzeb declared him incompetent to rule, and kept Shah Jahan imprisoned until his death in 1666.[54]:68 During Aurangzeb's reign, the empire gained political strength once more and became the world's most powerful economy.[citation needed] Aurangzeb oversaw an increase in the Islamicization of the Mughal state. He encouraged conversion to Islam, reinstated the jizya on non-Muslims, and compiled the Fatwa Alamgiri, a collection of Islamic law. Aurangzeb also executed the Sikh guru Tegh Bahadur, leading to the militarization of the Sikh community.[55][51][52] He expanded the empire to include almost the whole of South Asia,[54]:1 but at his death in 1707, "many parts of the empire were in open revolt".[41] Aurangzeb is considered India's most controversial king,[54] with some historians[weasel words] arguing his religious conservatism and intolerance undermined the stability of Mughal society,[41] while other historians question this, noting that he built Hindu temples,[56] employed significantly more Hindus in his imperial bureaucracy than his predecessors did, opposed bigotry against Hindus and Shia Muslims,[54]:50 and married Hindu Rajput princess Nawab Bai.[47]
Aurangzeb's son, Bahadur Shah I, repealed the religious policies of his father and attempted to reform the administration. "However, after his death in 1712, the Mughal dynasty sank into chaos and violent feuds. In 1719 alone, four emperors successively ascended the throne".[41]
During the reign of Muhammad Shah (reigned 1719–1748), the empire began to break up, and vast tracts of central India passed from Mughal to Maratha hands. The far-off Indian campaign of Nadir Shah, who had previously reestablished Iranian suzerainty over most of West Asia, the Caucasus, and Central Asia, culminated with the Sack of Delhi and shattered the remnants of Mughal power and prestige. Many of the empire's elites now sought to control their own affairs, and broke away to form independent kingdoms.[citation needed] But, according to Sugata Bose and Ayesha Jalal, the Mughal Emperor continued to be the highest manifestation of sovereignty. Not only the Muslim gentry, but the Maratha, Hindu, and Sikh leaders took part in ceremonial acknowledgments of the emperor as the sovereign of India.[57]
Meanwhile, some regional polities within the increasingly fragmented Mughal Empire, involved themselves and the state in global conflicts, leading only to defeat and loss of territory during the Carnatic Wars and the Bengal War.
The Mughal Emperor Shah Alam II (1759–1806) made futile attempts to reverse the Mughal decline but ultimately had to seek the protection of the Emir of Afghanistan, Ahmed Shah Abdali, which led to the Third Battle of Panipat between the Maratha Empire and the Afghans (led by Abdali) in 1761. In 1771, the Marathas recaptured Delhi from Afghan control and in 1784 they officially became the protectors of the emperor in Delhi,[58] a state of affairs that continued until the Second Anglo-Maratha War. Thereafter, the British East India Company became the protectors of the Mughal dynasty in Delhi.[57] The British East India Company took control of the former Mughal province of Bengal-Bihar in 1793 after it abolished local rule (Nizamat) that lasted until 1858, marking the beginning of British colonial era over the Indian Subcontinent. By 1857 a considerable part of former Mughal India was under the East India Company's control. After a crushing defeat in the war of 1857–1858 which he nominally led, the last Mughal, Bahadur Shah Zafar, was deposed by the British East India Company and exiled in 1858. Through the Government of India Act 1858 the British Crown assumed direct control of East India Company-held territories in India in the form of the new British Raj. In 1876 the British Queen Victoria assumed the title of Empress of India.
Historians have offered numerous explanations for the rapid collapse of the Mughal Empire between 1707 and 1720, after a century of growth and prosperity. In fiscal terms, the throne lost the revenues needed to pay its chief officers, the emirs (nobles) and their entourages. The emperor lost authority, as the widely scattered imperial officers lost confidence in the central authorities, and made their own deals with local men of influence. The imperial army bogged down in long, futile wars against the more aggressive Marathas, lost its fighting spirit. Finally came a series of violent political feuds over control of the throne. After the execution of Emperor Farrukhsiyar in 1719, local Mughal successor states took power in region after region.[59]
Contemporary chroniclers bewailed the decay they witnessed, a theme picked up by the first British historians who wanted to underscore the need for a British-led rejuvenation.[60]
Since the 1970s historians have taken multiple approaches to the decline, with little consensus on which factor was dominant. The psychological interpretations emphasise depravity in high places, excessive luxury, and increasingly narrow views that left the rulers unprepared for an external challenge. A Marxist school (led by Irfan Habib and based at Aligarh Muslim University) emphasises excessive exploitation of the peasantry by the rich, which stripped away the will and the means to support the regime.[61] Karen Leonard has focused on the failure of the regime to work with Hindu bankers, whose financial support was increasingly needed; the bankers then helped the Maratha and the British.[62] In a religious interpretation, some scholars argue that the Hindu powers revolted against the rule of a Muslim dynasty.[63] Finally, other scholars argue that the very prosperity of the Empire inspired the provinces to achieve a high degree of independence, thus weakening the imperial court.[64]
Jeffrey G. Williamson has argued that the Indian economy went through deindustrialization in the latter half of the 18th century as an indirect outcome of the collapse of the Mughal Empire, with British rule later causing further deindustrialization.[65] According to Williamson, the decline of the Mughal Empire led to a decline in agricultural productivity, which drove up food prices, then nominal wages, and then textile prices, which led to India losing a share of the world textile market to Britain even before it had superior factory technology.[66] Indian textiles, however, still maintained a competitive advantage over British textiles up until the 19th century.[67]
The largest manufacturing industry in the Mughal Empire was textile manufacturing, particularly cotton textile manufacturing, which included the production of piece goods, calicos, and muslins, available unbleached and in a variety of colours. The cotton textile industry was responsible for a large part of the empire's international trade.[69] India had a 25% share of the global textile trade in the early 18th century.[96] Indian cotton textiles were the most important manufactured goods in world trade in the 18th century, consumed across the world from the Americas to Japan.[97] By the early 18th century, Mughal Indian textiles were clothing people across the Indian subcontinent, Southeast Asia, Europe, the Americas, Africa, and the Middle East.[66] The most important center of cotton production was the Bengal province, particularly around its capital city of Dhaka.[98]
Bengal accounted for more than 50% of textiles and around 80% of silks imported by the Dutch from Asia,[95] Bengali silk and cotton textiles were exported in large quantities to Europe, Indonesia, and Japan,[8]:202 and Bengali muslin textiles from Dhaka were sold in Central Asia, where they were known as "daka" textiles.[98] Indian textiles dominated the Indian Ocean trade for centuries, were sold in the Atlantic Ocean trade, and had a 38% share of the West African trade in the early 18th century, while Indian calicos were a major force in Europe, and Indian textiles accounted for 20% of total English trade with Southern Europe in the early 18th century.[65]
The worm gear roller cotton gin, which was invented in India during the early Delhi Sultanate era of the 13th–14th centuries, came into use in the Mughal Empire sometime around the 16th century,[92] and is still used in India through to the present day.[99] Another innovation, the incorporation of the crank handle in the cotton gin, first appeared in India sometime during the late Delhi Sultanate or the early Mughal Empire.[100] The production of cotton, which may have largely been spun in the villages and then taken to towns in the form of yarn to be woven into cloth textiles, was advanced by the diffusion of the spinning wheel across India shortly before the Mughal era, lowering the costs of yarn and helping to increase demand for cotton. The diffusion of the spinning wheel, and the incorporation of the worm gear and crank handle into the roller cotton gin led to greatly expanded Indian cotton textile production during the Mughal era.[101]
The Bengal Subah province was especially prosperous from the time of its takeover by the Mughals in 1590 until the British East India Company seized control in 1757.[105] It was the Mughal Empire's wealthiest province.[106] Domestically, much of India depended on Bengali products such as rice, silks and cotton textiles. Overseas, Europeans depended on Bengali products such as cotton textiles, silks, and opium; Bengal accounted for 40% of Dutch imports from Asia, for example, including more than 50% of textiles and around 80% of silks.[95] From Bengal, saltpeter was also shipped to Europe, opium was sold in Indonesia, raw silk was exported to Japan and the Netherlands, and cotton and silk textiles were exported to Europe, Indonesia and Japan.[8] Akbar played a key role in establishing Bengal as a leading economic centre, as he began transforming many of the jungles there into farms. As soon as he conquered the region, he brought tools and men to clear jungles in order to expand cultivation and brought Sufis to open the jungles to farming.[89] Bengal was later described as the Paradise of Nations by Mughal emperors.[107] The Mughals introduced agrarian reforms, including the modern Bengali calendar.[108] The calendar played a vital role in developing and organising harvests, tax collection and Bengali culture in general, including the New Year and Autumn festivals. The province was a leading producer of grains, salt, fruits, liquors and wines, precious metals and ornaments.[109][page needed] Its handloom industry flourished under royal warrants, making the region a hub of the worldwide muslin trade, which peaked in the 17th and 18th centuries. The provincial capital Dhaka became the commercial capital of the empire. The Mughals expanded cultivated land in the Bengal delta under the leadership of Sufis, which consolidated the foundation of Bengali Muslim society.[110][page needed]
According to Irfan Habib Cities and towns boomed under the Mughal Empire, which had a relatively high degree of urbanization for its time, with 15% of its population living in urban centres.[115] This was higher than the percentage of the urban population in contemporary Europe at the time and higher than that of British India in the 19th century;[115] the level of urbanization in Europe did not reach 15% until the 19th century.[116]
Under Akbar's reign in 1600, the Mughal Empire's urban population was up to 17 million people, 15% of the empire's total population. This was larger than the entire urban population in Europe at the time, and even a century later in 1700, the urban population of England, Scotland and Wales did not exceed 13% of its total population,[113] while British India had an urban population that was under 13% of its total population in 1800 and 9% in 1881, a decline from the earlier Mughal era.[117] By 1700, Mughal India had an urban population of 23 million people, larger than British India's urban population of 22.3 million in 1871.[118]
Those estimates were criticized by Tim Dyson, who consider them exaggerations. According to Dyson urbanization of Mughal empire was less then 9%[119]
The historian Nizamuddin Ahmad (1551–1621) reported that, under Akbar's reign, there were 120 large cities and 3200 townships.[115] A number of cities in India had a population between a quarter-million and half-million people,[115] with larger cities including Agra (in Agra Subah) with up to 800,000 people, Lahore (in Lahore Subah) with up to 700,000 people,[120] Dhaka (in Bengal Subah) with over 1 million people,[121] and Delhi (in Delhi Subah) with over 600,000 people.[122]
Cities acted as markets for the sale of goods, and provided homes for a variety of merchants, traders, shopkeepers, artisans, moneylenders, weavers, craftspeople, officials, and religious figures.[69] However, a number of cities were military and political centres, rather than manufacturing or commerce centres.[123]
The name Alexander is derived from the Greek: Ἀλέξανδρος (Aléxandros; 'Defender of the people', 'Defending men',[2] or 'Protector of men'). It is a compound of the verb ἀλέξειν (aléxein; 'to ward off, avert, defend')[3] and the noun ἀνήρ (anḗr, genitive: ἀνδρός, andrós; meaning 'man').[4] It is an example of the widespread motif of Greek names expressing "battle-prowess", in this case the ability to withstand or push back an enemy battle line.[citation needed]
The earliest attested form of the name is the Mycenaean Greek feminine anthroponym 𐀀𐀩𐀏𐀭𐀅𐀨, a-re-ka-sa-da-ra, (/Alexandra/), written in the Linear B syllabic script.[5][6][7] Alaksandu, alternatively called Alakasandu or Alaksandus, was a king of Wilusa who sealed a treaty with the Hittite king Muwatalli II ca. 1280 BC; this is generally assumed to have been a Greek called Alexandros.
The name was one of the epithets given to the Greek goddess Hera and as such is usually taken to mean "one who comes to save warriors". In the Iliad, the character Paris is known also as Alexander.[8] The name's popularity was spread throughout the Greek world by the military conquests of King Alexander III, commonly known as "Alexander the Great". Most later Alexanders in various countries were directly or indirectly named after him.[9][citation needed]
Alexander III of Macedon (Greek: Αλέξανδρος, Aléxandros; 20/21 July 356 BC – 10/11 June 323 BC), commonly known as Alexander the Great, was a king (basileus) of the ancient Greek kingdom of Macedon[a] and a member of the Argead dynasty. He was born in Pella in 356 BC and succeeded his father Philip II to the throne at the age of 20. He spent most of his ruling years on an unprecedented military campaign through Western Asia and Northeastern Africa, and by the age of thirty, he had created one of the largest empires in history, stretching from Greece to northwestern India.[1][2] He was undefeated in battle and is widely considered one of history's most successful military commanders.[3]
During his youth, Alexander was tutored by Aristotle until age 16. After Philip's assassination in 336 BC, he succeeded his father to the throne and inherited a strong kingdom and an experienced army. Alexander was awarded the generalship of Greece and used this authority to launch his father's pan-Hellenic project to lead the Greeks in the conquest of Persia.[4][5] In 334 BC, he invaded the Achaemenid Empire (Persian Empire) and began a series of campaigns that lasted 10 years. Following the conquest of Anatolia, Alexander broke the power of Persia in a series of decisive battles, including those of Issus and Gaugamela. He subsequently overthrew Persian King Darius III and conquered the Achaemenid Empire in its entirety.[b] At that point, his empire stretched from the Adriatic Sea to the Beas River.
Alexander endeavoured to reach the "ends of the world and the Great Outer Sea" and invaded India in 326 BC, winning an important victory over the Pauravas at the Battle of the Hydaspes. He eventually turned back at the demand of his homesick troops, dying in Babylon in 323 BC, the city that he planned to establish as his capital, without executing a series of planned campaigns that would have begun with an invasion of Arabia. In the years following his death, a series of civil wars tore his empire apart, resulting in the establishment of several states ruled by the Diadochi, Alexander's surviving generals and heirs.
Alexander's legacy includes the cultural diffusion and syncretism which his conquests engendered, such as Greco-Buddhism. He founded some twenty cities that bore his name, most notably Alexandria in Egypt. Alexander's settlement of Greek colonists and the resulting spread of Greek culture in the east resulted in a new Hellenistic civilization, aspects of which were still evident in the traditions of the Byzantine Empire in the mid-15th century AD and the presence of Greek speakers in central and far eastern Anatolia until the Greek genocide and the population exchange in the 1920s. Alexander became legendary as a classical hero in the mould of Achilles, and he features prominently in the history and mythic traditions of both Greek and non-Greek cultures. He was undefeated in battle and has become the measure against which many military leaders compare themselves.[c] Military academies throughout the world still teach his tactics.[6] He is often ranked among the most influential people in human history.[7][8]
Alexander was born in Pella, the capital of the Kingdom of Macedon,[9] on the sixth day of the ancient Greek month of Hekatombaion, which probably corresponds to 20 July 356 BC, although the exact date is uncertain.[10] He was the son of the king of Macedon, Philip II, and his fourth wife, Olympias, the daughter of Neoptolemus I, king of Epirus.[11] Although Philip had seven or eight wives, Olympias was his principal wife for some time, likely because she gave birth to Alexander.[12]
Several legends surround Alexander's birth and childhood.[13] According to the ancient Greek biographer Plutarch, on the eve of the consummation of her marriage to Philip, Olympias dreamed that her womb was struck by a thunderbolt that caused a flame to spread "far and wide" before dying away. Sometime after the wedding, Philip is said to have seen himself, in a dream, securing his wife's womb with a seal engraved with a lion's image.[14] Plutarch offered a variety of interpretations of these dreams: that Olympias was pregnant before her marriage, indicated by the sealing of her womb; or that Alexander's father was Zeus. Ancient commentators were divided about whether the ambitious Olympias promulgated the story of Alexander's divine parentage, variously claiming that she had told Alexander, or that she dismissed the suggestion as impious.[14]
On the day Alexander was born, Philip was preparing a siege on the city of Potidea on the peninsula of Chalcidice. That same day, Philip received news that his general Parmenion had defeated the combined Illyrian and Paeonian armies and that his horses had won at the Olympic Games. It was also said that on this day, the Temple of Artemis in Ephesus, one of the Seven Wonders of the World, burnt down. This led Hegesias of Magnesia to say that it had burnt down because Artemis was away, attending the birth of Alexander.[15] Such legends may have emerged when Alexander was king, and possibly at his instigation, to show that he was superhuman and destined for greatness from conception.[13]
In his early years, Alexander was raised by a nurse, Lanike, sister of Alexander's future general Cleitus the Black. Later in his childhood, Alexander was tutored by the strict Leonidas, a relative of his mother, and by Lysimachus of Acarnania.[16] Alexander was raised in the manner of noble Macedonian youths, learning to read, play the lyre, ride, fight, and hunt.[17]
At the age of 16, Alexander's education under Aristotle ended. Philip waged war against Byzantion, leaving Alexander in charge as regent and heir apparent.[13] During Philip's absence, the Thracian Maedi revolted against Macedonia. Alexander responded quickly, driving them from their territory. He colonized it with Greeks, and founded a city named Alexandropolis.[30]
Upon Philip's return, he dispatched Alexander with a small force to subdue revolts in southern Thrace. Campaigning against the Greek city of Perinthus, Alexander is reported to have saved his father's life. Meanwhile, the city of Amphissa began to work lands that were sacred to Apollo near Delphi, a sacrilege that gave Philip the opportunity to further intervene in Greek affairs. Still occupied in Thrace, he ordered Alexander to muster an army for a campaign in southern Greece. Concerned that other Greek states might intervene, Alexander made it look as though he was preparing to attack Illyria instead. During this turmoil, the Illyrians invaded Macedonia, only to be repelled by Alexander.[31]
Philip and his army joined his son in 338 BC, and they marched south through Thermopylae, taking it after stubborn resistance from its Theban garrison. They went on to occupy the city of Elatea, only a few days' march from both Athens and Thebes. The Athenians, led by Demosthenes, voted to seek alliance with Thebes against Macedonia. Both Athens and Philip sent embassies to win Thebes's favour, but Athens won the contest.[32] Philip marched on Amphissa (ostensibly acting on the request of the Amphictyonic League), capturing the mercenaries sent there by Demosthenes and accepting the city's surrender. Philip then returned to Elatea, sending a final offer of peace to Athens and Thebes, who both rejected it.[33]
As Philip marched south, his opponents blocked him near Chaeronea, Boeotia. During the ensuing Battle of Chaeronea, Philip commanded the right wing and Alexander the left, accompanied by a group of Philip's trusted generals. According to the ancient sources, the two sides fought bitterly for some time. Philip deliberately commanded his troops to retreat, counting on the untested Athenian hoplites to follow, thus breaking their line. Alexander was the first to break the Theban lines, followed by Philip's generals. Having damaged the enemy's cohesion, Philip ordered his troops to press forward and quickly routed them. With the Athenians lost, the Thebans were surrounded. Left to fight alone, they were defeated.[34]
After the victory at Chaeronea, Philip and Alexander marched unopposed into the Peloponnese, welcomed by all cities; however, when they reached Sparta, they were refused, but did not resort to war.[35] At Corinth, Philip established a "Hellenic Alliance" (modelled on the old anti-Persian alliance of the Greco-Persian Wars), which included most Greek city-states except Sparta. Philip was then named Hegemon (often translated as "Supreme Commander") of this league (known by modern scholars as the League of Corinth), and announced his plans to attack the Persian Empire.[36][37]
Alexander began his reign by eliminating potential rivals to the throne. He had his cousin, the former Amyntas IV, executed.[50] He also had two Macedonian princes from the region of Lyncestis killed, but spared a third, Alexander Lyncestes. Olympias had Cleopatra Eurydice and Europa, her daughter by Philip, burned alive. When Alexander learned about this, he was furious. Alexander also ordered the murder of Attalus,[50] who was in command of the advance guard of the army in Asia Minor and Cleopatra's uncle.[51]
Attalus was at that time corresponding with Demosthenes, regarding the possibility of defecting to Athens. Attalus also had severely insulted Alexander, and following Cleopatra's murder, Alexander may have considered him too dangerous to leave alive.[51] Alexander spared Arrhidaeus, who was by all accounts mentally disabled, possibly as a result of poisoning by Olympias.[47][49][52]
News of Philip's death roused many states into revolt, including Thebes, Athens, Thessaly, and the Thracian tribes north of Macedon. When news of the revolts reached Alexander, he responded quickly. Though advised to use diplomacy, Alexander mustered 3,000 Macedonian cavalry and rode south towards Thessaly. He found the Thessalian army occupying the pass between Mount Olympus and Mount Ossa, and ordered his men to ride over Mount Ossa. When the Thessalians awoke the next day, they found Alexander in their rear and promptly surrendered, adding their cavalry to Alexander's force. He then continued south towards the Peloponnese.[53]
Alexander stopped at Thermopylae, where he was recognized as the leader of the Amphictyonic League before heading south to Corinth. Athens sued for peace and Alexander pardoned the rebels. The famous encounter between Alexander and Diogenes the Cynic occurred during Alexander's stay in Corinth. When Alexander asked Diogenes what he could do for him, the philosopher disdainfully asked Alexander to stand a little to the side, as he was blocking the sunlight.[54] This reply apparently delighted Alexander, who is reported to have said "But verily, if I were not Alexander, I would like to be Diogenes."[55] At Corinth, Alexander took the title of Hegemon ("leader") and, like Philip, was appointed commander for the coming war against Persia. He also received news of a Thracian uprising.[56]
Before crossing to Asia, Alexander wanted to safeguard his northern borders. In the spring of 335 BC, he advanced to suppress several revolts. Starting from Amphipolis, he travelled east into the country of the "Independent Thracians"; and at Mount Haemus, the Macedonian army attacked and defeated the Thracian forces manning the heights.[57] The Macedonians marched into the country of the Triballi, and defeated their army near the Lyginus river[58] (a tributary of the Danube). Alexander then marched for three days to the Danube, encountering the Getae tribe on the opposite shore. Crossing the river at night, he surprised them and forced their army to retreat after the first cavalry skirmish.[59]
News then reached Alexander that Cleitus, King of Illyria, and King Glaukias of the Taulantii were in open revolt against his authority. Marching west into Illyria, Alexander defeated each in turn, forcing the two rulers to flee with their troops. With these victories, he secured his northern frontier.[60]
While Alexander campaigned north, the Thebans and Athenians rebelled once again. Alexander immediately headed south.[61] While the other cities again hesitated, Thebes decided to fight. The Theban resistance was ineffective, and Alexander razed the city and divided its territory between the other Boeotian cities. The end of Thebes cowed Athens, leaving all of Greece temporarily at peace.[61] Alexander then set out on his Asian campaign, leaving Antipater as regent.[62]
According to ancient writers Demosthenes called Alexander "Margites" (Greek: Μαργίτης)[63][64][65] and a boy.[65] Greeks used the word Margites to describe fool and useless people, on account of the Margites.[64][66]
After his victory at the Battle of Chaeronea (338 BC), Philip II began the work of establishing himself as hēgemṓn (Greek: ἡγεμών) of a league which according to Diodorus was to wage a campaign against the Persians for the sundry grievances Greece suffered in 480 and free the Greek cities of the western coast and islands from Achaemenid rule. In 336 he sent Parmenion, with Amyntas, Andromenes and Attalus, and an army of 10,000 men into Anatolia to make preparations for an invasion.[67][68] At first, all went well. The Greek cities on the western coast of Anatolia revolted until the news arrived that Philip had been murdered and had been succeeded by his young son Alexander. The Macedonians were demoralized by Philip's death and were subsequently defeated near Magnesia by the Achaemenids under the command of the mercenary Memnon of Rhodes.[67][68]
Taking over the invasion project of Philip II, Alexander's army crossed the Hellespont in 334 BC with approximately 48,100 soldiers, 6,100 cavalry and a fleet of 120 ships with crews numbering 38,000,[61] drawn from Macedon and various Greek city-states, mercenaries, and feudally raised soldiers from Thrace, Paionia, and Illyria.[69][f] He showed his intent to conquer the entirety of the Persian Empire by throwing a spear into Asian soil and saying he accepted Asia as a gift from the gods. This also showed Alexander's eagerness to fight, in contrast to his father's preference for diplomacy.[61]
After an initial victory against Persian forces at the Battle of the Granicus, Alexander accepted the surrender of the Persian provincial capital and treasury of Sardis; he then proceeded along the Ionian coast, granting autonomy and democracy to the cities. Miletus, held by Achaemenid forces, required a delicate siege operation, with Persian naval forces nearby. Further south, at Halicarnassus, in Caria, Alexander successfully waged his first large-scale siege, eventually forcing his opponents, the mercenary captain Memnon of Rhodes and the Persian satrap of Caria, Orontobates, to withdraw by sea.[70] Alexander left the government of Caria to a member of the Hecatomnid dynasty, Ada, who adopted Alexander.[71]
From Halicarnassus, Alexander proceeded into mountainous Lycia and the Pamphylian plain, asserting control over all coastal cities to deny the Persians naval bases. From Pamphylia onwards the coast held no major ports and Alexander moved inland. At Termessos, Alexander humbled but did not storm the Pisidian city.[72] At the ancient Phrygian capital of Gordium, Alexander "undid" the hitherto unsolvable Gordian Knot, a feat said to await the future "king of Asia".[73] According to the story, Alexander proclaimed that it did not matter how the knot was undone and hacked it apart with his sword.[74]
In spring 333 BC, Alexander crossed the Taurus into Cilicia. After a long pause due to an illness, he marched on towards Syria. Though outmanoeuvered by Darius's significantly larger army, he marched back to Cilicia, where he defeated Darius at Issus. Darius fled the battle, causing his army to collapse, and left behind his wife, his two daughters, his mother Sisygambis, and a fabulous treasure.[75] He offered a peace treaty that included the lands he had already lost, and a ransom of 10,000 talents for his family. Alexander replied that since he was now king of Asia, it was he alone who decided territorial divisions.[76] Alexander proceeded to take possession of Syria, and most of the coast of the Levant.[71] In the following year, 332 BC, he was forced to attack Tyre, which he captured after a long and difficult siege.[77][78] The men of military age were massacred and the women and children sold into slavery.[79]
Alexander then chased Darius, first into Media, and then Parthia.[98] The Persian king no longer controlled his own destiny, and was taken prisoner by Bessus, his Bactrian satrap and kinsman.[99] As Alexander approached, Bessus had his men fatally stab the Great King and then declared himself Darius's successor as Artaxerxes V, before retreating into Central Asia to launch a guerrilla campaign against Alexander.[100] Alexander buried Darius's remains next to his Achaemenid predecessors in a regal funeral.[101] He claimed that, while dying, Darius had named him as his successor to the Achaemenid throne.[102] The Achaemenid Empire is normally considered to have fallen with Darius.[103]
Alexander viewed Bessus as a usurper and set out to defeat him. This campaign, initially against Bessus, turned into a grand tour of central Asia. Alexander founded a series of new cities, all called Alexandria, including modern Kandahar in Afghanistan, and Alexandria Eschate ("The Furthest") in modern Tajikistan. The campaign took Alexander through Media, Parthia, Aria (West Afghanistan), Drangiana, Arachosia (South and Central Afghanistan), Bactria (North and Central Afghanistan), and Scythia.[104]
In 329 BC, Spitamenes, who held an undefined position in the satrapy of Sogdiana, betrayed Bessus to Ptolemy, one of Alexander's trusted companions, and Bessus was executed.[105] However, when, at some point later, Alexander was on the Jaxartes dealing with an incursion by a horse nomad army, Spitamenes raised Sogdiana in revolt. Alexander personally defeated the Scythians at the Battle of Jaxartes and immediately launched a campaign against Spitamenes, defeating him in the Battle of Gabai. After the defeat, Spitamenes was killed by his own men, who then sued for peace.[106]
During this time, Alexander adopted some elements of Persian dress and customs at his court, notably the custom of proskynesis, either a symbolic kissing of the hand, or prostration on the ground, that Persians showed to their social superiors.[107] The Greeks regarded the gesture as the province of deities and believed that Alexander meant to deify himself by requiring it. This cost him the sympathies of many of his countrymen, and he eventually abandoned it.[108]
A plot against his life was revealed, and one of his officers, Philotas, was executed for failing to alert Alexander. The death of the son necessitated the death of the father, and thus Parmenion, who had been charged with guarding the treasury at Ecbatana, was assassinated at Alexander's command, to prevent attempts at vengeance. Most infamously, Alexander personally killed the man who had saved his life at Granicus, Cleitus the Black, during a violent drunken altercation at Maracanda (modern day Samarkand in Uzbekistan), in which Cleitus accused Alexander of several judgmental mistakes and most especially, of having forgotten the Macedonian ways in favour of a corrupt oriental lifestyle.[109]
Later, in the Central Asian campaign, a second plot against his life was revealed, this one instigated by his own royal pages. His official historian, Callisthenes of Olynthus, was implicated in the plot, and in the Anabasis of Alexander, Arrian states that Callisthenes and the pages were then tortured on the rack as punishment, and likely died soon after.[110] It remains unclear if Callisthenes was actually involved in the plot, for prior to his accusation he had fallen out of favour by leading the opposition to the attempt to introduce proskynesis.[111]
After the death of Spitamenes and his marriage to Roxana (Raoxshna in Old Iranian) to cement relations with his new satrapies, Alexander turned to the Indian subcontinent. He invited the chieftains of the former satrapy of Gandhara (a region presently straddling eastern Afghanistan and northern Pakistan), to come to him and submit to his authority. Omphis (Indian name Ambhi), the ruler of Taxila, whose kingdom extended from the Indus to the Hydaspes (Jhelum), complied, but the chieftains of some hill clans, including the Aspasioi and Assakenoi sections of the Kambojas (known in Indian texts also as Ashvayanas and Ashvakayanas), refused to submit.[116] Ambhi hastened to relieve Alexander of his apprehension and met him with valuable presents, placing himself and all his forces at his disposal. Alexander not only returned Ambhi his title and the gifts but he also presented him with a wardrobe of "Persian robes, gold and silver ornaments, 30 horses and 1,000 talents in gold". Alexander was emboldened to divide his forces, and Ambhi assisted Hephaestion and Perdiccas in constructing a bridge over the Indus where it bends at Hund,[117] supplied their troops with provisions, and received Alexander himself, and his whole army, in his capital city of Taxila, with every demonstration of friendship and the most liberal hospitality.
On the subsequent advance of the Macedonian king, Taxiles accompanied him with a force of 5,000 men and took part in the battle of the Hydaspes River. After that victory he was sent by Alexander in pursuit of Porus (Indian name Puru), to whom he was charged to offer favourable terms, but narrowly escaped losing his life at the hands of his old enemy. Subsequently, however, the two rivals were reconciled by the personal mediation of Alexander; and Taxiles, after having contributed zealously to the equipment of the fleet on the Hydaspes, was entrusted by the king with the government of the whole territory between that river and the Indus. A considerable accession of power was granted him after the death of Philip, son of Machatas; and he was allowed to retain his authority at the death of Alexander himself (323 BC), as well as in the subsequent partition of the provinces at Triparadisus, 321 BC.
In the winter of 327/326 BC, Alexander personally led a campaign against the Aspasioi of Kunar valleys, the Guraeans of the Guraeus valley, and the Assakenoi of the Swat and Buner valleys.[118] A fierce contest ensued with the Aspasioi in which Alexander was wounded in the shoulder by a dart, but eventually the Aspasioi lost. Alexander then faced the Assakenoi, who fought against him from the strongholds of Massaga, Ora and Aornos.[116]
The fort of Massaga was reduced only after days of bloody fighting, in which Alexander was wounded seriously in the ankle. According to Curtius, "Not only did Alexander slaughter the entire population of Massaga, but also did he reduce its buildings to rubble."[119] A similar slaughter followed at Ora. In the aftermath of Massaga and Ora, numerous Assakenians fled to the fortress of Aornos. Alexander followed close behind and captured the strategic hill-fort after four bloody days.[116]
After Aornos, Alexander crossed the Indus and fought and won an epic battle against King Porus, who ruled a region lying between the Hydaspes and the Acesines (Chenab), in what is now the Punjab, in the Battle of the Hydaspes in 326 BC.[120] Alexander was impressed by Porus's bravery, and made him an ally. He appointed Porus as satrap, and added to Porus's territory land that he did not previously own, towards the south-east, up to the Hyphasis (Beas).[121][122] Choosing a local helped him control these lands so distant from Greece.[123] Alexander founded two cities on opposite sides of the Hydaspes river, naming one Bucephala, in honour of his horse, who died around this time.[124] The other was Nicaea (Victory), thought to be located at the site of modern-day Mong, Punjab.[125] Philostratus the Elder in the Life of Apollonius of Tyana writes that in the army of Porus there was an elephant who fought brave against Alexander's army and Alexander dedicated it to the Helios (Sun) and named it Ajax, because he thought that a so great animal deserved a great name.
Discovering that many of his satraps and military governors had misbehaved in his absence, Alexander executed several of them as examples on his way to Susa.[134][135] As a gesture of thanks, he paid off the debts of his soldiers, and announced that he would send over-aged and disabled veterans back to Macedon, led by Craterus. His troops misunderstood his intention and mutinied at the town of Opis. They refused to be sent away and criticized his adoption of Persian customs and dress and the introduction of Persian officers and soldiers into Macedonian units.[136]
On either 10 or 11 June 323 BC, Alexander died in the palace of Nebuchadnezzar II, in Babylon, at age 32.[143] There are two different versions of Alexander's death and details of the death differ slightly in each. Plutarch's account is that roughly 14 days before his death, Alexander entertained admiral Nearchus, and spent the night and next day drinking with Medius of Larissa.[144] He developed a fever, which worsened until he was unable to speak. The common soldiers, anxious about his health, were granted the right to file past him as he silently waved at them.[145] In the second account, Diodorus recounts that Alexander was struck with pain after downing a large bowl of unmixed wine in honour of Heracles, followed by 11 days of weakness; he did not develop a fever and died after some agony.[146] Arrian also mentioned this as an alternative, but Plutarch specifically denied this claim.[144]
Given the propensity of the Macedonian aristocracy to assassination,[147] foul play featured in multiple accounts of his death. Diodorus, Plutarch, Arrian and Justin all mentioned the theory that Alexander was poisoned. Justin stated that Alexander was the victim of a poisoning conspiracy, Plutarch dismissed it as a fabrication,[148] while both Diodorus and Arrian noted that they mentioned it only for the sake of completeness.[146][149] The accounts were nevertheless fairly consistent in designating Antipater, recently removed as Macedonian viceroy, and at odds with Olympias, as the head of the alleged plot. Perhaps taking his summons to Babylon as a death sentence,[150] and having seen the fate of Parmenion and Philotas,[151] Antipater purportedly arranged for Alexander to be poisoned by his son Iollas, who was Alexander's wine-pourer.[149][151] There was even a suggestion that Aristotle may have participated.[149]
The strongest argument against the poison theory is the fact that twelve days passed between the start of his illness and his death; such long-acting poisons were probably not available.[152] However, in a 2003 BBC documentary investigating the death of Alexander, Leo Schep from the New Zealand National Poisons Centre proposed that the plant white hellebore (Veratrum album), which was known in antiquity, may have been used to poison Alexander.[153][154][155] In a 2014 manuscript in the journal Clinical Toxicology, Schep suggested Alexander's wine was spiked with Veratrum album, and that this would produce poisoning symptoms that match the course of events described in the Alexander Romance.[156] Veratrum album poisoning can have a prolonged course and it was suggested that if Alexander was poisoned, Veratrum album offers the most plausible cause.[156][157] Another poisoning explanation put forward in 2010 proposed that the circumstances of his death were compatible with poisoning by water of the river Styx (modern-day Mavroneri in Arcadia, Greece) that contained calicheamicin, a dangerous compound produced by bacteria.[158]
Several natural causes (diseases) have been suggested, including malaria and typhoid fever. A 1998 article in the New England Journal of Medicine attributed his death to typhoid fever complicated by bowel perforation and ascending paralysis.[159] Another recent analysis suggested pyogenic (infectious) spondylitis or meningitis.[160] Other illnesses fit the symptoms, including acute pancreatitis and West Nile virus.[161][162] Natural-cause theories also tend to emphasize that Alexander's health may have been in general decline after years of heavy drinking and severe wounds. The anguish that Alexander felt after Hephaestion's death may also have contributed to his declining health.[159]
Alexander's body was laid in a gold anthropoid sarcophagus that was filled with honey, which was in turn placed in a gold casket.[163][164] According to Aelian, a seer called Aristander foretold that the land where Alexander was laid to rest "would be happy and unvanquishable forever".[165] Perhaps more likely, the successors may have seen possession of the body as a symbol of legitimacy, since burying the prior king was a royal prerogative.[166]
While Alexander's funeral cortege was on its way to Macedon, Ptolemy seized it and took it temporarily to Memphis.[163][165] His successor, Ptolemy II Philadelphus, transferred the sarcophagus to Alexandria, where it remained until at least late Antiquity. Ptolemy IX Lathyros, one of Ptolemy's final successors, replaced Alexander's sarcophagus with a glass one so he could convert the original to coinage.[167] The recent discovery of an enormous tomb in northern Greece, at Amphipolis, dating from the time of Alexander the Great[168] has given rise to speculation that its original intent was to be the burial place of Alexander. This would fit with the intended destination of Alexander's funeral cortege. However, the memorial was found to be dedicated to the dearest friend of Alexander the Great, Hephaestion.[169][170]
Detail of Alexander on the Alexander Sarcophagus
Pompey, Julius Caesar and Augustus all visited the tomb in Alexandria, where Augustus, allegedly, accidentally knocked the nose off. Caligula was said to have taken Alexander's breastplate from the tomb for his own use. Around AD 200, Emperor Septimius Severus closed Alexander's tomb to the public. His son and successor, Caracalla, a great admirer, visited the tomb during his own reign. After this, details on the fate of the tomb are hazy.[167]
The so-called "Alexander Sarcophagus", discovered near Sidon and now in the Istanbul Archaeology Museum, is so named not because it was thought to have contained Alexander's remains, but because its bas-reliefs depict Alexander and his companions fighting the Persians and hunting. It was originally thought to have been the sarcophagus of Abdalonymus (died 311 BC), the king of Sidon appointed by Alexander immediately following the battle of Issus in 331.[171][172] However, more recently, it has been suggested that it may date from earlier than Abdalonymus's death.
Demades likened the Macedonian army, after the death of Alexander, to the blinded Cyclops, due to the many random and disorderly movements that it made.[173][174][175] In addition, Leosthenes, also, likened the anarchy between the generals, after Alexander's death, to the blinded Cyclops "who after he had lost his eye went feeling and groping about with his hands before him, not knowing where to lay them".[176]
Alexander's death was so sudden that when reports of his death reached Greece, they were not immediately believed.[62] Alexander had no obvious or legitimate heir, his son Alexander IV by Roxane being born after Alexander's death.[177] According to Diodorus, Alexander's companions asked him on his deathbed to whom he bequeathed his kingdom; his laconic reply was "tôi kratistôi"—"to the strongest".[146] Another theory is that his successors wilfully or erroneously misheard "tôi Kraterôi"—"to Craterus", the general leading his Macedonian troops home and newly entrusted with the regency of Macedonia.[178]
Arrian and Plutarch claimed that Alexander was speechless by this point, implying that this was an apocryphal story.[179] Diodorus, Curtius and Justin offered the more plausible story that Alexander passed his signet ring to Perdiccas, a bodyguard and leader of the companion cavalry, in front of witnesses, thereby nominating him.[146][177]
Perdiccas initially did not claim power, instead suggesting that Roxane's baby would be king, if male; with himself, Craterus, Leonnatus, and Antipater as guardians. However, the infantry, under the command of Meleager, rejected this arrangement since they had been excluded from the discussion. Instead, they supported Alexander's half-brother Philip Arrhidaeus. Eventually, the two sides reconciled, and after the birth of Alexander IV, he and Philip III were appointed joint kings, albeit in name only.[180]
Dissension and rivalry soon afflicted the Macedonians, however. The satrapies handed out by Perdiccas at the Partition of Babylon became power bases each general used to bid for power. After the assassination of Perdiccas in 321 BC, Macedonian unity collapsed, and 40 years of war between "The Successors" (Diadochi) ensued before the Hellenistic world settled into four stable power blocs: Ptolemaic Egypt , Seleucid Mesopotamia and Central Asia, Attalid Anatolia, and Antigonid Macedon. In the process, both Alexander IV and Philip III were murdered.[181]
Alexander earned the epithet "the Great" due to his unparalleled success as a military commander. He never lost a battle, despite typically being outnumbered.[61] This was due to use of terrain, phalanx and cavalry tactics, bold strategy, and the fierce loyalty of his troops.[187] The Macedonian phalanx, armed with the sarissa, a spear 6 metres (20 ft) long, had been developed and perfected by Philip II through rigorous training, and Alexander used its speed and manoeuvrability to great effect against larger but more disparate Persian forces.[188] Alexander also recognized the potential for disunity among his diverse army, which employed various languages and weapons. He overcame this by being personally involved in battle,[91] in the manner of a Macedonian king.[187]
In his first battle in Asia, at Granicus, Alexander used only a small part of his forces, perhaps 13,000 infantry with 5,000 cavalry, against a much larger Persian force of 40,000.[189] Alexander placed the phalanx at the center and cavalry and archers on the wings, so that his line matched the length of the Persian cavalry line, about 3 km (1.86 mi). By contrast, the Persian infantry was stationed behind its cavalry. This ensured that Alexander would not be outflanked, while his phalanx, armed with long pikes, had a considerable advantage over the Persians' scimitars and javelins. Macedonian losses were negligible compared to those of the Persians.[190]
At Issus in 333 BC, his first confrontation with Darius, he used the same deployment, and again the central phalanx pushed through.[190] Alexander personally led the charge in the center, routing the opposing army.[191] At the decisive encounter with Darius at Gaugamela, Darius equipped his chariots with scythes on the wheels to break up the phalanx and equipped his cavalry with pikes. Alexander arranged a double phalanx, with the center advancing at an angle, parting when the chariots bore down and then reforming. The advance was successful and broke Darius's center, causing the latter to flee once again.[190]
When faced with opponents who used unfamiliar fighting techniques, such as in Central Asia and India, Alexander adapted his forces to his opponents' style. Thus, in Bactria and Sogdiana, Alexander successfully used his javelin throwers and archers to prevent outflanking movements, while massing his cavalry at the center.[191] In India, confronted by Porus's elephant corps, the Macedonians opened their ranks to envelop the elephants and used their sarissas to strike upwards and dislodge the elephants' handlers.[137]
Some of Alexander's strongest personality traits formed in response to his parents. His mother had huge ambitions, and encouraged him to believe it was his destiny to conquer the Persian Empire.[194] Olympias's influence instilled a sense of destiny in him,[200] and Plutarch tells how his ambition "kept his spirit serious and lofty in advance of his years".[201] However, his father Philip was Alexander's most immediate and influential role model, as the young Alexander watched him campaign practically every year, winning victory after victory while ignoring severe wounds.[50] Alexander's relationship with his father forged the competitive side of his personality; he had a need to outdo his father, illustrated by his reckless behaviour in battle.[194] While Alexander worried that his father would leave him "no great or brilliant achievement to be displayed to the world",[202] he also downplayed his father's achievements to his companions.[194]
According to Plutarch, among Alexander's traits were a violent temper and rash, impulsive nature,[203] which undoubtedly contributed to some of his decisions.[194] Although Alexander was stubborn and did not respond well to orders from his father, he was open to reasoned debate.[204] He had a calmer side—perceptive, logical, and calculating. He had a great desire for knowledge, a love for philosophy, and was an avid reader.[205] This was no doubt in part due to Aristotle's tutelage; Alexander was intelligent and quick to learn.[194] His intelligent and rational side was amply demonstrated by his ability and success as a general.[203] He had great self-restraint in "pleasures of the body", in contrast with his lack of self-control with alcohol.[206]
Alexander was erudite and patronized both arts and sciences.[201][205] However, he had little interest in sports or the Olympic games (unlike his father), seeking only the Homeric ideals of honour (timê) and glory (kudos).[207] He had great charisma and force of personality, characteristics which made him a great leader.[177][203] His unique abilities were further demonstrated by the inability of any of his generals to unite Macedonia and retain the Empire after his death—only Alexander had the ability to do so.[177]
During his final years, and especially after the death of Hephaestion, Alexander began to exhibit signs of megalomania and paranoia.[150] His extraordinary achievements, coupled with his own ineffable sense of destiny and the flattery of his companions, may have combined to produce this effect.[208] His delusions of grandeur are readily visible in his will and in his desire to conquer the world,[150] in as much as he is by various sources described as having boundless ambition,[209][210] an epithet, the meaning of which has descended into an historical cliché.[211][212]
He appears to have believed himself a deity, or at least sought to deify himself.[150] Olympias always insisted to him that he was the son of Zeus,[213] a theory apparently confirmed to him by the oracle of Amun at Siwa.[214] He began to identify himself as the son of Zeus-Ammon.[214] Alexander adopted elements of Persian dress and customs at court, notably proskynesis, a practice of which Macedonians disapproved, and were loath to perform.[107] This behaviour cost him the sympathies of many of his countrymen.[215] However, Alexander also was a pragmatic ruler who understood the difficulties of ruling culturally disparate peoples, many of whom lived in kingdoms where the king was divine.[216] Thus, rather than megalomania, his behaviour may simply have been a practical attempt at strengthening his rule and keeping his empire together.[217]
Alexander married three times: Roxana, daughter of the Sogdian nobleman Oxyartes of Bactria,[218][219][220] out of love;[221] and the Persian princesses Stateira II and Parysatis II, the former a daughter of Darius III and latter a daughter of Artaxerxes III, for political reasons.[222][223] He apparently had two sons, Alexander IV of Macedon by Roxana and, possibly, Heracles of Macedon from his mistress Barsine. He lost another child when Roxana miscarried at Babylon.[224][225]
Alexander also had a close relationship with his friend, general, and bodyguard Hephaestion, the son of a Macedonian noble.[140][194][226] Hephaestion's death devastated Alexander.[140][227] This event may have contributed to Alexander's failing health and detached mental state during his final months.[150][159]
Alexander's sexuality has been the subject of speculation and controversy in modern times.[228] The Roman era writer Athenaeus says, based on the scholar Dicaearchus, who was Alexander's contemporary, that the king "was quite excessively keen on boys", and that Alexander kissed the eunuch Bagoas in public.[229] This episode is also told by Plutarch, probably based on the same source. None of Alexander's contemporaries, however, are known to have explicitly described Alexander's relationship with Hephaestion as sexual, though the pair was often compared to Achilles and Patroclus, whom classical Greek culture painted as a couple. Aelian writes of Alexander's visit to Troy where "Alexander garlanded the tomb of Achilles, and Hephaestion that of Patroclus, the latter hinting that he was a beloved of Alexander, in just the same way as Patroclus was of Achilles."[230] Some modern historians (e.g., Robin Lane Fox) believe not only that Alexander's youthful relationship with Hephaestion was sexual, but that their sexual contacts may have continued into adulthood, which went against the social norms of at least some Greek cities, such as Athens,[231][232] though some modern researchers have tentatively proposed that Macedonia (or at least the Macedonian court) may have been more tolerant of homosexuality between adults.[233]
Green argues that there is little evidence in ancient sources that Alexander had much carnal interest in women; he did not produce an heir until the very end of his life.[194] However, Ogden calculates that Alexander, who impregnated his partners thrice in eight years, had a higher matrimonial record than his father at the same age.[234] Two of these pregnancies — Stateira's and Barsine's — are of dubious legitimacy.[235]
According to Diodorus Siculus, Alexander accumulated a harem in the style of Persian kings, but he used it rather sparingly, "not wishing to offend the Macedonians",[236] showing great self-control in "pleasures of the body".[206] Nevertheless, Plutarch described how Alexander was infatuated by Roxana while complimenting him on not forcing himself on her.[237] Green suggested that, in the context of the period, Alexander formed quite strong friendships with women, including Ada of Caria, who adopted him, and even Darius's mother Sisygambis, who supposedly died from grief upon hearing of Alexander's death.[194]
Napoléon Bonaparte[a] (15 August 1769 – 5 May 1821) was a French military and political leader. He rose to prominence during the French Revolution and led several successful campaigns during the Revolutionary Wars. As Napoleon I, he was Emperor of the French from 1804 until 1814, and again in 1815. Napoleon dominated European and global affairs for more than a decade while leading France against a series of coalitions in the Napoleonic Wars. He won most of these wars and the vast majority of his battles, building a large empire that ruled over continental Europe before its final collapse in 1815. One of the greatest commanders in history, his wars and campaigns are studied at military schools worldwide. He remains one of the most celebrated and controversial political figures in human history.[3][4]
Napoleon had an extensive and powerful impact on the modern world, bringing liberal reforms to the numerous territories that he conquered and controlled, especially the Low Countries, Switzerland, and large parts of modern Italy and Germany. He implemented fundamental liberal policies in France and throughout Western Europe.[b] His lasting legal achievement, the Napoleonic Code, has been highly influential. Roberts says, "The ideas that underpin our modern world—meritocracy, equality before the law, property rights, religious toleration, modern secular education, sound finances, and so on—were championed, consolidated, codified and geographically extended by Napoleon. To them he added a rational and efficient local administration, an end to rural banditry, the encouragement of science and the arts, the abolition of feudalism and the greatest codification of laws since the fall of the Roman Empire."[11]
Born Napoleone di Buonaparte on the island of Corsica not long after its annexation by the Kingdom of France, Napoleon's modest family descended from minor Italian nobility. He supported the French Revolution in 1789 while serving in the French army, and tried to spread its ideals to his native Corsica. He rose rapidly in the Army after he saved the governing French Directory by firing on royalist insurgents. In April 1796, he began his first military campaign against the Austrians and their Italian allies, scoring a series of decisive victories and becoming a national hero. Two years later, he led a military expedition to Egypt that served as a springboard to political power.
He engineered a coup in November 1799 and became First Consul of the Republic. Intractable differences with the British meant that the French were facing the War of the Third Coalition by 1805. Napoleon shattered this coalition with decisive victories in the Ulm Campaign, and a historic triumph at the Battle of Austerlitz, which led to the elimination of the Holy Roman Empire. In 1806, the Fourth Coalition took up arms against him because Prussia became worried about growing French influence on the continent. Napoleon quickly knocked out Prussia at the battles of Jena and Auerstedt, then marched the Grand Army deep into Eastern Europe, annihilating the Russians in June 1807 at Friedland, and forcing the defeated nations of the Fourth Coalition to accept the Treaties of Tilsit. Two years later, the Austrians challenged the French again during the War of the Fifth Coalition, but Napoleon solidified his grip over Europe after triumphing at the Battle of Wagram.
Hoping to extend the Continental System (embargo of Britain), Napoleon invaded Iberia and declared his brother Joseph the King of Spain in 1808. The Spanish and the Portuguese revolted with British support. The Peninsular War lasted six years, featured brutal guerrilla warfare, and culminated in a defeat for Napoleon. Napoleon launched an invasion of Russia in the summer of 1812. The resulting campaign witnessed the catastrophic retreat of Napoleon's Grand Army and encouraged his enemies. In 1813, Prussia and Austria joined Russian forces in a Sixth Coalition against France. A chaotic military campaign culminated in a large coalition army defeating Napoleon at the Battle of Leipzig in October 1813. The coalition invaded France and captured Paris, forcing Napoleon to abdicate in April 1814.
Napoleon was exiled to the island of Elba, between Corsica and Italy. In France, the Bourbons were restored to power. However, Napoleon escaped from Elba in February 1815 and took control of France. The Allies responded by forming a Seventh Coalition, which ultimately defeated Napoleon at the Battle of Waterloo in June 1815. The British exiled him to the remote island of Saint Helena in the South Atlantic. His death in 1821 at the age of 51 was received with shock and grief throughout Europe.
Napoleon's family was of Italian origin: his paternal ancestors, the Buonapartes, descended from a minor Tuscan noble family that emigrated to Corsica in the 16th century; while his maternal ancestors, the Ramolinos, descended from a minor Genoese noble family.[12] The Buonapartes were also the relatives, by marriage and by birth, of the Pietrasentas, Costas, Paraviccinis, and Bonellis, all Corsican families of the interior.[13] His parents Carlo Maria di Buonaparte and Maria Letizia Ramolino maintained an ancestral home called "Casa Buonaparte" in Ajaccio. Napoleon was born there on 15 August 1769, their fourth child and third son. A boy and girl were born first but died in infancy. He had an elder brother, Joseph, and younger siblings Lucien, Elisa, Louis, Pauline, Caroline, and Jérôme. Napoleon was baptised as a Catholic, under the name Napoleone.[14] In his youth, his name was also spelled as Nabulione, Nabulio, Napolionne, and Napulione.[15]
Napoleon was born the same year the Republic of Genoa ceded Corsica to France.[16] The state sold sovereign rights a year before his birth in 1768, and the island was conquered by France during the year of his birth and formally incorporated as a province in 1770, after 500 years under Genoese rule and 14 years of independence.[c] Napoleon's parents joined the Corsican resistance and fought against the French to maintain independence, even when Maria was pregnant with him. His father was an attorney who went on to be named Corsica's representative to the court of Louis XVI in 1777.[20]
The dominant influence of Napoleon's childhood was his mother, whose firm discipline restrained a rambunctious child.[20] Later in life Napoleon stated, "The future destiny of the child is always the work of the mother."[21] Napoleon's maternal grandmother had married into the Swiss Fesch family in her second marriage, and Napoleon's uncle, the cardinal Joseph Fesch, would fulfill a role as protector of the Bonaparte family for some years. Napoleon's noble, moderately affluent background afforded him greater opportunities to study than were available to a typical Corsican of the time.[22]
When he turned 9 years old,[23][24] he moved to the French mainland and enrolled at a religious school in Autun in January 1779. In May, he transferred with a scholarship to a military academy at Brienne-le-Château.[25] In his youth he was an outspoken Corsican nationalist and supported the state's independence from France.[better source needed][23] Like many Corsicans, Napoleon spoke and read Corsican (as his mother tongue) and Italian (as the official language of Corsica).[26][27][28] He began learning French in school at around age 10.[29] Although he became fluent in French, he spoke with a distinctive Corsican accent and never learned how to spell French correctly.[30] He was, however, not an isolated case, as it was estimated in 1790 that fewer than 3 million people, out of France's population of 28 million, were able to speak standard French, and those who could write it were even fewer.[31]
Napoleon was routinely bullied by his peers for his accent, birthplace, short stature, mannerisms and inability to speak French quickly.[27] Bonaparte became reserved and melancholy applying himself to reading. An examiner observed that Napoleon "has always been distinguished for his application in mathematics. He is fairly well acquainted with history and geography ... This boy would make an excellent sailor".[d][33] In early adulthood, he briefly intended to become a writer; he authored a history of Corsica and a romantic novella.[23]
On completion of his studies at Brienne in 1784, Napoleon was admitted to the École Militaire in Paris. He trained to become an artillery officer and, when his father's death reduced his income, was forced to complete the two-year course in one year.[34] He was the first Corsican to graduate from the École Militaire.[34] He was examined by the famed scientist Pierre-Simon Laplace.[35]
Upon graduating in September 1785, Bonaparte was commissioned a second lieutenant in La Fère artillery regiment.[e][25] He served in Valence and Auxonne until after the outbreak of the Revolution in 1789. The young man still was a fervent Corsican nationalist during this period and asked for leave to join his mentor Pasquale Paoli, when the latter was allowed to return to Corsica by the National Assembly. Paoli had no sympathy for Napoleon however as he deemed his father a traitor for having deserted his cause for Corsican independence.[citation needed]
He spent the early years of the Revolution in Corsica, fighting in a complex three-way struggle among royalists, revolutionaries, and Corsican nationalists. Napoleon, however, came to embrace the ideals of the Revolution, becoming a supporter of the Jacobins and joining the pro-French Corsican Republicans who opposed Paoli's policy and his aspirations of secession.[37] He was given command over a battalion of volunteers and was promoted to captain in the regular army in July 1792, despite exceeding his leave of absence and leading a riot against French troops.[38] When Corsica declared formal secession from France and requested the protection of the British government Napoleon and his commitment to the French Revolution came into conflict with Paoli, who had decided to sabotage the Corsican contribution to the Expédition de Sardaigne, by preventing a French assault on the Sardinian island of La Maddalena.[39] Bonaparte and his family were compelled to flee to Toulon on the French mainland in June 1793 because of the split with Paoli.[40]
Although he was born "Napoleone di Buonaparte", it was after this that Napoleon began styling himself "Napoléon Bonaparte" but his family did not drop the name Buonaparte until 1796. The first known record of him signing his name as Bonaparte was at the age of 27 (in 1796).[41][14][42]
Some contemporaries alleged that Bonaparte was put under house arrest at Nice for his association with the Robespierres following their fall in the Thermidorian Reaction in July 1794, but Napoleon's secretary Bourrienne disputed the allegation in his memoirs. According to Bourrienne, jealousy was responsible, between the Army of the Alps and the Army of Italy (with whom Napoleon was seconded at the time).[47] Bonaparte dispatched an impassioned defence in a letter to the commissar Saliceti, and he was subsequently acquitted of any wrongdoing.[48] He was released within two weeks (on 20 August) and, due to his technical skills, was asked to draw up plans to attack Italian positions in the context of France's war with Austria. He also took part in an expedition to take back Corsica from the British, but the French were repulsed by the British Royal Navy.[49]Two days after the marriage, Bonaparte left Paris to take command of the Army of Italy. He immediately went on the offensive, hoping to defeat the forces of Piedmont before their Austrian allies could intervene. In a series of rapid victories during the Montenotte Campaign, he knocked Piedmont out of the war in two weeks. The French then focused on the Austrians for the remainder of the war, the highlight of which became the protracted struggle for Mantua. The Austrians launched a series of offensives against the French to break the siege, but Napoleon defeated every relief effort, scoring victories at the battles of Castiglione, Bassano, Arcole, and Rivoli. The decisive French triumph at Rivoli in January 1797 led to the collapse of the Austrian position in Italy. At Rivoli, the Austrians lost up to 14,000 men while the French lost about 5,000.[59]
The next phase of the campaign featured the French invasion of the Habsburg heartlands. French forces in Southern Germany had been defeated by the Archduke Charles in 1796, but the Archduke withdrew his forces to protect Vienna after learning about Napoleon's assault. In the first encounter between the two commanders, Napoleon pushed back his opponent and advanced deep into Austrian territory after winning at the Battle of Tarvis in March 1797. The Austrians were alarmed by the French thrust that reached all the way to Leoben, about 100 km from Vienna, and finally decided to sue for peace.[60] The Treaty of Leoben, followed by the more comprehensive Treaty of Campo Formio, gave France control of most of northern Italy and the Low Countries, and a secret clause promised the Republic of Venice to Austria. Bonaparte marched on Venice and forced its surrender, ending 1,100 years of Venetian independence. He also authorized the French to loot treasures such as the Horses of Saint Mark.[61] On the journey, Bonaparte conversed much about the warriors of antiquity especially Alexander, Caesar, Scipio and Hannibal. He studied their strategy and combined it with his own. In a question from Bourrienne, asking whether he gave his preference to Alexander or Caesar, Napoleon said that he places Alexander The Great in the first rank, the main reason being his campaign on Asia.[62]
After two months of planning, Bonaparte decided that France's naval strength was not yet sufficient enough to confront the British Royal Navy. He decided on a military expedition to seize Egypt and thereby undermine Britain's access to its trade interests in India.[40] Bonaparte wished to establish a French presence in the Middle East and join forces with Tipu Sultan, the Sultan of Mysore who was an enemy of the British.[71] Napoleon assured the Directory that "as soon as he had conquered Egypt, he will establish relations with the Indian princes and, together with them, attack the English in their possessions".[72] The Directory agreed in order to secure a trade route to the Indian subcontinent.[73]
In May 1798, Bonaparte was elected a member of the French Academy of Sciences. His Egyptian expedition included a group of 167 scientists, with mathematicians, naturalists, chemists, and geodesists among them. Their discoveries included the Rosetta Stone, and their work was published in the Description de l'Égypte in 1809.[74]
En route to Egypt, Bonaparte reached Malta on 9 June 1798, then controlled by the Knights Hospitaller. Grand Master Ferdinand von Hompesch zu Bolheim surrendered after token resistance, and Bonaparte captured an important naval base with the loss of only three men.[75]
Bonaparte and his expedition eluded pursuit by the Royal Navy and landed at Alexandria on 1 July.[40] He fought the Battle of Shubra Khit against the Mamluks, Egypt's ruling military caste. This helped the French practise their defensive tactic for the Battle of the Pyramids, fought on 21 July, about 24 km (15 mi) from the pyramids. General Bonaparte's forces of 25,000 roughly equalled those of the Mamluks' Egyptian cavalry. Twenty-nine French[76] and approximately 2,000 Egyptians were killed. The victory boosted the morale of the French army.[77]
On 1 August 1798, the British fleet under Sir Horatio Nelson captured or destroyed all but two vessels of the French fleet in the Battle of the Nile, defeating Bonaparte's goal to strengthen the French position in the Mediterranean.[78] His army had succeeded in a temporary increase of French power in Egypt, though it faced repeated uprisings.[79] In early 1799, he moved an army into the Ottoman province of Damascus (Syria and Galilee). Bonaparte led these 13,000 French soldiers in the conquest of the coastal towns of Arish, Gaza, Jaffa, and Haifa.[80] The attack on Jaffa was particularly brutal. Bonaparte discovered that many of the defenders were former prisoners of war, ostensibly on parole, so he ordered the garrison and 1,400 prisoners to be executed by bayonet or drowning to save bullets.[78] Men, women, and children were robbed and murdered for three days.[81]
Bonaparte began with an army of 13,000 men; 1,500 were reported missing, 1,200 died in combat, and thousands perished from disease—mostly bubonic plague. He failed to reduce the fortress of Acre, so he marched his army back to Egypt in May. To speed up the retreat, Bonaparte ordered plague-stricken men to be poisoned with opium; the number who died remains disputed, ranging from a low of 30 to a high of 580. He also brought out 1,000 wounded men.[82] Back in Egypt on 25 July, Bonaparte defeated an Ottoman amphibious invasion at Abukir.[83]
While in Egypt, Bonaparte stayed informed of European affairs. He learned that France had suffered a series of defeats in the War of the Second Coalition.[84] On 24 August 1799, he took advantage of the temporary departure of British ships from French coastal ports and set sail for France, despite the fact that he had received no explicit orders from Paris.[78] The army was left in the charge of Jean-Baptiste Kléber.[85]
Unknown to Bonaparte, the Directory had sent him orders to return to ward off possible invasions of French soil, but poor lines of communication prevented the delivery of these messages.[84] By the time that he reached Paris in October, France's situation had been improved by a series of victories. The Republic, however, was bankrupt and the ineffective Directory was unpopular with the French population.[86] The Directory discussed Bonaparte's "desertion" but was too weak to punish him.[84]
Despite the failures in Egypt, Napoleon returned to a hero's welcome. He drew together an alliance with director Emmanuel Joseph Sieyès, his brother Lucien, speaker of the Council of Five Hundred Roger Ducos, director Joseph Fouché, and Talleyrand, and they overthrew the Directory by a coup d'état on 9 November 1799 ("the 18th Brumaire" according to the revolutionary calendar), closing down the Council of Five Hundred. Napoleon became "first consul" for ten years, with two consuls appointed by him who had consultative voices only. His power was confirmed by the new "Constitution of the Year VIII", originally devised by Sieyès to give Napoleon a minor role, but rewritten by Napoleon, and accepted by direct popular vote (3,000,000 in favour, 1,567 opposed). The constitution preserved the appearance of a republic but in reality, established a dictatorship.[87][88]
Napoleon established a political system that historian Martyn Lyons called "dictatorship by plebiscite".[89] Worried by the democratic forces unleashed by the Revolution, but unwilling to ignore them entirely, Napoleon resorted to regular electoral consultations with the French people on his road to imperial power.[89] He drafted the Constitution of the Year VIII and secured his own election as First Consul, taking up residence at the Tuileries. The constitution was approved in a rigged plebiscite held the following January, with 99.94 percent officially listed as voting "yes".[90]
Napoleon's brother, Lucien, had falsified the returns to show that 3 million people had participated in the plebiscite. The real number was 1.5 million.[89] Political observers at the time assumed the eligible French voting public numbered about 5 million people, so the regime artificially doubled the participation rate to indicate popular enthusiasm for the consulate.[89] In the first few months of the consulate, with war in Europe still raging and internal instability still plaguing the country, Napoleon's grip on power remained very tenuous.[91]
In the spring of 1800, Napoleon and his troops crossed the Swiss Alps into Italy, aiming to surprise the Austrian armies that had reoccupied the peninsula when Napoleon was still in Egypt.[f] After a difficult crossing over the Alps, the French army entered the plains of Northern Italy virtually unopposed.[93] While one French army approached from the north, the Austrians were busy with another stationed in Genoa, which was besieged by a substantial force. The fierce resistance of this French army, under André Masséna, gave the northern force some time to carry out their operations with little interference.[94]
After spending several days looking for each other, the two armies collided at the Battle of Marengo on 14 June. General Melas had a numerical advantage, fielding about 30,000 Austrian soldiers while Napoleon commanded 24,000 French troops.[95] The battle began favourably for the Austrians as their initial attack surprised the French and gradually drove them back. Melas stated that he had won the battle and retired to his headquarters around 3 pm, leaving his subordinates in charge of pursuing the French.[96] The French lines never broke during their tactical retreat. Napoleon constantly rode out among the troops urging them to stand and fight.[97]
Late in the afternoon, a full division under Desaix arrived on the field and reversed the tide of the battle. A series of artillery barrages and cavalry charges decimated the Austrian army, which fled over the Bormida River back to Alessandria, leaving behind 14,000 casualties.[97] The following day, the Austrian army agreed to abandon Northern Italy once more with the Convention of Alessandria, which granted them safe passage to friendly soil in exchange for their fortresses throughout the region.[97]
Although critics have blamed Napoleon for several tactical mistakes preceding the battle, they have also praised his audacity for selecting a risky campaign strategy, choosing to invade the Italian peninsula from the north when the vast majority of French invasions came from the west, near or along the coastline.[98] As Chandler points out, Napoleon spent almost a year getting the Austrians out of Italy in his first campaign. In 1800, it took him only a month to achieve the same goal.[98] German strategist and field marshal Alfred von Schlieffen concluded that "Bonaparte did not annihilate his enemy but eliminated him and rendered him harmless" while "[attaining] the object of the campaign: the conquest of North Italy".[99]
Napoleon's triumph at Marengo secured his political authority and boosted his popularity back home, but it did not lead to an immediate peace. Bonaparte's brother, Joseph, led the complex negotiations in Lunéville and reported that Austria, emboldened by British support, would not acknowledge the new territory that France had acquired. As negotiations became increasingly fractious, Bonaparte gave orders to his general Moreau to strike Austria once more. Moreau and the French swept through Bavaria and scored an overwhelming victory at Hohenlinden in December 1800. As a result, the Austrians capitulated and signed the Treaty of Lunéville in February 1801. The treaty reaffirmed and expanded earlier French gains at Campo Formio.[100]
Great Britain had broken the Peace of Amiens by declaring war on France in May 1803.[123] In December 1804, an Anglo-Swedish agreement became the first step towards the creation of the Third Coalition. By April 1805, Britain had also signed an alliance with Russia.[124] Austria had been defeated by France twice in recent memory and wanted revenge, so it joined the coalition a few months later.[125]
Before the formation of the Third Coalition, Napoleon had assembled an invasion force, the Armée d'Angleterre, around six camps at Boulogne in Northern France. He intended to use this invasion force to strike at England. They never invaded, but Napoleon's troops received careful and invaluable training for future military operations.[126] The men at Boulogne formed the core for what Napoleon later called La Grande Armée. At the start, this French army had about 200,000 men organized into seven corps, which were large field units that contained 36–40 cannons each and were capable of independent action until other corps could come to the rescue.[127]
A single corps properly situated in a strong defensive position could survive at least a day without support, giving the Grande Armée countless strategic and tactical options on every campaign. On top of these forces, Napoleon created a cavalry reserve of 22,000 organized into two cuirassier divisions, four mounted dragoon divisions, one division of dismounted dragoons, and one of light cavalry, all supported by 24 artillery pieces.[128] By 1805, the Grande Armée had grown to a force of 350,000 men,[128] who were well equipped, well trained, and led by competent officers.[129]
Napoleon knew that the French fleet could not defeat the Royal Navy in a head-to-head battle, so he planned to lure it away from the English Channel through diversionary tactics.[130] The main strategic idea involved the French Navy escaping from the British blockades of Toulon and Brest and threatening to attack the West Indies. In the face of this attack, it was hoped, the British would weaken their defence of the Western Approaches by sending ships to the Caribbean, allowing a combined Franco-Spanish fleet to take control of the channel long enough for French armies to cross and invade.[130] However, the plan unravelled after the British victory at the Battle of Cape Finisterre in July 1805. French Admiral Villeneuve then retreated to Cádiz instead of linking up with French naval forces at Brest for an attack on the English Channel.[131]
By August 1805, Napoleon had realized that the strategic situation had changed fundamentally. Facing a potential invasion from his continental enemies, he decided to strike first and turned his army's sights from the English Channel to the Rhine. His basic objective was to destroy the isolated Austrian armies in Southern Germany before their Russian allies could arrive. On 25 September, after great secrecy and feverish marching, 200,000 French troops began to cross the Rhine on a front of 260 km (160 mi).[132][133]
Austrian commander Karl Mack had gathered the greater part of the Austrian army at the fortress of Ulm in Swabia. Napoleon swung his forces to the southeast and the Grande Armée performed an elaborate wheeling movement that outflanked the Austrian positions. The Ulm Maneuver completely surprised General Mack, who belatedly understood that his army had been cut off. After some minor engagements that culminated in the Battle of Ulm, Mack finally surrendered after realizing that there was no way to break out of the French encirclement. For just 2,000 French casualties, Napoleon had managed to capture a total of 60,000 Austrian soldiers through his army's rapid marching.[134]
The Ulm Campaign is generally regarded as a strategic masterpiece and was influential in the development of the Schlieffen Plan in the late 19th century.[135] For the French, this spectacular victory on land was soured by the decisive victory that the Royal Navy attained at the Battle of Trafalgar on 21 October. After Trafalgar, Britain had total domination of the seas for the duration of the Napoleonic Wars.[citation needed]
Following the Ulm Campaign, French forces managed to capture Vienna in November. The fall of Vienna provided the French a huge bounty as they captured 100,000 muskets, 500 cannons, and the intact bridges across the Danube.[136] At this critical juncture, both Tsar Alexander I and Holy Roman Emperor Francis II decided to engage Napoleon in battle, despite reservations from some of their subordinates. Napoleon sent his army north in pursuit of the Allies but then ordered his forces to retreat so that he could feign a grave weakness.[137]
Desperate to lure the Allies into battle, Napoleon gave every indication in the days preceding the engagement that the French army was in a pitiful state, even abandoning the dominant Pratzen Heights near the village of Austerlitz. At the Battle of Austerlitz, in Moravia on 2 December, he deployed the French army below the Pratzen Heights and deliberately weakened his right flank, enticing the Allies to launch a major assault there in the hopes of rolling up the whole French line. A forced march from Vienna by Marshal Davout and his III Corps plugged the gap left by Napoleon just in time.[137]
Meanwhile, the heavy Allied deployment against the French right flank weakened their center on the Pratzen Heights, which was viciously attacked by the IV Corps of Marshal Soult. With the Allied center demolished, the French swept through both enemy flanks and sent the Allies fleeing chaotically, capturing thousands of prisoners in the process. The battle is often seen as a tactical masterpiece because of the near-perfect execution of a calibrated but dangerous plan—of the same stature as Cannae, the celebrated triumph by Hannibal some 2,000 years before.[137]
The Allied disaster at Austerlitz significantly shook the faith of Emperor Francis in the British-led war effort. France and Austria agreed to an armistice immediately and the Treaty of Pressburg followed shortly after on 26 December. Pressburg took Austria out of both the war and the Coalition while reinforcing the earlier treaties of Campo Formio and of Lunéville between the two powers. The treaty confirmed the Austrian loss of lands to France in Italy and Bavaria, and lands in Germany to Napoleon's German allies. It also imposed an indemnity of 40 million francs on the defeated Habsburgs and allowed the fleeing Russian troops free passage through hostile territories and back to their home soil. Napoleon went on to say, "The battle of Austerlitz is the finest of all I have fought".[138] Frank McLynn suggests that Napoleon was so successful at Austerlitz that he lost touch with reality, and what used to be French foreign policy became a "personal Napoleonic one".[139] Vincent Cronin disagrees, stating that Napoleon was not overly ambitious for himself, "he embodied the ambitions of thirty million Frenchmen".[140]
Napoleon continued to entertain a grand scheme to establish a French presence in the Middle East in order to put pressure on Britain and Russia, and perhaps form an alliance with the Ottoman Empire.[71] In February 1806, Ottoman Emperor Selim III recognised Napoleon as Emperor. He also opted for an alliance with France, calling France "our sincere and natural ally".[141] That decision brought the Ottoman Empire into a losing war against Russia and Britain. A Franco-Persian alliance was also formed between Napoleon and the Persian Empire of Fat′h-Ali Shah Qajar. It collapsed in 1807 when France and Russia themselves formed an unexpected alliance.[71] In the end, Napoleon had made no effective alliances in the Middle East.[142]
After Austerlitz, Napoleon established the Confederation of the Rhine in 1806. A collection of German states intended to serve as a buffer zone between France and Central Europe, the creation of the Confederation spelled the end of the Holy Roman Empire and significantly alarmed the Prussians. The brazen reorganization of German territory by the French risked threatening Prussian influence in the region, if not eliminating it outright. War fever in Berlin rose steadily throughout the summer of 1806. At the insistence of his court, especially his wife Queen Louise, Frederick William III decided to challenge the French domination of Central Europe by going to war.[143]
The initial military manoeuvres began in September 1806. In a letter to Marshal Soult detailing the plan for the campaign, Napoleon described the essential features of Napoleonic warfare and introduced the phrase le bataillon-carré ("square battalion").[144] In the bataillon-carré system, the various corps of the Grande Armée would march uniformly together in close supporting distance.[144] If any single corps was attacked, the others could quickly spring into action and arrive to help.[145]
Napoleon invaded Prussia with 180,000 troops, rapidly marching on the right bank of the River Saale. As in previous campaigns, his fundamental objective was to destroy one opponent before reinforcements from another could tip the balance of the war. Upon learning the whereabouts of the Prussian army, the French swung westwards and crossed the Saale with overwhelming force. At the twin battles of Jena and Auerstedt, fought on 14 October, the French convincingly defeated the Prussians and inflicted heavy casualties. With several major commanders dead or incapacitated, the Prussian king proved incapable of effectively commanding the army, which began to quickly disintegrate.[145]On 14 June Napoleon obtained an overwhelming victory over the Russians at the Battle of Friedland, wiping out the majority of the Russian army in a very bloody struggle. The scale of their defeat convinced the Russians to make peace with the French. On 19 June, Tsar Alexander sent an envoy to seek an armistice with Napoleon. The latter assured the envoy that the Vistula River represented the natural borders between French and Russian influence in Europe. On that basis, the two emperors began peace negotiations at the town of Tilsit after meeting on an iconic raft on the River Niemen. The very first thing Alexander said to Napoleon was probably well-calibrated: "I hate the English as much as you do".[149]
Alexander faced pressure from his brother, Duke Constantine, to make peace with Napoleon. Given the victory he had just achieved, the French emperor offered the Russians relatively lenient terms—demanding that Russia join the Continental System, withdraw its forces from Wallachia and Moldavia, and hand over the Ionian Islands to France.[150] By contrast, Napoleon dictated very harsh peace terms for Prussia, despite the ceaseless exhortations of Queen Louise. Wiping out half of Prussian territories from the map, Napoleon created a new kingdom of 2,800 square kilometres (1,100 sq mi) called Westphalia and appointed his young brother Jérôme as its monarch. Prussia's humiliating treatment at Tilsit caused a deep and bitter antagonism that festered as the Napoleonic era progressed. Moreover, Alexander's pretensions at friendship with Napoleon led the latter to seriously misjudge the true intentions of his Russian counterpart, who would violate numerous provisions of the treaty in the next few years. Despite these problems, the Treaties of Tilsit at last gave Napoleon a respite from war and allowed him to return to France, which he had not seen in over 300 days.[151]
After four years on the sidelines, Austria sought another war with France to avenge its recent defeats. Austria could not count on Russian support because the latter was at war with Britain, Sweden, and the Ottoman Empire in 1809. Frederick William of Prussia initially promised to help the Austrians but reneged before conflict began.[161] A report from the Austrian finance minister suggested that the treasury would run out of money by the middle of 1809 if the large army that the Austrians had formed since the Third Coalition remained mobilized.[161] Although Archduke Charles warned that the Austrians were not ready for another showdown with Napoleon, a stance that landed him in the so-called "peace party", he did not want to see the army demobilized either.[161] On 8 February 1809, the advocates for war finally succeeded when the Imperial Government secretly decided on another confrontation against the French.[citation needed]
In the early morning of 10 April, leading elements of the Austrian army crossed the Inn River and invaded Bavaria. The early Austrian attack surprised the French; Napoleon himself was still in Paris when he heard about the invasion. He arrived at Donauwörth on the 17th to find the Grande Armée in a dangerous position, with its two wings separated by 120 km (75 mi) and joined together by a thin cordon of Bavarian troops. Charles pressed the left wing of the French army and hurled his men towards the III Corps of Marshal Davout. In response, Napoleon came up with a plan to cut off the Austrians in the celebrated Landshut Maneuver.[162] He realigned the axis of his army and marched his soldiers towards the town of Eckmühl. The French scored a convincing win in the resulting Battle of Eckmühl, forcing Charles to withdraw his forces over the Danube and into Bohemia. On 13 May, Vienna fell for the second time in four years, although the war continued since most of the Austrian army had survived the initial engagements in Southern Germany.
The battle was characterized by a vicious back-and-forth struggle for the two villages of Aspern and Essling, the focal points of the French bridgehead. By the end of the fighting, the French had lost Aspern but still controlled Essling. A sustained Austrian artillery bombardment eventually convinced Napoleon to withdraw his forces back onto Lobau Island. Both sides inflicted about 23,000 casualties on each other.[165] It was the first defeat Napoleon suffered in a major set-piece battle, and it caused excitement throughout many parts of Europe because it proved that he could be beaten on the battlefield.[166]
After the setback at Aspern-Essling, Napoleon took more than six weeks in planning and preparing for contingencies before he made another attempt at crossing the Danube.[167] From 30 June to the early days of July, the French recrossed the Danube in strength, with more than 180,000 troops marching across the Marchfeld towards the Austrians.[167] Charles received the French with 150,000 of his own men.[168] In the ensuing Battle of Wagram, which also lasted two days, Napoleon commanded his forces in what was the largest battle of his career up until then. Napoleon finished off the battle with a concentrated central thrust that punctured a hole in the Austrian army and forced Charles to retreat. Austrian losses were very heavy, reaching well over 40,000 casualties.[169] The French were too exhausted to pursue the Austrians immediately, but Napoleon eventually caught up with Charles at Znaim and the latter signed an armistice on 12 July.
Separated from his wife and son, who had returned to Austria, cut off from the allowance guaranteed to him by the Treaty of Fontainebleau, and aware of rumours he was about to be banished to a remote island in the Atlantic Ocean,[199] Napoleon escaped from Elba in the brig Inconstant on 26 February 1815 with 700 men.[199] Two days later, he landed on the French mainland at Golfe-Juan and started heading north.[199]
The 5th Regiment was sent to intercept him and made contact just south of Grenoble on 7 March 1815. Napoleon approached the regiment alone, dismounted his horse and, when he was within gunshot range, shouted to the soldiers, "Here I am. Kill your Emperor, if you wish."[200] The soldiers quickly responded with, "Vive L'Empereur!" Ney, who had boasted to the restored Bourbon king, Louis XVIII, that he would bring Napoleon to Paris in an iron cage, affectionately kissed his former emperor and forgot his oath of allegiance to the Bourbon monarch. The two then marched together toward Paris with a growing army. The unpopular Louis XVIII fled to Belgium after realizing that he had little political support. On 13 March, the powers at the Congress of Vienna declared Napoleon an outlaw. Four days later, Great Britain, Russia, Austria, and Prussia each pledged to put 150,000 men into the field to end his rule.[201]
Napoleon arrived in Paris on 20 March and governed for a period now called the Hundred Days. By the start of June, the armed forces available to him had reached 200,000, and he decided to go on the offensive to attempt to drive a wedge between the oncoming British and Prussian armies. The French Army of the North crossed the frontier into the United Kingdom of the Netherlands, in modern-day Belgium.[202]
Napoleon's forces fought two Coalition armies, commanded by the British Duke of Wellington and the Prussian Prince Blücher, at the Battle of Waterloo on 18 June 1815. Wellington's army withstood repeated attacks by the French and drove them from the field while the Prussians arrived in force and broke through Napoleon's right flank.
Napoleon returned to Paris and found that both the legislature and the people had turned against him. Realizing that his position was untenable, he abdicated on 22 June in favour of his son. He left Paris three days later and settled at Josephine's former palace in Malmaison (on the western bank of the Seine about 17 kilometres (11 mi) west of Paris). Even as Napoleon travelled to Paris, the Coalition forces swept through France (arriving in the vicinity of Paris on 29 June), with the stated intent of restoring Louis XVIII to the French throne.
When Napoleon heard that Prussian troops had orders to capture him dead or alive, he fled to Rochefort, considering an escape to the United States. British ships were blocking every port. Napoleon surrendered to Captain Frederick Maitland on HMS Bellerophon on 15 July 1815.[203]